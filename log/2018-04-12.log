2018-04-12 12:28:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: HousePriceNJ)
2018-04-12 12:28:01 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.3.1, w3lib 1.18.0, Twisted 17.9.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-38-generic-x86_64-with-Ubuntu-16.04-xenial
2018-04-12 12:28:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'HousePriceNJ', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['HousePriceNJ.spiders'], 'NEWSPIDER_MODULE': 'HousePriceNJ.spiders', 'FEED_EXPORT_ENCODING': 'utf-8'}
2018-04-12 12:28:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-04-12 12:28:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-04-12 12:28:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-04-12 12:28:02 [scrapy.middleware] INFO: Enabled item pipelines:
['HousePriceNJ.pipelines.HousepricenjPipeline']
2018-04-12 12:28:02 [scrapy.core.engine] INFO: Spider opened
2018-04-12 12:28:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:28:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2018-04-12 12:28:02 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://nj.fang.lianjia.com/robots.txt> (referer: None)
2018-04-12 12:28:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg1> (referer: None)
2018-04-12 12:28:02 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-04-12 12:28:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg2> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcylggaatbq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rczyaarxa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%87%95%E5%AD%90%E7%9F%B6%E8%A1%97%E9%81%93%E8%9E%8D%E5%88%9B%E7%8E%89%E5%85%B0%E5%85%AC%E9%A6%86 HTTP/1.1" 200 137
2018-04-12 12:28:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rcylggaatbq/>
{'lat': 32.15160833098263,
 'lng': 118.84955152284388,
 'location': '南京项目地址：燕子矶街道融创玉兰公馆',
 'name': '融创玉兰公馆',
 'price': 0,
 'when': '2018-02-25'}
2018-04-12 12:28:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jpzydfaatdk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jysaatdp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF%E5%92%8C%E5%B9%BF%E7%94%B5%E5%8D%97%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:28:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rczyaarxa/>
{'lat': 32.0621065277938,
 'lng': 118.61903334846893,
 'location': '南京项目地址：雨山西路和广电南路交汇处',
 'name': '融创臻园',
 'price': 0,
 'when': '2017-12-07'}
2018-04-12 12:28:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gzbzszjlyabaiw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdjjtaadjb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E4%BA%94%E8%B7%AF%E9%87%91%E6%B5%A6%E7%B4%AB%E5%BE%A1%E4%B8%9C%E6%96%B9 HTTP/1.1" 200 134
2018-04-12 12:28:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jpzydfaatdk/>
{'lat': 32.1312287642796,
 'lng': 118.84117460118358,
 'location': '南京项目地址：经五路金浦紫御东方',
 'name': '金浦紫御东方',
 'price': ' 28600',
 'when': '2017-11-06'}
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%B4%E8%B4%A4%E8%B7%AF19%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jysaatdp/>
{'lat': 32.110827426049745,
 'lng': 118.84457333169928,
 'location': '南京项目地址：兴贤路19号',
 'name': '嘉誉山',
 'price': ' 29000',
 'when': '2017-07-09'}
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A5%94%E9%A9%AC%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E9%92%9F%E5%B1%B1 HTTP/1.1" 200 136
2018-04-12 12:28:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/>
{'lat': 32.08330568277308,
 'lng': 118.91771165983776,
 'location': '南京项目地址：奔马路新城璞樾钟山',
 'name': '新城璞樾钟山',
 'price': 0,
 'when': '2017-12-02'}
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%92%8C%E7%87%95%E8%B7%AF%E8%91%9B%E6%B4%B2%E5%9D%9D%E6%8B%9B%E5%95%86%E7%B4%AB%E9%83%A1%E8%98%AD%E5%9B%AD HTTP/1.1" 200 132
2018-04-12 12:28:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gzbzszjlyabaiw/>
{'lat': 32.1265750663835,
 'lng': 118.83957790985149,
 'location': '南京项目地址：和燕路葛洲坝招商紫郡蘭园',
 'name': '葛洲坝招商紫郡兰园',
 'price': 0,
 'when': '2017-10-31'}
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%B7%E5%8E%9A%E8%A1%9710%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdjjtaadjb/>
{'lat': 31.923030009156427,
 'lng': 118.78848868837916,
 'location': '南京项目地址：康厚街10号',
 'name': '九间堂',
 'price': ' 2200',
 'when': '2018-04-08'}
2018-04-12 12:28:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjydfabjyv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hynxnzxaavzr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%A2%A8%E6%A0%91%E5%9B%AD%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:28:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkjydfabjyv/>
{'lat': 31.934076010618092,
 'lng': 118.9482089800879,
 'location': '南京项目地址：淳化街道梨树园路9号',
 'name': '万科金域东方',
 'price': ' 23800',
 'when': '2018-03-24'}
2018-04-12 12:28:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E4%B8%AD%E5%A4%AE%E5%8C%97%E8%B7%AF%E6%B2%B3%E8%B7%AF%E9%81%931%E5%8F%B7 HTTP/1.1" 200 134
2018-04-12 12:28:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hynxnzxaavzr/>
{'lat': 32.1027477897518,
 'lng': 118.78834230949631,
 'location': '南京项目地址：鼓楼区中央北路河路道1号',
 'name': '花样年喜年中心',
 'price': ' 23000',
 'when': '2016-09-21'}
2018-04-12 12:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyzsgcxablwc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg3> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzscyfaapqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A2%A8%E6%A0%91%E5%9B%AD%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyzsgcxablwc/>
{'lat': 31.934076010618092,
 'lng': 118.9482089800879,
 'location': '南京项目地址：梨树园路10号',
 'name': '弘阳禹洲时光春晓',
 'price': ' 23600',
 'when': '2018-01-10'}
2018-04-12 12:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdfchtaadlc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yfltaacfl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E8%8B%8F%E5%AE%81%E9%92%9F%E5%B1%B1%E6%9C%9D%E9%98%B3%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:28:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_snzscyfaapqr/>
{'lat': 32.0913139891331,
 'lng': 118.89802397497581,
 'location': '南京项目地址：玄武大道苏宁钟山朝阳府',
 'name': '苏宁钟山朝阳府',
 'price': 0,
 'when': '2016-05-08'}
2018-04-12 12:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjgxtaasun/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rqgdyxaacoj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltllxzaavtr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E9%A3%9E%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdfchtaadlc/>
{'lat': 32.104949086157944,
 'lng': 118.82824103380696,
 'location': '南京项目地址：华飞路1号',
 'name': '恒大翡翠华庭',
 'price': ' 32000',
 'when': '2017-07-05'}
2018-04-12 12:28:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%86%E5%86%9B%E5%A4%A7%E9%81%93129%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yfltaacfl/>
{'lat': 31.912818603145553,
 'lng': 118.79794097426038,
 'location': '南京项目地址：将军大道129号',
 'name': '雍福龙庭',
 'price': 0,
 'when': '2017-01-25'}
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E4%B8%AD%E5%BB%BA%E5%9B%BD%E7%86%99%E5%8F%B0 HTTP/1.1" 200 142
2018-04-12 12:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjgxtaasun/>
{'lat': 32.06590199137902,
 'lng': 118.65369290890968,
 'location': '南京项目地址：新浦路中建国熙台',
 'name': '中建国熙台',
 'price': 0,
 'when': '2017-12-02'}
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%B7%E9%99%A2%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rqgdyxaacoj/>
{'lat': 32.08509008337853,
 'lng': 118.63412696869857,
 'location': '南京项目地址：海院路88号',
 'name': '融侨观邸',
 'price': ' 25500',
 'when': '2017-07-02'}
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E5%8D%97%E8%B7%AF688%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ltllxzaavtr/>
{'lat': 31.915202323802344,
 'lng': 118.86477525813511,
 'location': '南京项目地址：秣陵街道竹山南路688号',
 'name': '罗托鲁拉小镇',
 'price': 0,
 'when': '2017-11-18'}
2018-04-12 12:28:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcxylsaaccp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%AC%E5%9C%B0%E8%B7%AF%E6%96%B0%E5%9F%8E%E9%A6%99%E6%82%A6%E6%BE%9C%E5%B1%B1 HTTP/1.1" 200 140
2018-04-12 12:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xcxylsaaccp/>
{'lat': 32.131600315832,
 'lng': 118.9822212970358,
 'location': '南京项目地址：纬地路新城香悦澜山',
 'name': '新城香悦澜山',
 'price': 0,
 'when': '2017-04-10'}
2018-04-12 12:28:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smcpaawml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yqszaatdm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8F%8C%E8%B7%AF%E4%B8%96%E8%8C%82%E5%9F%8E%E5%93%81 HTTP/1.1" 200 145
2018-04-12 12:28:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smcpaawml/>
{'lat': 31.97666251592093,
 'lng': 118.76671169042649,
 'location': '南京项目地址：宁双路世茂城品',
 'name': '世茂城品',
 'price': 0,
 'when': '2017-06-23'}
2018-04-12 12:28:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg4> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E5%B1%B1%E8%A1%97%E9%81%93%E9%98%B3%E6%98%8E%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:28:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yqszaatdm/>
{'lat': 32.059437385842024,
 'lng': 118.96418417578569,
 'location': '南京项目地址：汤山街道阳明路99号',
 'name': '云栖山庄',
 'price': 0,
 'when': '2016-09-11'}
2018-04-12 12:28:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlysjaabvt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:28:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hrxytdaatbu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%85%89%E8%B7%AF67%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:28:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlysjaabvt/>
{'lat': 32.0310141948896,
 'lng': 118.81408773463262,
 'location': '南京项目地址：大光路67号',
 'name': '金陵雅颂居',
 'price': 0,
 'when': '2016-08-14'}
2018-04-12 12:28:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwqlnhyaaaux/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%80%E8%A1%977%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hrxytdaatbu/>
{'lat': 32.02198720429714,
 'lng': 118.76589413719202,
 'location': '南京项目地址：所街7号',
 'name': '华润新悦天地',
 'price': 0,
 'when': '2016-08-08'}
2018-04-12 12:28:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jyzjfaagmw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sfssaaqqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8D%8E%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:28:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cwqlnhyaaaux/>
{'lat': 32.31827364260565,
 'lng': 118.81844075425253,
 'location': '南京项目地址：龙池街道龙华路66号',
 'name': '骋望七里楠花园',
 'price': 0,
 'when': '2016-08-19'}
2018-04-12 12:28:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B3%B0%E5%B1%B1%E8%B7%AF%E9%87%91%E9%9A%85%E7%B4%AB%E9%87%91%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:28:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jyzjfaagmw/>
{'lat': 31.99647068073844,
 'lng': 118.74219268227752,
 'location': '南京项目地址：泰山路金隅紫金府',
 'name': '金隅紫京府',
 'price': ' 643',
 'when': '2017-12-30'}
2018-04-12 12:28:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E8%A1%97%E9%81%93%E5%B0%9A%E5%B3%B0%E5%B0%9A%E6%B0%B4 HTTP/1.1" 200 139
2018-04-12 12:28:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sfssaaqqv/>
{'lat': 32.097852651559236,
 'lng': 118.51451267002572,
 'location': '南京项目地址：汤泉街道尚峰尚水',
 'name': '尚峰尚水',
 'price': ' 500',
 'when': '2017-04-22'}
2018-04-12 12:28:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdhfaaelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjybjgjaagoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytaaava/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwydaaasz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjeqaatpa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E5%8F%B0%E5%8C%BA%E8%B5%9B%E8%99%B9%E6%A1%A5%E8%A1%97%E9%81%93 HTTP/1.1" 200 139
2018-04-12 12:28:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdhfaaelr/>
{'lat': 31.99525360625542,
 'lng': 118.76410088763129,
 'location': '南京项目地址：雨花台区赛虹桥街道',
 'name': '恒大华府',
 'price': 0,
 'when': '2017-02-13'}
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E6%B5%A6%E8%B7%AF96%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yjybjgjaagoo/>
{'lat': 32.068138157816925,
 'lng': 118.67819018794667,
 'location': '南京项目地址：天浦路96号',
 'name': '雅居乐滨江国际',
 'price': ' 28000',
 'when': '2017-11-06'}
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E8%83%A1%E6%A1%A5%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfytaaava/>
{'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：江浦街道胡桥路9号',
 'name': '明发云庭',
 'price': 0,
 'when': '2018-02-09'}
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%B9%A4%E9%B8%A3%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cwydaaasz/>
{'lat': 32.10341702868925,
 'lng': 118.90268150938394,
 'location': '南京项目地址：鹤鸣路68号',
 'name': '骋望云邸',
 'price': 0,
 'when': '2015-12-19'}
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:28:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gkrjeqaatpa/>
{'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境桂山堂',
 'price': ' 32000',
 'when': '2017-07-16'}
2018-04-12 12:28:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg5> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfzjgjaarco/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:28:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjhfaafcw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BC%A0%E6%95%A6%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfzjgjaarco/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：张敦路59号',
 'name': '明发珠江国际',
 'price': ' 27800',
 'when': '2016-04-15'}
2018-04-12 12:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrxhmdaatqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dsljaayua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njbgyaaldy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rqycaawis/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yztaadtx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjjcyxaabaj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A1%BE%E5%AE%B6%E8%90%A5%E8%B7%AF%E7%B4%AB%E9%87%91%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:28:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjhfaafcw/>
{'lat': 32.044802270791855,
 'lng': 118.8854034320355,
 'location': '南京项目地址：顾家营路紫金华府',
 'name': '紫金华府',
 'price': 0,
 'when': '2017-12-25'}
2018-04-12 12:28:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E5%85%83%E8%B7%AF%E4%B8%AD%E8%B7%AF128%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zrxhmdaatqp/>
{'lat': 32.04694030889066,
 'lng': 118.80071471620052,
 'location': '南京项目地址：天元路中路128号',
 'name': '中锐星湖名邸',
 'price': 0,
 'when': '2017-04-23'}
2018-04-12 12:28:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%8E%B1%E8%8C%B5%E8%BE%BE%E8%B7%AF12%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dsljaayua/>
{'lat': 31.950984236736673,
 'lng': 118.86091033640727,
 'location': '南京项目地址：莱茵达路12号',
 'name': '都市丽景',
 'price': 0,
 'when': '2017-01-22'}
2018-04-12 12:28:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%89%9B%E9%A6%96%E5%A4%A7%E9%81%93%E5%BA%86%E5%85%B4%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_njbgyaaldy/>
{'lat': 31.886978323966712,
 'lng': 118.71252324038538,
 'location': '南京项目地址：牛首大道庆兴路8号',
 'name': '南京碧桂园',
 'price': 0,
 'when': '2017-09-05'}
2018-04-12 12:28:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E4%B8%87%E5%AE%89%E5%8D%97%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:28:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rqycaawis/>
{'lat': 31.962191115716916,
 'lng': 118.88690470266143,
 'location': '南京项目地址：东山街道万安南路9号',
 'name': '融侨悦城',
 'price': 0,
 'when': '2018-03-30'}
2018-04-12 12:28:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%86%E5%86%9B%E5%A4%A7%E9%81%93%E9%9F%A9%E5%BA%9C%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yztaadtx/>
{'lat': 31.94294979560223,
 'lng': 118.78826271962814,
 'location': '南京项目地址：将军大道韩府路18号',
 'name': '滟紫台',
 'price': 0,
 'when': '2014-10-30'}
2018-04-12 12:28:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bjjcyxaabaj/>
{'lat': 32.05876455593678,
 'lng': 118.62066377476616,
 'location': '南京项目地址：雨山西路89号',
 'name': '北江锦城',
 'price': ' 24300',
 'when': '2017-11-01'}
2018-04-12 12:28:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhsyhaalja/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blxjyaabaz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E6%BA%AA%E8%A1%97%E9%81%93%E7%94%98%E6%B3%89%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhsyhaalja/>
{'lat': 31.759965542424297,
 'lng': 118.72924045440054,
 'location': '南京项目地址：横溪街道甘泉湖路1号',
 'name': '中浩山屿湖',
 'price': 0,
 'when': '2017-06-12'}
2018-04-12 12:28:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg6> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mlysaaawr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:28:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rshfaatdn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blzygyaaavy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smzsysaakkg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlhbskpaaeco/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9F%8E%E5%8D%97%E6%B2%B3%E8%B7%AF%E4%BF%9D%E5%88%A9%E8%A5%BF%E6%B1%9F%E6%9C%88 HTTP/1.1" 200 141
2018-04-12 12:28:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_blxjyaabaz/>
{'lat': 32.04810818480485,
 'lng': 118.66452157400175,
 'location': '南京项目地址：城南河路保利西江月',
 'name': '保利西江月',
 'price': 0,
 'when': '2017-05-27'}
2018-04-12 12:28:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lyzyaarxs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zlxyaatbm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%A8%E6%BA%AA%E5%A4%A7%E9%81%931000%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mlysaaawr/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滨溪大道1000号',
 'name': '牧龙原墅',
 'price': ' 23000',
 'when': '2015-04-24'}
2018-04-12 12:28:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E6%A1%A5%E8%A5%BF%E8%B7%AF162%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rshfaatdn/>
{'lat': 32.33635869765098,
 'lng': 118.84812434355814,
 'location': '南京项目地址：雄州街道桥西路162号',
 'name': '荣盛华府',
 'price': 0,
 'when': '2017-07-15'}
2018-04-12 12:28:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%95%BF%E4%BA%AD%E8%A1%9759%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_blzygyaaavy/>
{'lat': 31.914770739009395,
 'lng': 118.83304208150336,
 'location': '南京项目地址：秣陵街道长亭街59号',
 'name': '保利中央公园东苑',
 'price': 0,
 'when': '2017-06-15'}
2018-04-12 12:28:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E9%A9%AC%E8%B7%AF%E4%B8%96%E8%8C%82%E6%8B%9B%E5%95%86%E8%AF%AD%E5%B1%B1 HTTP/1.1" 200 143
2018-04-12 12:28:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smzsysaakkg/>
{'lat': 32.07140443035624,
 'lng': 118.91366956082265,
 'location': '南京项目地址：金马路世茂招商语山',
 'name': '世茂招商语山',
 'price': 0,
 'when': '2016-10-29'}
2018-04-12 12:28:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E6%B8%85%E6%B0%B4%E4%BA%AD%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlhbskpaaeco/>
{'lat': 31.919765529265728,
 'lng': 118.81406744370776,
 'location': '南京项目地址：秣陵街道清水亭西路188号',
 'name': '九龙湖别墅',
 'price': 0,
 'when': '2016-11-18'}
2018-04-12 12:28:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lyzyaarxs/>
{'lat': 32.05876455593678,
 'lng': 118.62066377476616,
 'location': '南京项目地址：雨山西路89号',
 'name': '路易庄园',
 'price': ' 25000',
 'when': '2018-01-19'}
2018-04-12 12:28:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E9%B9%8F%E5%B1%B1%E8%B7%AF28%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zlxyaatbm/>
{'lat': 31.924654849950382,
 'lng': 118.90626134667176,
 'location': '南京项目地址：淳化街道鹏山路28号',
 'name': '中粮祥云',
 'price': 0,
 'when': '2016-11-05'}
2018-04-12 12:28:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hdljaatpb/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:28:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_lntsyaatqn/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:28:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:28:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rshycaaksj/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg7> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djgyaabbs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wylzqhyaatpq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzyyxsaawjw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhgjsqaatbj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E9%95%87%E6%B1%9F%E6%98%9F%E6%A1%A5%E7%BA%BF HTTP/1.1" 200 138
2018-04-12 12:28:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djgyaabbs/>
{'lat': 32.09369697857316,
 'lng': 118.52483283221608,
 'location': '南京项目地址：汤泉镇江星桥线',
 'name': '大吉公元',
 'price': 0,
 'when': '2016-09-14'}
2018-04-12 12:28:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyjfaatdo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rsldrfaawky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyhgssaarrc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hrxflaakqa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E5%85%83%E4%B8%AD%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wylzqhyaatpq/>
{'lat': 31.93623568074372,
 'lng': 118.84629476472597,
 'location': '南京项目地址：天元中路99号',
 'name': '武夷绿洲沁荷苑',
 'price': 0,
 'when': '2017-07-03'}
2018-04-12 12:28:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%96%84%E6%B0%B4%E6%B9%BE%E8%A5%BF%E4%BE%A7%E7%A6%B9%E6%B4%B2%E6%98%A0%E6%9C%88%E6%BA%AA%E5%B1%B1 HTTP/1.1" 200 143
2018-04-12 12:28:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yzyyxsaawjw/>
{'lat': 31.958704964869618,
 'lng': 118.73669664435383,
 'location': '南京项目地址：善水湾西侧禹洲映月溪山',
 'name': '禹洲映月溪山',
 'price': 0,
 'when': '2017-04-28'}
2018-04-12 12:28:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%87%95%E5%AD%90%E7%9F%B6%E8%A1%97%E9%81%93%E4%B8%AD%E8%88%AA%E5%9B%BD%E9%99%85%E7%A4%BE%E5%8C%BA HTTP/1.1" 200 137
2018-04-12 12:28:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhgjsqaatbj/>
{'lat': 32.15160833098263,
 'lng': 118.84955152284388,
 'location': '南京项目地址：燕子矶街道中航国际社区',
 'name': '中航国际社区',
 'price': 0,
 'when': '2017-10-30'}
2018-04-12 12:28:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxyscaadwd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E6%96%B0%E8%B7%AF%E5%BC%98%E9%98%B3%E7%87%95%E6%B1%9F%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:28:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyjfaatdo/>
{'lat': 32.14416255725624,
 'lng': 118.83407420848347,
 'location': '南京项目地址：太新路弘阳燕江府',
 'name': '弘阳燕江府',
 'price': ' 25800',
 'when': '2016-12-29'}
2018-04-12 12:28:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E9%9E%8D%E8%A1%97%E9%81%93%E9%B9%AD%E5%B2%9B%E5%8D%97%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rsldrfaawky/>
{'lat': 32.5387256198191,
 'lng': 118.81897438994582,
 'location': '南京项目地址：马鞍街道鹭岛南路3号',
 'name': '荣盛鹭岛荣府',
 'price': ' 11500',
 'when': '2018-03-24'}
2018-04-12 12:28:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%B0%B7%E9%87%8C%E8%A1%97%E9%81%93%E6%82%A6%E6%B9%96%E8%B7%AF16%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:28:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyhgssaarrc/>
{'lat': 31.865723915051426,
 'lng': 118.73198543798807,
 'location': '南京项目地址：谷里街道悦湖路16号',
 'name': '碧桂园湖光山色',
 'price': ' 900',
 'when': '2017-12-23'}
2018-04-12 12:28:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%A7%E5%8C%96%E8%A1%97%E9%81%93%E5%89%8D%E5%A1%98%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hrxflaakqa/>
{'lat': 32.138809818069916,
 'lng': 118.89732473396684,
 'location': '南京项目地址：尧化街道前塘路9号',
 'name': '华润幸福里',
 'price': ' 18500',
 'when': '2017-09-30'}
2018-04-12 12:28:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jstygqcaaayk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:28:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:28:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rshycaaksj/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:28:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E7%A5%9E%E5%87%A4%E8%B7%AF1169%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:28:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hxyscaadwd/>
{'lat': 32.000159660995386,
 'lng': 118.95595120578673,
 'location': '南京项目地址：东山街道神凤路1169号',
 'name': '鸿信云深处',
 'price': ' 1762',
 'when': '2013-07-14'}
2018-04-12 12:28:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E5%8D%8E%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jstygqcaaayk/>
{'lat': 32.32157817364182,
 'lng': 118.81476070379864,
 'location': '南京项目地址：龙华路8号',
 'name': '金盛田阳光青城',
 'price': 0,
 'when': '2016-06-12'}
2018-04-12 12:28:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg8> (referer: https://nj.fang.lianjia.com/loupan/pg/pg7)
2018-04-12 12:28:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdljaatpb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%92%E9%BA%9F%E8%A1%97%E9%81%93%E8%A2%81%E5%AE%B6%E8%BE%B9%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdljaatpb/>
{'lat': 32.02524213109228,
 'lng': 118.92961737976174,
 'location': '南京项目地址：麒麟街道袁家边路9号',
 'name': '恒大龙珺',
 'price': 0,
 'when': '2017-07-08'}
2018-04-12 12:28:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rshycaaksj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E6%9E%97%E5%9C%BA%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:28:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rshycaaksj/>
{'lat': 32.32446249240832,
 'lng': 118.85133622323109,
 'location': '南京项目地址：龙池街道林场路1号',
 'name': '荣盛花语城',
 'price': 0,
 'when': '2017-08-05'}
2018-04-12 12:28:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jfnsaaelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BC%98%E6%99%AF%E5%A4%A7%E9%81%933888%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:28:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jfnsaaelc/>
{'lat': 31.902158491130926,
 'lng': 118.90369318104928,
 'location': '南京项目地址：弘景大道3888号',
 'name': '景枫你山',
 'price': 0,
 'when': '2016-08-26'}
2018-04-12 12:28:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sybjbdaamiq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lntsyaatqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg9> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycjydfaauoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djhfscaalag/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%9F%E8%B7%AF30%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sybjbdaamiq/>
{'lat': 32.10314358339629,
 'lng': 118.74617782513008,
 'location': '南京项目地址：龙江路30号',
 'name': '深业滨江半岛',
 'price': ' 38700',
 'when': '2017-12-25'}
2018-04-12 12:28:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%BC%E8%87%B4%E8%A5%BF%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lntsyaatqn/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：格致西路1号',
 'name': '鲁能泰山7号院',
 'price': 0,
 'when': '2017-07-19'}
2018-04-12 12:28:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97169%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ycjydfaauoe/>
{'lat': 32.05156767640222,
 'lng': 118.89683388187007,
 'location': '南京项目地址：马群街169号',
 'name': '银城君颐东方',
 'price': ' 43000',
 'when': '2017-12-02'}
2018-04-12 12:28:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E4%BA%94%E8%B7%AF%E7%94%B5%E5%BB%BA%E6%B5%B7%E8%B5%8B%E5%B0%9A%E5%9F%8E HTTP/1.1" 200 141
2018-04-12 12:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djhfscaalag/>
{'lat': 32.137634319277,
 'lng': 118.84295688872218,
 'location': '南京项目地址：经五路电建海赋尚城',
 'name': '电建海赋尚城',
 'price': ' 25800',
 'when': '2018-01-31'}
2018-04-12 12:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cfdszgaacay/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfxlsyaaedw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%A7%E9%BE%99%E6%B9%96%E5%A4%A7%E9%81%931%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/>
{'lat': 31.731203746093776,
 'lng': 119.0553388291052,
 'location': '南京项目地址：卧龙湖大道1号',
 'name': '卧龙湖小镇',
 'price': ' 13500',
 'when': '2018-02-03'}
2018-04-12 12:28:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E5%8D%97%E8%B7%AF5%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:28:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cfdszgaacay/>
{'lat': 31.99997241005109,
 'lng': 118.78497177739231,
 'location': '南京项目地址：雨花南路5号',
 'name': '长发都市诸公',
 'price': ' 864',
 'when': '2015-10-24'}
2018-04-12 12:28:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%99%BD%E9%A9%AC%E8%B7%AF90%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dfxlsyaaedw/>
{'lat': 32.08732150414787,
 'lng': 118.63490312801513,
 'location': '南京项目地址：白马路90号',
 'name': '东方熙龙山院',
 'price': 0,
 'when': '2012-12-20'}
2018-04-12 12:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhmdaakpp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfryaaknc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hynhycaakrk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E5%9B%BA%E5%9F%8E%E9%95%87%E8%82%B2%E6%89%8D%E8%A5%BF%E8%B7%AF91%E5%8F%B7%EF%BC%88%E5%AE%81%E5%AE%A3%E5%85%AC%E8%B7%AF%E4%B8%9C%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:28:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhmdaakpp/>
{'lat': 31.31262210058944,
 'lng': 118.97510527831135,
 'location': '南京项目地址：高淳固城镇育才西路91号（宁宣公路东侧）',
 'name': '景湖名都',
 'price': 0,
 'when': '2014-11-12'}
2018-04-12 12:28:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaazm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zyhfaaxbt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsylaatbk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rachsaahns/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:28:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltxfaawiy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mdjyslaadxi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%8B%9C%E5%B2%97%E8%B7%AF%E5%A4%A7%E5%8F%91%E8%9E%8D%E6%82%A6 HTTP/1.1" 200 144
2018-04-12 12:28:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dfryaaknc/>
{'lat': 32.03761727573808,
 'lng': 118.87577728900419,
 'location': '南京项目地址：双拜岗路大发融悦',
 'name': '大发融悦',
 'price': 0,
 'when': '2016-04-26'}
2018-04-12 12:28:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E9%AB%98%E8%B7%AF50%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:28:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hynhycaakrk/>
{'lat': 31.344984216195197,
 'lng': 118.92722832470832,
 'location': '南京项目地址：双高路50号',
 'name': '花样年花样城',
 'price': ' 8500',
 'when': '2017-12-06'}
2018-04-12 12:28:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%8C%E6%B1%9F%E6%95%85%E5%B1%85%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:28:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aaazm/>
{'lat': 31.865264410601366,
 'lng': 118.47517450362449,
 'location': '南京项目地址：乌江故居路8号',
 'name': '江岸景城',
 'price': ' 15000',
 'when': '2015-02-08'}
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%BE%E6%9D%A8%E8%B7%AF%E7%B4%AB%E8%89%BA%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 136
2018-04-12 12:28:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zyhfaaxbt/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：松杨路紫艺华府',
 'name': '紫艺华府',
 'price': 0,
 'when': '2018-01-19'}
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E7%87%95%E4%B8%9C%E8%B7%AF%E6%8B%9B%E5%95%861872%E5%85%AC%E5%9B%AD%E9%87%8C HTTP/1.1" 200 132
2018-04-12 12:28:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zsylaatbk/>
{'lat': 32.1265750663835,
 'lng': 118.83957790985149,
 'location': '南京项目地址：钟燕东路招商1872公园里',
 'name': '招商1872公园里',
 'price': 0,
 'when': '2017-03-08'}
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%89%9B%E9%A6%96%E5%B1%B1%E5%A4%A7%E9%81%93121%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rachsaahns/>
{'lat': 31.918954454210063,
 'lng': 118.75165574782486,
 'location': '南京项目地址：牛首山大道121号',
 'name': '瑞安翠湖山',
 'price': ' 20000',
 'when': '2018-04-03'}
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E7%86%9F%E8%A1%97%E9%81%93%E6%B6%A6%E6%B9%96%E5%A4%A7%E9%81%93398%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:28:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ltxfaawiy/>
{'lat': 31.873594814596018,
 'lng': 118.97674222511495,
 'location': '南京项目地址：湖熟街道润湖大道398号',
 'name': '梁台煦府',
 'price': 0,
 'when': '2016-12-10'}
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BB%84%E5%B1%B1%E5%B2%AD%E8%B7%AF%E4%B9%9D%E6%9C%88%E6%A3%AE%E6%9E%97 HTTP/1.1" 200 143
2018-04-12 12:28:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mdjyslaadxi/>
{'lat': 32.08342667185487,
 'lng': 118.62232126700839,
 'location': '南京项目地址：黄山岭路九月森林',
 'name': '九月森林',
 'price': 0,
 'when': '2018-03-24'}
2018-04-12 12:28:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_shshyaacka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E9%95%87%E5%81%87%E6%97%A5%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_shshyaacka/>
{'lat': 32.09294316228797,
 'lng': 118.52460713295669,
 'location': '南京项目地址：汤泉镇假日路8号',
 'name': '山河水花园',
 'price': ' 25000',
 'when': '2014-04-30'}
2018-04-12 12:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg10> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hymdaatgo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjmyaawmp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jrcfslaaudc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dhjxhcxymsaavuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:28:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9C%88%E5%AE%89%E8%A1%9711%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hymdaatgo/>
{'lat': 32.02460861962323,
 'lng': 118.74210601897207,
 'location': '南京项目地址：月安街11号',
 'name': '海玥名都',
 'price': 0,
 'when': '2017-04-21'}
2018-04-12 12:28:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%95%E5%BA%9C%E4%B8%9C%E8%B7%AF228%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:28:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjmyaawmp/>
{'lat': 32.12191964138096,
 'lng': 118.81329580556283,
 'location': '南京项目地址：幕府东路228号',
 'name': '紫金铭苑',
 'price': 0,
 'when': '2017-07-24'}
2018-04-12 12:28:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%90%89%E5%B1%B1%E5%A4%A7%E9%81%939%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jrcfslaaudc/>
{'lat': 31.861380358744533,
 'lng': 118.77282264452263,
 'location': '南京项目地址：吉山大道9号',
 'name': '景瑞春风十里',
 'price': ' 19000',
 'when': '2017-06-06'}
2018-04-12 12:28:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:28:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dhjxhcxymsaavuz/>
{'lat': 32.123523391191696,
 'lng': 118.72947850536069,
 'location': '南京项目地址：浦珠北路59号',
 'name': '大华锦绣华城香鸢美颂',
 'price': ' 24600',
 'when': '2017-11-25'}
2018-04-12 12:28:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg11> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:28:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htygjczgcaakog/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:28:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:28:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jpylwkpaalaf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:28:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E6%B7%B3%E6%BA%AA%E9%95%87%E5%AE%9D%E5%A1%94%E8%B7%AF269%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:28:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_htygjczgcaakog/>
{'lat': 31.33618242769404,
 'lng': 118.9089895903361,
 'location': '南京项目地址：高淳淳溪镇宝塔路269号',
 'name': '红太阳国际财智广场',
 'price': 0,
 'when': '2016-04-10'}
2018-04-12 12:28:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xhycbmlsaakqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:28:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smmxjaakrd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:28:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znjyaaksn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:28:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E6%A1%A5%E5%8C%97%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:28:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/>
{'lat': 32.01816879567414,
 'lng': 118.74715685147487,
 'location': '南京项目地址：大桥北路9号',
 'name': '弘阳印象华庭',
 'price': 0,
 'when': '2017-03-01'}
2018-04-12 12:28:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:28:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%92%8C%E7%87%95%E8%B7%AF390%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:28:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jpylwkpaalaf/>
{'lat': 32.11951519928469,
 'lng': 118.82242316715464,
 'location': '南京项目地址：和燕路390号',
 'name': '金浦御龙湾',
 'price': 0,
 'when': '2017-07-21'}
2018-04-12 12:28:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sclfaakub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:28:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_heshyhggaakok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:28:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E7%99%BD%E9%A9%AC%E8%B7%AF%E4%B8%8E%E7%8B%AE%E5%B1%B1%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:29:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xhycbmlsaakqw/>
{'lat': 32.08258412514195,
 'lng': 118.63632209768683,
 'location': '南京项目地址：浦口区白马路与狮山路交汇处',
 'name': '旭辉银城白马澜山',
 'price': 0,
 'when': '2017-12-25'}
2018-04-12 12:29:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E7%91%9E%E6%96%87%E8%B7%AF199%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smmxjaakrd/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：淳化街道瑞文路199号',
 'name': '世茂梦享家',
 'price': 0,
 'when': '2016-04-30'}
2018-04-12 12:29:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: HousePriceNJ)
2018-04-12 12:29:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.3.1, w3lib 1.18.0, Twisted 17.9.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-38-generic-x86_64-with-Ubuntu-16.04-xenial
2018-04-12 12:29:02 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'HousePriceNJ.spiders', 'FEED_EXPORT_ENCODING': 'utf-8', 'BOT_NAME': 'HousePriceNJ', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['HousePriceNJ.spiders']}
2018-04-12 12:29:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage']
2018-04-12 12:29:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-04-12 12:29:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-04-12 12:29:02 [scrapy.middleware] INFO: Enabled item pipelines:
['HousePriceNJ.pipelines.HousepricenjPipeline']
2018-04-12 12:29:02 [scrapy.core.engine] INFO: Spider opened
2018-04-12 12:29:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:29:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6026
2018-04-12 12:29:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BD%AF%E4%BB%B6%E5%A4%A7%E9%81%93%E4%B8%AD%E5%8D%97%E9%94%A6%E8%8B%91 HTTP/1.1" 200 144
2018-04-12 12:29:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_znjyaaksn/>
{'lat': 31.984256699458975,
 'lng': 118.75651496529456,
 'location': '南京项目地址：软件大道中南锦苑',
 'name': '中南锦苑',
 'price': 0,
 'when': '2016-09-03'}
2018-04-12 12:29:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fhhrdxaaclk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:29:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aafrw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:02 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://nj.fang.lianjia.com/robots.txt> (referer: None)
2018-04-12 12:29:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wycaakob/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:29:02 [scrapy.extensions.logstats] INFO: Crawled 103 pages (at 103 pages/min), scraped 86 items (at 86 items/min)
2018-04-12 12:29:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%9C%B0%E9%93%81%E4%BA%8C%E5%8F%B7%E7%BA%BF%E5%A4%A9%E8%BF%88%E5%B9%BF%E5%9C%BA%E6%B2%B9%E5%9D%8A%E6%A1%A5%E7%AB%99 HTTP/1.1" 200 139
2018-04-12 12:29:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sclfaakub/>
{'lat': 31.971841104007034,
 'lng': 118.72764980327469,
 'location': '南京项目地址：建邺地铁二号线天迈广场油坊桥站',
 'name': '首创立方',
 'price': ' 20000',
 'when': '2016-04-01'}
2018-04-12 12:29:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_heshyhggaakok/>
{'lat': 31.393150940897428,
 'lng': 118.97196008794114,
 'location': '南京项目地址：双湖路1号',
 'name': '海尔双湖壹号公馆',
 'price': ' 8300',
 'when': '2017-09-27'}
2018-04-12 12:29:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg1> (referer: None)
2018-04-12 12:29:03 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-04-12 12:29:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg2> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rczyaarxa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcylggaatbq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jysaatdp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jpzydfaatdk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF%E5%92%8C%E5%B9%BF%E7%94%B5%E5%8D%97%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:29:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rczyaarxa/>
{'lat': 32.0621065277938,
 'lng': 118.61903334846893,
 'location': '南京项目地址：雨山西路和广电南路交汇处',
 'name': '融创臻园',
 'price': 0,
 'when': '2017-12-07'}
2018-04-12 12:29:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E5%B9%B3%E5%8D%97%E8%B7%AF%E4%B8%8E%E7%99%BD%E4%B8%8B%E8%B7%AF%E4%BA%A4%E7%95%8C%E5%A4%84 HTTP/1.1" 200 136
2018-04-12 12:29:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_fhhrdxaaclk/>
{'lat': 32.03553521855789,
 'lng': 118.79736364858033,
 'location': '南京项目地址：太平南路与白下路交界处',
 'name': '凤凰和睿大厦',
 'price': ' 22000',
 'when': '时间待定'}
2018-04-12 12:29:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%87%95%E5%AD%90%E7%9F%B6%E8%A1%97%E9%81%93%E8%9E%8D%E5%88%9B%E7%8E%89%E5%85%B0%E5%85%AC%E9%A6%86 HTTP/1.1" 200 137
2018-04-12 12:29:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rcylggaatbq/>
{'lat': 32.15160833098263,
 'lng': 118.84955152284388,
 'location': '南京项目地址：燕子矶街道融创玉兰公馆',
 'name': '融创玉兰公馆',
 'price': 0,
 'when': '2018-02-25'}
2018-04-12 12:29:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%B4%E8%B4%A4%E8%B7%AF19%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jysaatdp/>
{'lat': 32.110827426049745,
 'lng': 118.84457333169928,
 'location': '南京项目地址：兴贤路19号',
 'name': '嘉誉山',
 'price': ' 29000',
 'when': '2017-07-09'}
2018-04-12 12:29:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%87%A4%E9%9B%86%E5%A4%A7%E9%81%936%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aafrw/>
{'lat': 31.93439038369555,
 'lng': 118.66586279443327,
 'location': '南京项目地址：凤集大道6号',
 'name': '石林大公园',
 'price': 0,
 'when': '2012-08-08'}
2018-04-12 12:29:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%9D%E9%BE%99%E5%B1%B1%E8%B7%AF%E4%B8%87%E6%82%A6%E5%9F%8E HTTP/1.1" 200 143
2018-04-12 12:29:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wycaakob/>
{'lat': 31.369820090663627,
 'lng': 118.95197910453356,
 'location': '南京项目地址：九龙山路万悦城',
 'name': '万悦城',
 'price': 0,
 'when': '2017-05-03'}
2018-04-12 12:29:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfptmhjaaqjj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fdyzsyxaampu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyascaapvm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%87%A4%E6%B1%87%E5%A4%A7%E9%81%93%E6%98%8E%E5%8F%91%E6%B5%A6%E6%B3%B0%E6%A2%A6%E5%B9%BB%E5%AE%B6 HTTP/1.1" 200 143
2018-04-12 12:29:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfptmhjaaqjj/>
{'lat': 31.92740779796182,
 'lng': 118.64778341958687,
 'location': '南京项目地址：凤汇大道明发浦泰梦幻家',
 'name': '明发浦泰梦幻家',
 'price': 0,
 'when': '2017-09-05'}
2018-04-12 12:29:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E9%A9%AC%E7%BE%A4%E8%A1%972%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_fdyzsyxaampu/>
{'lat': 32.05578425340213,
 'lng': 118.89966428083703,
 'location': '南京项目地址：马群街道马群街2号',
 'name': '复地御钟山二期',
 'price': 0,
 'when': '2014-07-19'}
2018-04-12 12:29:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A6%E5%B1%B1%E8%A1%97%E9%81%93123%E5%9C%B0%E5%9D%97 HTTP/1.1" 200 136
2018-04-12 12:29:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyascaapvm/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：秦山街道123地块',
 'name': '弘阳爱上城',
 'price': 0,
 'when': '2015-11-20'}
2018-04-12 12:29:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg12> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycyfsaafsp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E4%BA%94%E8%B7%AF%E9%87%91%E6%B5%A6%E7%B4%AB%E5%BE%A1%E4%B8%9C%E6%96%B9 HTTP/1.1" 200 134
2018-04-12 12:29:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jpzydfaatdk/>
{'lat': 32.1312287642796,
 'lng': 118.84117460118358,
 'location': '南京项目地址：经五路金浦紫御东方',
 'name': '金浦紫御东方',
 'price': ' 28600',
 'when': '2017-11-06'}
2018-04-12 12:29:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E5%90%89%E5%8D%B0%E5%A4%A7%E9%81%934199%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ycyfsaafsp/>
{'lat': 31.878871395291938,
 'lng': 118.78266735426757,
 'location': '南京项目地址：江宁区淳化街道吉印大道4199号',
 'name': '银城一方山',
 'price': 0,
 'when': '2015-11-13'}
2018-04-12 12:29:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjdhaacak/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ssyfhyyxaafss/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aafrg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tzyyxaafsh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hjfhsaahno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:29:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg13> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhjyaadjj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A5%94%E9%A9%AC%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E9%92%9F%E5%B1%B1 HTTP/1.1" 200 136
2018-04-12 12:29:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/>
{'lat': 32.08330568277308,
 'lng': 118.91771165983776,
 'location': '南京项目地址：奔马路新城璞樾钟山',
 'name': '新城璞樾钟山',
 'price': 0,
 'when': '2017-12-02'}
2018-04-12 12:29:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyzsgcxablwc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdjjtaadjb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gzbzszjlyabaiw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjydfabjyv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hynxnzxaavzr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:29:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A2%A8%E6%A0%91%E5%9B%AD%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyzsgcxablwc/>
{'lat': 31.934076010618092,
 'lng': 118.9482089800879,
 'location': '南京项目地址：梨树园路10号',
 'name': '弘阳禹洲时光春晓',
 'price': ' 23600',
 'when': '2018-01-10'}
2018-04-12 12:29:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%B7%E5%8E%9A%E8%A1%9710%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdjjtaadjb/>
{'lat': 31.923030009156427,
 'lng': 118.78848868837916,
 'location': '南京项目地址：康厚街10号',
 'name': '九间堂',
 'price': ' 2200',
 'when': '2018-04-08'}
2018-04-12 12:29:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%92%8C%E7%87%95%E8%B7%AF%E8%91%9B%E6%B4%B2%E5%9D%9D%E6%8B%9B%E5%95%86%E7%B4%AB%E9%83%A1%E8%98%AD%E5%9B%AD HTTP/1.1" 200 132
2018-04-12 12:29:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gzbzszjlyabaiw/>
{'lat': 32.1265750663835,
 'lng': 118.83957790985149,
 'location': '南京项目地址：和燕路葛洲坝招商紫郡蘭园',
 'name': '葛洲坝招商紫郡兰园',
 'price': 0,
 'when': '2017-10-31'}
2018-04-12 12:29:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%A2%A8%E6%A0%91%E5%9B%AD%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkjydfabjyv/>
{'lat': 31.934076010618092,
 'lng': 118.9482089800879,
 'location': '南京项目地址：淳化街道梨树园路9号',
 'name': '万科金域东方',
 'price': ' 23800',
 'when': '2018-03-24'}
2018-04-12 12:29:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%91%E5%92%8C%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:29:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkjdhaacak/>
{'lat': 31.976571884202652,
 'lng': 118.81231844287983,
 'location': '南京项目地址：民和路1号',
 'name': '万科九都荟',
 'price': 0,
 'when': '2015-11-17'}
2018-04-12 12:29:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF126%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ssyfhyyxaafss/>
{'lat': 32.11862130443328,
 'lng': 118.70782125782063,
 'location': '南京项目地址：浦珠北路126号',
 'name': '山水云房花园',
 'price': ' 23000',
 'when': '2017-05-22'}
2018-04-12 12:29:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%91%A1%E5%9B%AD%E8%B7%AF%E4%BB%81%E6%81%92%E7%BB%BF%E6%B4%B2%E6%96%B0%E5%B2%9B HTTP/1.1" 200 143
2018-04-12 12:29:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/>
{'lat': 32.03377176667957,
 'lng': 118.70845022618616,
 'location': '南京项目地址：葡园路仁恒绿洲新岛',
 'name': '仁恒绿洲新岛',
 'price': 0,
 'when': '2017-11-19'}
2018-04-12 12:29:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E5%87%A4%E6%BB%A8%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aafrg/>
{'lat': 32.207695799701774,
 'lng': 118.74507388427848,
 'location': '南京项目地址：大厂凤滨路18号',
 'name': '福基九龙新城',
 'price': 0,
 'when': '2011-05-06'}
2018-04-12 12:29:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E4%B8%AD%E5%A4%AE%E5%8C%97%E8%B7%AF%E6%B2%B3%E8%B7%AF%E9%81%931%E5%8F%B7 HTTP/1.1" 200 134
2018-04-12 12:29:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hynxnzxaavzr/>
{'lat': 32.1027477897518,
 'lng': 118.78834230949631,
 'location': '南京项目地址：鼓楼区中央北路河路道1号',
 'name': '花样年喜年中心',
 'price': ' 23000',
 'when': '2016-09-21'}
2018-04-12 12:29:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg3> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlysjaabvt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcxylsaaccp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E8%B7%AF588%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tzyyxaafsh/>
{'lat': 31.92671560623449,
 'lng': 118.85742595575786,
 'location': '南京项目地址：江宁区秣陵街道竹山路588号',
 'name': '天泽苑',
 'price': ' 28000',
 'when': '2018-02-03'}
2018-04-12 12:29:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%85%89%E8%B7%AF67%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlysjaabvt/>
{'lat': 32.0310141948896,
 'lng': 118.81408773463262,
 'location': '南京项目地址：大光路67号',
 'name': '金陵雅颂居',
 'price': 0,
 'when': '2016-08-14'}
2018-04-12 12:29:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rqgdyxaacoj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yqszaatdm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yfltaacfl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdfchtaadlc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smcpaawml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjgxtaasun/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%AC%E5%9C%B0%E8%B7%AF%E6%96%B0%E5%9F%8E%E9%A6%99%E6%82%A6%E6%BE%9C%E5%B1%B1 HTTP/1.1" 200 140
2018-04-12 12:29:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xcxylsaaccp/>
{'lat': 32.131600315832,
 'lng': 118.9822212970358,
 'location': '南京项目地址：纬地路新城香悦澜山',
 'name': '新城香悦澜山',
 'price': 0,
 'when': '2017-04-10'}
2018-04-12 12:29:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E9%9C%9E%E6%96%87%E9%BC%8E%E8%B7%AF1%E5%8F%B7%EF%BC%88%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E4%B8%8E%E5%AD%A6%E6%9E%97%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:29:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hjfhsaahno/>
{'lat': 32.11865857092845,
 'lng': 118.91214765162765,
 'location': '南京项目地址：栖霞文鼎路1号（玄武大道与学林路交汇处）',
 'name': '恒基富荟山',
 'price': 0,
 'when': '2014-10-30'}
2018-04-12 12:29:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E6%B9%96%E8%B7%AF100%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhjyaadjj/>
{'lat': 31.696231584053706,
 'lng': 119.11840755372283,
 'location': '南京项目地址：金湖路100号',
 'name': '金湖家园',
 'price': 0,
 'when': '2011-08-18'}
2018-04-12 12:29:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aadlk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gxzrtcaabuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xwhjmgcaadxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jjhtaabzh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxcaabwu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%AF%E9%99%B5%E8%B7%AF7%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aadlk/>
{'lat': 32.08813762841439,
 'lng': 118.87777963354526,
 'location': '南京项目地址：环陵路7号',
 'name': '钟山国际高尔夫',
 'price': 0,
 'when': '2013-06-01'}
2018-04-12 12:29:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%B2%BF%E5%B1%B1%E4%B8%9C%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gxzrtcaabuc/>
{'lat': 32.09729036743584,
 'lng': 118.63965590436665,
 'location': '南京项目地址：浦口区江浦街道沿山东路188号',
 'name': '国信自然天城',
 'price': 0,
 'when': '2008-10-28'}
2018-04-12 12:29:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%B7%E9%99%A2%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rqgdyxaacoj/>
{'lat': 32.08509008337853,
 'lng': 118.63412696869857,
 'location': '南京项目地址：海院路88号',
 'name': '融侨观邸',
 'price': ' 25500',
 'when': '2017-07-02'}
2018-04-12 12:29:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%AE%E8%B7%AF201%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xwhjmgcaadxy/>
{'lat': 32.07904243541421,
 'lng': 118.78987490852688,
 'location': '南京项目地址：中央路201号',
 'name': '玄武湖金茂广场御景华府',
 'price': 0,
 'when': '2009-11-01'}
2018-04-12 12:29:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E5%B1%B1%E8%A1%97%E9%81%93%E9%98%B3%E6%98%8E%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:29:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yqszaatdm/>
{'lat': 32.059437385842024,
 'lng': 118.96418417578569,
 'location': '南京项目地址：汤山街道阳明路99号',
 'name': '云栖山庄',
 'price': 0,
 'when': '2016-09-11'}
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%93%BA%E5%B2%97%E8%A1%9728%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jjhtaabzh/>
{'lat': 31.924283790875556,
 'lng': 118.84223111805659,
 'location': '南京项目地址：秣陵街道铺岗街28号',
 'name': '骏景华庭',
 'price': 0,
 'when': '2015-08-12'}
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%86%E5%86%9B%E5%A4%A7%E9%81%93129%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:29:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yfltaacfl/>
{'lat': 31.912818603145553,
 'lng': 118.79794097426038,
 'location': '南京项目地址：将军大道129号',
 'name': '雍福龙庭',
 'price': 0,
 'when': '2017-01-25'}
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E9%A3%9E%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdfchtaadlc/>
{'lat': 32.104949086157944,
 'lng': 118.82824103380696,
 'location': '南京项目地址：华飞路1号',
 'name': '恒大翡翠华庭',
 'price': ' 32000',
 'when': '2017-07-05'}
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8F%8C%E8%B7%AF%E4%B8%96%E8%8C%82%E5%9F%8E%E5%93%81 HTTP/1.1" 200 145
2018-04-12 12:29:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smcpaawml/>
{'lat': 31.97666251592093,
 'lng': 118.76671169042649,
 'location': '南京项目地址：宁双路世茂城品',
 'name': '世茂城品',
 'price': 0,
 'when': '2017-06-23'}
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E4%B8%AD%E5%BB%BA%E5%9B%BD%E7%86%99%E5%8F%B0 HTTP/1.1" 200 142
2018-04-12 12:29:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjgxtaasun/>
{'lat': 32.06590199137902,
 'lng': 118.65369290890968,
 'location': '南京项目地址：新浦路中建国熙台',
 'name': '中建国熙台',
 'price': 0,
 'when': '2017-12-02'}
2018-04-12 12:29:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzscyfaapqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltllxzaavtr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:29:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%AC%E5%AD%90%E6%B1%9F%E5%A4%A7%E9%81%93399%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hxcaabwu/>
{'lat': 31.987082829704036,
 'lng': 118.69301154165758,
 'location': '南京项目地址：扬子江大道399号',
 'name': '海峡城',
 'price': 0,
 'when': '时间待定'}
2018-04-12 12:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cjfjaaazu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwyhcaadvo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gfdyaadlv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_attycaadid/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg14> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyyjwaacdv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E5%8C%97%E8%B7%AF645%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cjfjaaazu/>
{'lat': 32.09263358876117,
 'lng': 118.74039547747762,
 'location': '南京项目地址：中山北路645号',
 'name': '长江峰景',
 'price': 0,
 'when': '2010-12-30'}
2018-04-12 12:29:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9B%A2%E5%B1%B1%E8%A5%BF%E8%B7%AF26%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cwyhcaadvo/>
{'lat': 31.69267717506764,
 'lng': 119.0207176406826,
 'location': '南京项目地址：团山西路26号',
 'name': '创维乐活城',
 'price': ' 6800',
 'when': '2017-09-29'}
2018-04-12 12:29:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E8%8B%8F%E5%AE%81%E9%92%9F%E5%B1%B1%E6%9C%9D%E9%98%B3%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:29:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_snzscyfaapqr/>
{'lat': 32.0913139891331,
 'lng': 118.89802397497581,
 'location': '南京项目地址：玄武大道苏宁钟山朝阳府',
 'name': '苏宁钟山朝阳府',
 'price': 0,
 'when': '2016-05-08'}
2018-04-12 12:29:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jyzjfaagmw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytaaava/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjeqaatpa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwqlnhyaaaux/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjybjgjaagoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sfssaaqqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E5%8D%97%E8%B7%AF688%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ltllxzaavtr/>
{'lat': 31.915202323802344,
 'lng': 118.86477525813511,
 'location': '南京项目地址：秣陵街道竹山南路688号',
 'name': '罗托鲁拉小镇',
 'price': 0,
 'when': '2017-11-18'}
2018-04-12 12:29:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B3%B0%E5%B1%B1%E8%B7%AF%E9%87%91%E9%9A%85%E7%B4%AB%E9%87%91%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:29:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jyzjfaagmw/>
{'lat': 31.99647068073844,
 'lng': 118.74219268227752,
 'location': '南京项目地址：泰山路金隅紫金府',
 'name': '金隅紫京府',
 'price': ' 643',
 'when': '2017-12-30'}
2018-04-12 12:29:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E9%93%9C%E8%B7%AF%E5%9B%BD%E5%BA%9C%E5%A4%A7%E9%99%A2 HTTP/1.1" 200 145
2018-04-12 12:29:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gfdyaadlv/>
{'lat': 31.868615425164933,
 'lng': 118.97393347470582,
 'location': '南京项目地址：汤铜路国府大院',
 'name': '国府大院',
 'price': 0,
 'when': '2016-05-12'}
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A6%E6%B7%AE%E5%A4%A7%E9%81%93399%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_attycaadid/>
{'lat': 31.645263048037307,
 'lng': 119.0541065336066,
 'location': '南京项目地址：秦淮大道399号',
 'name': '爱涛天岳城',
 'price': 0,
 'when': '2018-01-08'}
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E7%9A%8B%E6%A1%A5%E8%A1%97%E9%81%93%E7%BD%91%E6%9D%BF%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xyyjwaacdv/>
{'lat': 32.10966291802278,
 'lng': 118.8313789586822,
 'location': '南京项目地址：迈皋桥街道网板路8号',
 'name': '星叶瑜憬湾',
 'price': ' 29500',
 'when': '2018-03-27'}
2018-04-12 12:29:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdyhfdaaavg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaadt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E7%94%B5%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdyhfdaaavg/>
{'lat': 32.107868121583785,
 'lng': 118.81988199561275,
 'location': '南京项目地址：华电路1号',
 'name': '中电颐和府邸',
 'price': 0,
 'when': '2017-12-26'}
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E8%83%A1%E6%A1%A5%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfytaaava/>
{'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：江浦街道胡桥路9号',
 'name': '明发云庭',
 'price': 0,
 'when': '2018-02-09'}
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%87%E6%99%AF%E5%8C%97%E8%B7%AF%E4%BF%9D%E5%88%A9%E5%A0%82%E6%82%A6 HTTP/1.1" 200 143
2018-04-12 12:29:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aaadt/>
{'lat': 31.987086765521944,
 'lng': 118.81312602132991,
 'location': '南京项目地址：汇景北路保利堂悦',
 'name': '保利堂悦',
 'price': 0,
 'when': '2017-01-18'}
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gkrjeqaatpa/>
{'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境桂山堂',
 'price': ' 32000',
 'when': '2017-07-16'}
2018-04-12 12:29:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyfqsaaaclf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltllxzaacjt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jzycsgcaachb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lsqcjqaacmb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%A1%AB%E6%B9%96%E4%B8%9C%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xyfqsaaaclf/>
{'lat': 31.947722743322984,
 'lng': 118.88189242724522,
 'location': '南京项目地址：衫湖东路18号',
 'name': '星叶枫情水岸',
 'price': 0,
 'when': '2015-03-06'}
2018-04-12 12:29:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8D%8E%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:29:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cwqlnhyaaaux/>
{'lat': 32.31827364260565,
 'lng': 118.81844075425253,
 'location': '南京项目地址：龙池街道龙华路66号',
 'name': '骋望七里楠花园',
 'price': 0,
 'when': '2016-08-19'}
2018-04-12 12:29:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E6%B5%A6%E8%B7%AF96%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yjybjgjaagoo/>
{'lat': 32.068138157816925,
 'lng': 118.67819018794667,
 'location': '南京项目地址：天浦路96号',
 'name': '雅居乐滨江国际',
 'price': ' 28000',
 'when': '2017-11-06'}
2018-04-12 12:29:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E5%8D%97%E8%B7%AF688%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ltllxzaacjt/>
{'lat': 31.915202323802344,
 'lng': 118.86477525813511,
 'location': '南京项目地址：秣陵街道竹山南路688号',
 'name': '罗托鲁拉小镇',
 'price': 0,
 'when': '2016-04-30'}
2018-04-12 12:29:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bllsaaazg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:29:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yclxjaaces/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyyshhyaaazr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:29:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wdmaacfw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:29:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E6%B8%85%E8%B7%AF%E4%BD%B3%E5%85%86%E4%B8%9A%E5%9F%8E%E5%B8%82%E5%B9%BF%E5%9C%BA HTTP/1.1" 200 144
2018-04-12 12:29:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jzycsgcaachb/>
{'lat': 31.975496662881305,
 'lng': 118.71114275142682,
 'location': '南京项目地址：太清路佳兆业城市广场',
 'name': '佳兆业城市广场',
 'price': ' 300',
 'when': '2017-11-19'}
2018-04-12 12:29:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%A5%E5%87%A4%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lsqcjqaacmb/>
{'lat': 31.78379644297444,
 'lng': 118.86052299785104,
 'location': '南京项目地址：来凤路18号',
 'name': '朗诗青春街区',
 'price': 0,
 'when': '2017-11-30'}
2018-04-12 12:29:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E8%A1%97%E9%81%93%E5%B0%9A%E5%B3%B0%E5%B0%9A%E6%B0%B4 HTTP/1.1" 200 139
2018-04-12 12:29:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sfssaaqqv/>
{'lat': 32.097852651559236,
 'lng': 118.51451267002572,
 'location': '南京项目地址：汤泉街道尚峰尚水',
 'name': '尚峰尚水',
 'price': ' 500',
 'when': '2017-04-22'}
2018-04-12 12:29:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwydaaasz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfzjgjaarco/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BB%99%E6%9E%97%E8%A1%97%E9%81%93%E4%BF%9D%E5%88%A9%E7%A4%BC%E5%A2%85 HTTP/1.1" 200 137
2018-04-12 12:29:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bllsaaazg/>
{'lat': 32.11097695649148,
 'lng': 118.9295337061967,
 'location': '南京项目地址：仙林街道保利礼墅',
 'name': '保利礼墅',
 'price': 0,
 'when': '2015-06-20'}
2018-04-12 12:29:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%B9%A4%E9%B8%A3%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cwydaaasz/>
{'lat': 32.10341702868925,
 'lng': 118.90268150938394,
 'location': '南京项目地址：鹤鸣路68号',
 'name': '骋望云邸',
 'price': 0,
 'when': '2015-12-19'}
2018-04-12 12:29:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg4> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hrxytdaatbu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdhfaaelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:29:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BC%A0%E6%95%A6%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfzjgjaarco/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：张敦路59号',
 'name': '明发珠江国际',
 'price': ' 27800',
 'when': '2016-04-15'}
2018-04-12 12:29:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%80%E8%A1%977%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hrxytdaatbu/>
{'lat': 32.02198720429714,
 'lng': 118.76589413719202,
 'location': '南京项目地址：所街7号',
 'name': '华润新悦天地',
 'price': 0,
 'when': '2016-08-08'}
2018-04-12 12:29:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E5%8F%B0%E5%8C%BA%E8%B5%9B%E8%99%B9%E6%A1%A5%E8%A1%97%E9%81%93 HTTP/1.1" 200 139
2018-04-12 12:29:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdhfaaelr/>
{'lat': 31.99525360625542,
 'lng': 118.76410088763129,
 'location': '南京项目地址：雨花台区赛虹桥街道',
 'name': '恒大华府',
 'price': 0,
 'when': '2017-02-13'}
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E5%88%9B%E6%96%B0%E4%B8%9C%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:29:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yclxjaaces/>
{'lat': 31.8838176413981,
 'lng': 118.88290815941363,
 'location': '南京项目地址：秣陵街道创新东路2号',
 'name': '银城蓝溪郡',
 'price': 0,
 'when': '2016-04-16'}
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BE%8A%E5%B1%B1%E5%8C%97%E8%B7%AF%E6%98%9F%E5%8F%B6%E7%BE%8A%E5%B1%B1%E6%B9%96%E8%8A%B1%E5%9B%AD HTTP/1.1" 200 136
2018-04-12 12:29:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xyyshhyaaazr/>
{'lat': 32.12228406250346,
 'lng': 118.9464675340093,
 'location': '南京项目地址：羊山北路星叶羊山湖花园',
 'name': '星叶羊山湖花园',
 'price': 0,
 'when': '2014-10-25'}
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg5> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF%E4%B8%87%E8%BE%BE%E8%8C%82 HTTP/1.1" 200 135
2018-04-12 12:29:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wdmaacfw/>
{'lat': 32.13304989681055,
 'lng': 118.9886366904625,
 'location': '南京项目地址：守敬路万达茂',
 'name': '万达茂',
 'price': 0,
 'when': '2015-10-31'}
2018-04-12 12:29:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_pjhfyxaaaze/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:29:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ckxdyyaabax/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dsljaayua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrxhmdaatqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjhfaafcw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%8E%B1%E8%8C%B5%E8%BE%BE%E8%B7%AF12%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dsljaayua/>
{'lat': 31.950984236736673,
 'lng': 118.86091033640727,
 'location': '南京项目地址：莱茵达路12号',
 'name': '都市丽景',
 'price': 0,
 'when': '2017-01-22'}
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E5%85%83%E8%B7%AF%E4%B8%AD%E8%B7%AF128%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zrxhmdaatqp/>
{'lat': 32.04694030889066,
 'lng': 118.80071471620052,
 'location': '南京项目地址：天元路中路128号',
 'name': '中锐星湖名邸',
 'price': 0,
 'when': '2017-04-23'}
2018-04-12 12:29:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A1%BE%E5%AE%B6%E8%90%A5%E8%B7%AF%E7%B4%AB%E9%87%91%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:29:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjhfaafcw/>
{'lat': 32.044802270791855,
 'lng': 118.8854034320355,
 'location': '南京项目地址：顾家营路紫金华府',
 'name': '紫金华府',
 'price': 0,
 'when': '2017-12-25'}
2018-04-12 12:29:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rqycaawis/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjjcyxaabaj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njbgyaaldy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yztaadtx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E4%B8%87%E5%AE%89%E5%8D%97%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rqycaawis/>
{'lat': 31.962191115716916,
 'lng': 118.88690470266143,
 'location': '南京项目地址：东山街道万安南路9号',
 'name': '融侨悦城',
 'price': 0,
 'when': '2018-03-30'}
2018-04-12 12:29:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:35 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E6%96%B0%E5%8D%8E%E8%A5%BF%E8%B7%AF458%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_pjhfyxaaaze/>
{'lat': 32.20805330579511,
 'lng': 118.7399702187509,
 'location': '南京项目地址：大厂新华西路458号',
 'name': '盘金华府',
 'price': 0,
 'when': '2014-06-21'}
2018-04-12 12:29:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg15> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:29:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhjjaabbi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:29:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bjjcyxaabaj/>
{'lat': 32.05876455593678,
 'lng': 118.62066377476616,
 'location': '南京项目地址：雨山西路89号',
 'name': '北江锦城',
 'price': ' 24300',
 'when': '2017-11-01'}
2018-04-12 12:29:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%89%9B%E9%A6%96%E5%A4%A7%E9%81%93%E5%BA%86%E5%85%B4%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_njbgyaaldy/>
{'lat': 31.886978323966712,
 'lng': 118.71252324038538,
 'location': '南京项目地址：牛首大道庆兴路8号',
 'name': '南京碧桂园',
 'price': 0,
 'when': '2017-09-05'}
2018-04-12 12:29:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E7%8E%8B%E6%A1%A5%E8%B7%AF28%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ckxdyyaabax/>
{'lat': 32.33955818255956,
 'lng': 118.84800376222998,
 'location': '南京项目地址：雄州街道王桥路28号',
 'name': '城开新都雅苑',
 'price': 0,
 'when': '2017-11-01'}
2018-04-12 12:29:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%86%B6%E6%B5%A6%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhjjaabbi/>
{'lat': 32.34747334123522,
 'lng': 118.867418077437,
 'location': '南京项目地址：冶浦路99号',
 'name': '龙海骏景',
 'price': 0,
 'when': '2017-08-03'}
2018-04-12 12:29:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mlhwjaayyg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%86%E5%86%9B%E5%A4%A7%E9%81%93%E9%9F%A9%E5%BA%9C%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yztaadtx/>
{'lat': 31.94294979560223,
 'lng': 118.78826271962814,
 'location': '南京项目地址：将军大道韩府路18号',
 'name': '滟紫台',
 'price': 0,
 'when': '2014-10-30'}
2018-04-12 12:29:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blxjyaabaz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhsyhaalja/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mlysaaawr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:29:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rshfaatdn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E9%95%87%E8%A5%BF%E5%B1%B1%E5%A4%B4 HTTP/1.1" 200 133
2018-04-12 12:29:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mlhwjaayyg/>
{'lat': 31.954170205823228,
 'lng': 118.93133649576195,
 'location': '南京项目地址：淳化镇西山头',
 'name': '梅龙湖无界',
 'price': 0,
 'when': '2015-10-15'}
2018-04-12 12:29:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdxmlyzxaavxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9F%8E%E5%8D%97%E6%B2%B3%E8%B7%AF%E4%BF%9D%E5%88%A9%E8%A5%BF%E6%B1%9F%E6%9C%88 HTTP/1.1" 200 141
2018-04-12 12:29:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_blxjyaabaz/>
{'lat': 32.04810818480485,
 'lng': 118.66452157400175,
 'location': '南京项目地址：城南河路保利西江月',
 'name': '保利西江月',
 'price': 0,
 'when': '2017-05-27'}
2018-04-12 12:29:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlxlfaawai/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zslxgkaayyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E6%BA%AA%E8%A1%97%E9%81%93%E7%94%98%E6%B3%89%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhsyhaalja/>
{'lat': 31.759965542424297,
 'lng': 118.72924045440054,
 'location': '南京项目地址：横溪街道甘泉湖路1号',
 'name': '中浩山屿湖',
 'price': 0,
 'when': '2017-06-12'}
2018-04-12 12:29:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%A8%E6%BA%AA%E5%A4%A7%E9%81%931000%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mlysaaawr/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滨溪大道1000号',
 'name': '牧龙原墅',
 'price': ' 23000',
 'when': '2015-04-24'}
2018-04-12 12:29:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E6%A1%A5%E8%A5%BF%E8%B7%AF162%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rshfaatdn/>
{'lat': 32.33635869765098,
 'lng': 118.84812434355814,
 'location': '南京项目地址：雄州街道桥西路162号',
 'name': '荣盛华府',
 'price': 0,
 'when': '2017-07-15'}
2018-04-12 12:29:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zlxyaatbm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smzsysaakkg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lyzyaarxs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E9%B9%8F%E5%B1%B1%E8%B7%AF28%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zlxyaatbm/>
{'lat': 31.924654849950382,
 'lng': 118.90626134667176,
 'location': '南京项目地址：淳化街道鹏山路28号',
 'name': '中粮祥云',
 'price': 0,
 'when': '2016-11-05'}
2018-04-12 12:29:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%91%E6%99%BA%E8%B7%AF9%E5%8F%B7%E3%80%8110%E5%8F%B7%E3%80%8111%E5%8F%B7%E3%80%8112%E5%8F%B7%E3%80%8113%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdxmlyzxaavxy/>
{'lat': 31.97029556775504,
 'lng': 118.81089211249278,
 'location': '南京项目地址：民智路9号、10号、11号、12号、13号',
 'name': '证大喜玛拉雅中心',
 'price': ' 20000',
 'when': '2018-01-06'}
2018-04-12 12:29:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfxsjaaeoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lgwxdhaavvc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg16> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhysaayxj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8D%97%E8%A1%97%E9%81%93%E9%87%91%E8%BD%AE%E6%98%9F%E7%AB%8B%E6%96%B9 HTTP/1.1" 200 136
2018-04-12 12:29:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlxlfaawai/>
{'lat': 31.99799477275822,
 'lng': 118.78177238865749,
 'location': '南京项目地址：宁南街道金轮星立方',
 'name': '金轮星立方',
 'price': ' 60000',
 'when': '2015-12-04'}
2018-04-12 12:29:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E9%A9%AC%E8%B7%AF%E4%B8%96%E8%8C%82%E6%8B%9B%E5%95%86%E8%AF%AD%E5%B1%B1 HTTP/1.1" 200 143
2018-04-12 12:29:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smzsysaakkg/>
{'lat': 32.07140443035624,
 'lng': 118.91366956082265,
 'location': '南京项目地址：金马路世茂招商语山',
 'name': '世茂招商语山',
 'price': 0,
 'when': '2016-10-29'}
2018-04-12 12:29:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lyzyaarxs/>
{'lat': 32.05876455593678,
 'lng': 118.62066377476616,
 'location': '南京项目地址：雨山西路89号',
 'name': '路易庄园',
 'price': ' 25000',
 'when': '2018-01-19'}
2018-04-12 12:29:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlhbskpaaeco/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blzygyaaavy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lntsyaatqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg6> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%8E%E5%9F%8E%E5%A4%A7%E9%81%93%E4%B8%87%E7%A7%91%E9%83%BD%E8%8D%9F%E5%8D%97%E8%8B%91 HTTP/1.1" 200 136
2018-04-12 12:29:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrs/>
{'lat': 31.97475979445248,
 'lng': 118.81085768852734,
 'location': '南京项目地址：明城大道万科都荟南苑',
 'name': '万科星荟',
 'price': 0,
 'when': '2017-07-12'}
2018-04-12 12:29:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E6%96%B0%E8%B7%AF%E6%8B%9B%E5%95%86%E5%85%B0%E6%BA%AA%E8%B0%B7 HTTP/1.1" 200 136
2018-04-12 12:29:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zslxgkaayyp/>
{'lat': 31.65760622534108,
 'lng': 119.04859890125368,
 'location': '南京项目地址：永新路招商兰溪谷',
 'name': '招商兰溪谷',
 'price': 0,
 'when': '2017-11-02'}
2018-04-12 12:29:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93%E4%B8%8E%E8%B4%A2%E5%85%AB%E8%B7%AF%E4%BA%A4%E5%8F%89%E5%8F%A3%EF%BC%88%E5%A4%A7%E9%A9%AC%E5%B1%B1%E8%B7%AF6%E5%8F%B7%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:29:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfxsjaaeoe/>
{'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：浦口江浦街道沿山大道与财八路交叉口（大马山路6号）',
 'name': '明发香山郡',
 'price': ' 26000',
 'when': '2017-07-22'}
2018-04-12 12:29:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E6%B8%85%E6%B0%B4%E4%BA%AD%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:29:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlhbskpaaeco/>
{'lat': 31.919765529265728,
 'lng': 118.81406744370776,
 'location': '南京项目地址：秣陵街道清水亭西路188号',
 'name': '九龙湖别墅',
 'price': 0,
 'when': '2016-11-18'}
2018-04-12 12:29:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%95%BF%E4%BA%AD%E8%A1%9759%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_blzygyaaavy/>
{'lat': 31.914770739009395,
 'lng': 118.83304208150336,
 'location': '南京项目地址：秣陵街道长亭街59号',
 'name': '保利中央公园东苑',
 'price': 0,
 'when': '2017-06-15'}
2018-04-12 12:29:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E4%B9%90%E8%B7%AF%E6%B4%AA%E5%AE%B6%E5%9B%AD1%E5%8F%B7 HTTP/1.1" 200 143
2018-04-12 12:29:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lgwxdhaavvc/>
{'lat': 32.0053428312632,
 'lng': 118.80204028545512,
 'location': '南京项目地址：永乐路洪家园1号',
 'name': '绿国万象都荟',
 'price': ' 50000',
 'when': '2015-11-17'}
2018-04-12 12:29:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E6%B9%96%E8%A1%97%E9%81%93%E9%80%9A%E6%B2%B3%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhysaayxj/>
{'lat': 32.45045312201094,
 'lng': 118.94784796098479,
 'location': '南京项目地址：金牛湖街道通河路9号',
 'name': '嘉恒有山',
 'price': ' 9550',
 'when': '2017-12-16'}
2018-04-12 12:29:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hycsxjaawkm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xtjaawkz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:29:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E8%97%8F%E5%A4%A7%E9%81%9312%E5%8F%B7%E5%BC%98%E9%98%B3 HTTP/1.1" 200 137
2018-04-12 12:29:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hycsxjaawkm/>
{'lat': 31.94682158034673,
 'lng': 118.67416296037928,
 'location': '南京项目地址：龙藏大道12号弘阳',
 'name': '弘阳春上西江',
 'price': 0,
 'when': '2016-11-27'}
2018-04-12 12:29:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8F%A3%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xtjaawkz/>
{'lat': 32.323376930598535,
 'lng': 118.8191838325704,
 'location': '南京项目地址：龙池街道龙口路9号',
 'name': '香缇郡',
 'price': 0,
 'when': '2016-10-20'}
2018-04-12 12:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg17> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%BC%E8%87%B4%E8%A5%BF%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lntsyaatqn/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：格致西路1号',
 'name': '鲁能泰山7号院',
 'price': 0,
 'when': '2017-07-19'}
2018-04-12 12:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhxwggabaxa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwqlnhyabgpx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxcabbgw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjgcabbey/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%81%92%E5%98%89%E8%B7%AF%E4%B8%AD%E6%B5%B7%E7%8E%84%E6%AD%A6%E5%85%AC%E9%A6%86 HTTP/1.1" 200 142
2018-04-12 12:29:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhxwggabaxa/>
{'lat': 32.10309198480382,
 'lng': 118.82802835368933,
 'location': '南京项目地址：恒嘉路中海玄武公馆',
 'name': '中海玄武公馆',
 'price': 0,
 'when': '2017-03-30'}
2018-04-12 12:29:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldzcabbev/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxhfabbbc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%A7%E9%BE%99%E6%B9%96%E5%A4%A7%E9%81%931%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/>
{'lat': 31.731203746093776,
 'lng': 119.0553388291052,
 'location': '南京项目地址：卧龙湖大道1号',
 'name': '卧龙湖小镇',
 'price': ' 13500',
 'when': '2018-02-03'}
2018-04-12 12:29:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8D%8E%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:29:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cwqlnhyabgpx/>
{'lat': 32.31827364260565,
 'lng': 118.81844075425253,
 'location': '南京项目地址：龙池街道龙华路66号',
 'name': '骋望七里楠花园',
 'price': 0,
 'when': '2015-02-14'}
2018-04-12 12:29:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg7> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:29:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdljaatpb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxyscaadwd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:29:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rshycaaksj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:29:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jstygqcaaayk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:29:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%AC%E5%AD%90%E6%B1%9F%E5%A4%A7%E9%81%93399%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:29:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hxcabbgw/>
{'lat': 31.987082829704036,
 'lng': 118.69301154165758,
 'location': '南京项目地址：扬子江大道399号',
 'name': '海峡城',
 'price': ' 30000',
 'when': '2016-12-20'}
2018-04-12 12:29:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%92%E9%BA%9F%E8%A1%97%E9%81%93%E8%A2%81%E5%AE%B6%E8%BE%B9%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdljaatpb/>
{'lat': 32.02524213109228,
 'lng': 118.92961737976174,
 'location': '南京项目地址：麒麟街道袁家边路9号',
 'name': '恒大龙珺',
 'price': 0,
 'when': '2017-07-08'}
2018-04-12 12:29:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyjfaatdo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:29:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hrxflaakqa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:29:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzyyxsaawjw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:29:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyhgssaarrc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:29:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E7%A5%9E%E5%87%A4%E8%B7%AF1169%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:29:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hxyscaadwd/>
{'lat': 32.000159660995386,
 'lng': 118.95595120578673,
 'location': '南京项目地址：东山街道神凤路1169号',
 'name': '鸿信云深处',
 'price': ' 1762',
 'when': '2013-07-14'}
2018-04-12 12:29:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E6%9E%97%E5%9C%BA%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:29:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rshycaaksj/>
{'lat': 32.32446249240832,
 'lng': 118.85133622323109,
 'location': '南京项目地址：龙池街道林场路1号',
 'name': '荣盛花语城',
 'price': 0,
 'when': '2017-08-05'}
2018-04-12 12:29:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E5%8D%8E%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jstygqcaaayk/>
{'lat': 32.32157817364182,
 'lng': 118.81476070379864,
 'location': '南京项目地址：龙华路8号',
 'name': '金盛田阳光青城',
 'price': 0,
 'when': '2016-06-12'}
2018-04-12 12:29:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BA%91%E9%94%A6%E8%B7%AF%E6%89%80%E8%A1%97 HTTP/1.1" 200 136
2018-04-12 12:29:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yjgcabbey/>
{'lat': 32.04035147114477,
 'lng': 118.75098867333959,
 'location': '南京项目地址：云锦路所街',
 'name': '乐基广场',
 'price': 0,
 'when': '2014-11-26'}
2018-04-12 12:29:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bltyabgvd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:29:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njbjzbjdswqabcno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sswhykpaawjt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njcfgcabgvg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:29:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytabctb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsabdir/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:29:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E6%96%B0%E8%B7%AF%E5%BC%98%E9%98%B3%E7%87%95%E6%B1%9F%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:29:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyjfaatdo/>
{'lat': 32.14416255725624,
 'lng': 118.83407420848347,
 'location': '南京项目地址：太新路弘阳燕江府',
 'name': '弘阳燕江府',
 'price': ' 25800',
 'when': '2016-12-29'}
2018-04-12 12:29:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E5%8D%97%E7%AB%99%E5%8C%97%E5%B9%BF%E5%9C%BA%E7%BB%BF%E5%9C%B0%E4%B9%8B%E7%AA%97 HTTP/1.1" 200 144
2018-04-12 12:29:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ldzcabbev/>
{'lat': 31.973807633953474,
 'lng': 118.79656951147558,
 'location': '南京项目地址：南京南站北广场绿地之窗',
 'name': '绿地之窗',
 'price': ' 60000',
 'when': '2017-01-01'}
2018-04-12 12:29:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%9F%E8%B7%AF%EF%BC%88%E5%8D%97%E4%BA%AC%E8%A5%BF%E7%AB%99%E8%A5%BF%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 140
2018-04-12 12:29:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jxhfabbbc/>
{'lat': 32.10087185564733,
 'lng': 118.74873294286502,
 'location': '南京项目地址：龙江路（南京西站西侧）',
 'name': '锦绣华府',
 'price': ' 420',
 'when': '2016-09-02'}
2018-04-12 12:29:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%94%E5%A4%A9%E5%A4%A7%E8%A1%97%E4%BF%9D%E5%88%A9%E5%A4%A9%E6%82%A6 HTTP/1.1" 200 145
2018-04-12 12:29:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bltyabgvd/>
{'lat': 32.03108091466837,
 'lng': 118.73254774489833,
 'location': '南京项目地址：应天大街保利天悦',
 'name': '保利天悦',
 'price': 0,
 'when': '2017-11-18'}
2018-04-12 12:29:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%A7%E5%8C%96%E8%A1%97%E9%81%93%E5%89%8D%E5%A1%98%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hrxflaakqa/>
{'lat': 32.138809818069916,
 'lng': 118.89732473396684,
 'location': '南京项目地址：尧化街道前塘路9号',
 'name': '华润幸福里',
 'price': ' 18500',
 'when': '2017-09-30'}
2018-04-12 12:29:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E7%87%95%E6%B1%9F%E8%B7%AF201%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:29:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_njbjzbjdswqabcno/>
{'lat': 32.06860445880062,
 'lng': 118.76505691316264,
 'location': '南京项目地址：鼓楼区燕江路201号',
 'name': '江山汇金',
 'price': ' 17100',
 'when': '2014-05-07'}
2018-04-12 12:29:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A2%85%E5%85%B4%E8%B7%AF%E5%96%84%E6%B0%B4%E6%B9%BE%E8%8A%B1%E5%9B%AD HTTP/1.1" 200 144
2018-04-12 12:29:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sswhykpaawjt/>
{'lat': 31.958704964869618,
 'lng': 118.73669664435383,
 'location': '南京项目地址：梅兴路善水湾花园',
 'name': '善水湾花园',
 'price': 0,
 'when': '2013-03-30'}
2018-04-12 12:29:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%B1%B1%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:29:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_njcfgcabgvg/>
{'lat': 32.09260114030094,
 'lng': 118.81803364578863,
 'location': '南京项目地址：红山路88号',
 'name': '南京常发广场',
 'price': ' 25000',
 'when': '2015-08-05'}
2018-04-12 12:29:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:29:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%96%84%E6%B0%B4%E6%B9%BE%E8%A5%BF%E4%BE%A7%E7%A6%B9%E6%B4%B2%E6%98%A0%E6%9C%88%E6%BA%AA%E5%B1%B1 HTTP/1.1" 200 143
2018-04-12 12:29:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yzyyxsaawjw/>
{'lat': 31.958704964869618,
 'lng': 118.73669664435383,
 'location': '南京项目地址：善水湾西侧禹洲映月溪山',
 'name': '禹洲映月溪山',
 'price': 0,
 'when': '2017-04-28'}
2018-04-12 12:29:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E8%83%A1%E6%A1%A5%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfytabctb/>
{'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：江浦街道胡桥路9号',
 'name': '明发云庭',
 'price': ' 35000',
 'when': '2017-03-18'}
2018-04-12 12:30:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A5%94%E9%A9%AC%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E9%92%9F%E5%B1%B1 HTTP/1.1" 200 136
2018-04-12 12:30:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xcpyzsabdir/>
{'lat': 32.08330568277308,
 'lng': 118.91771165983776,
 'location': '南京项目地址：奔马路新城璞樾钟山',
 'name': '新城璞樾钟山',
 'price': ' 900',
 'when': '2017-12-02'}
2018-04-12 12:30:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_tyljxyabgtm/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:30:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_tsyjabgtd/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%B0%B7%E9%87%8C%E8%A1%97%E9%81%93%E6%82%A6%E6%B9%96%E8%B7%AF16%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:30:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyhgssaarrc/>
{'lat': 31.865723915051426,
 'lng': 118.73198543798807,
 'location': '南京项目地址：谷里街道悦湖路16号',
 'name': '碧桂园湖光山色',
 'price': ' 900',
 'when': '2017-12-23'}
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djgyaabbs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wylzqhyaatpq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rsldrfaawky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg18> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E9%95%87%E6%B1%9F%E6%98%9F%E6%A1%A5%E7%BA%BF HTTP/1.1" 200 138
2018-04-12 12:30:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djgyaabbs/>
{'lat': 32.09369697857316,
 'lng': 118.52483283221608,
 'location': '南京项目地址：汤泉镇江星桥线',
 'name': '大吉公元',
 'price': 0,
 'when': '2016-09-14'}
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg8> (referer: https://nj.fang.lianjia.com/loupan/pg/pg7)
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E5%85%83%E4%B8%AD%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wylzqhyaatpq/>
{'lat': 31.93623568074372,
 'lng': 118.84629476472597,
 'location': '南京项目地址：天元中路99号',
 'name': '武夷绿洲沁荷苑',
 'price': 0,
 'when': '2017-07-03'}
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E9%9E%8D%E8%A1%97%E9%81%93%E9%B9%AD%E5%B2%9B%E5%8D%97%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rsldrfaawky/>
{'lat': 32.5387256198191,
 'lng': 118.81897438994582,
 'location': '南京项目地址：马鞍街道鹭岛南路3号',
 'name': '荣盛鹭岛荣府',
 'price': ' 11500',
 'when': '2018-03-24'}
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjgxtabgdk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tyljxyabgtm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tsyjabgtd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhgjsqaatbj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg19> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E4%B8%AD%E5%BB%BA%E5%9B%BD%E7%86%99%E5%8F%B0 HTTP/1.1" 200 142
2018-04-12 12:30:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjgxtabgdk/>
{'lat': 32.06590199137902,
 'lng': 118.65369290890968,
 'location': '南京项目地址：新浦路中建国熙台',
 'name': '中建国熙台',
 'price': 0,
 'when': '2017-06-16'}
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_pthtxsqabgbq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:30:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyzsgyxabgwq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:30:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: HousePriceNJ)
2018-04-12 12:30:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.3.1, w3lib 1.18.0, Twisted 17.9.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-38-generic-x86_64-with-Ubuntu-16.04-xenial
2018-04-12 12:30:02 [scrapy.crawler] INFO: Overridden settings: {'SPIDER_MODULES': ['HousePriceNJ.spiders'], 'NEWSPIDER_MODULE': 'HousePriceNJ.spiders', 'FEED_EXPORT_ENCODING': 'utf-8', 'ROBOTSTXT_OBEY': True, 'BOT_NAME': 'HousePriceNJ'}
2018-04-12 12:30:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2018-04-12 12:30:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-04-12 12:30:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-04-12 12:30:02 [scrapy.middleware] INFO: Enabled item pipelines:
['HousePriceNJ.pipelines.HousepricenjPipeline']
2018-04-12 12:30:02 [scrapy.core.engine] INFO: Spider opened
2018-04-12 12:30:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:30:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6028
2018-04-12 12:30:03 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://nj.fang.lianjia.com/robots.txt> (referer: None)
2018-04-12 12:30:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg1> (referer: None)
2018-04-12 12:30:03 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-04-12 12:30:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%87%95%E5%AD%90%E7%9F%B6%E8%A1%97%E9%81%93%E4%B8%AD%E8%88%AA%E5%9B%BD%E9%99%85%E7%A4%BE%E5%8C%BA HTTP/1.1" 200 137
2018-04-12 12:30:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhgjsqaatbj/>
{'lat': 32.15160833098263,
 'lng': 118.84955152284388,
 'location': '南京项目地址：燕子矶街道中航国际社区',
 'name': '中航国际社区',
 'price': 0,
 'when': '2017-10-30'}
2018-04-12 12:30:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E4%B8%83%E9%87%8C%E8%B7%AF%E4%B8%8E%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:30:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tyljxyabgtm/>
{'lat': 32.0913457771416,
 'lng': 118.65014507465395,
 'location': '南京项目地址：江浦街道七里路与沿山大道交汇处',
 'name': '通宇林景熙园',
 'price': 0,
 'when': '2017-08-02'}
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgybasjabgyc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jfnsaaelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg2> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfryaaknc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhmdaakpp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cfdszgaacay/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rachsaahns/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:04 [scrapy.extensions.logstats] INFO: Crawled 74 pages (at 74 pages/min), scraped 60 items (at 60 items/min)
2018-04-12 12:30:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcylggaatbq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rczyaarxa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%87%95%E5%AD%90%E7%9F%B6%E8%A1%97%E9%81%93%E8%9E%8D%E5%88%9B%E7%8E%89%E5%85%B0%E5%85%AC%E9%A6%86 HTTP/1.1" 200 137
2018-04-12 12:30:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.15160833098263,
 'lng': 118.84955152284388,
 'location': '南京项目地址：燕子矶街道融创玉兰公馆',
 'name': '融创玉兰公馆',
 'price': 0,
 'when': '2018-02-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jysaatdp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jpzydfaatdk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdjjtaadjb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B4%AA%E8%93%9D%E9%95%87%E5%87%A4%E5%87%B0%E4%BA%95%E8%B7%AF26%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tsyjabgtd/>
{'lat': 31.634768533012924,
 'lng': 119.00443475589523,
 'location': '南京项目地址：洪蓝镇凤凰井路26号',
 'name': '天生御景',
 'price': 0,
 'when': '2014-10-17'}
2018-04-12 12:30:06 [scrapy.extensions.logstats] INFO: Crawled 173 pages (at 70 pages/min), scraped 150 items (at 64 items/min)
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BC%98%E6%99%AF%E5%A4%A7%E9%81%933888%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jfnsaaelc/>
{'lat': 31.902158491130926,
 'lng': 118.90369318104928,
 'location': '南京项目地址：弘景大道3888号',
 'name': '景枫你山',
 'price': 0,
 'when': '2016-08-26'}
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%8B%9C%E5%B2%97%E8%B7%AF%E5%A4%A7%E5%8F%91%E8%9E%8D%E6%82%A6 HTTP/1.1" 200 144
2018-04-12 12:30:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dfryaaknc/>
{'lat': 32.03761727573808,
 'lng': 118.87577728900419,
 'location': '南京项目地址：双拜岗路大发融悦',
 'name': '大发融悦',
 'price': 0,
 'when': '2016-04-26'}
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E5%9B%BA%E5%9F%8E%E9%95%87%E8%82%B2%E6%89%8D%E8%A5%BF%E8%B7%AF91%E5%8F%B7%EF%BC%88%E5%AE%81%E5%AE%A3%E5%85%AC%E8%B7%AF%E4%B8%9C%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:30:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhmdaakpp/>
{'lat': 31.31262210058944,
 'lng': 118.97510527831135,
 'location': '南京项目地址：高淳固城镇育才西路91号（宁宣公路东侧）',
 'name': '景湖名都',
 'price': 0,
 'when': '2014-11-12'}
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_pthtxsqabgbq/>
{'lat': 32.13531269255433,
 'lng': 118.74226588429522,
 'location': '南京项目地址：江山路9号',
 'name': '浦泰和天下三期',
 'price': 0,
 'when': '2017-11-11'}
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E5%87%A4%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E5%8D%97%E8%B7%AF5%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyzsgyxabgwq/>
{'lat': 31.652751200874587,
 'lng': 119.0233543470155,
 'location': '南京项目地址：栖凤路68号',
 'name': '弘阳禹洲时光印象',
 'price': 0,
 'when': '2017-12-27'}
2018-04-12 12:30:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cfdszgaacay/>
{'lat': 31.99997241005109,
 'lng': 118.78497177739231,
 'location': '南京项目地址：雨花南路5号',
 'name': '长发都市诸公',
 'price': ' 864',
 'when': '2015-10-24'}
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF%E5%92%8C%E5%B9%BF%E7%94%B5%E5%8D%97%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:30:06 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0621065277938,
 'lng': 118.61903334846893,
 'location': '南京项目地址：雨山西路和广电南路交汇处',
 'name': '融创臻园',
 'price': 0,
 'when': '2017-12-07'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gzbzszjlyabaiw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjydfabjyv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%81%E9%98%B3%E4%B8%9C%E8%B7%AF901%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgybasjabgyc/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滁阳东路901号',
 'name': '碧桂园北岸世家',
 'price': 0,
 'when': '2017-07-26'}
2018-04-12 12:30:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A5%94%E9%A9%AC%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E9%92%9F%E5%B1%B1 HTTP/1.1" 200 136
2018-04-12 12:30:07 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08330568277308,
 'lng': 118.91771165983776,
 'location': '南京项目地址：奔马路新城璞樾钟山',
 'name': '新城璞樾钟山',
 'price': 0,
 'when': '2017-12-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg20> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:30:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_thnjyzaatgz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:30:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkddhabexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:30:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjjzaatbs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E5%8D%97%E8%B7%AF501%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_thnjyzaatgz/>
{'lat': 32.026788843993685,
 'lng': 118.78769049901827,
 'location': '南京项目地址：中山南路501号',
 'name': '泰禾南京院子',
 'price': 0,
 'when': '2017-06-06'}
2018-04-12 12:30:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcjctdaaxrj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%AB%99%E4%B8%9C%E4%BA%8C%E8%B7%AF%E4%B8%87%E7%A7%91%E5%A4%A7%E9%83%BD%E4%BC%9A HTTP/1.1" 200 136
2018-04-12 12:30:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkddhabexa/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：站东二路万科大都会',
 'name': '万科大都会',
 'price': 0,
 'when': '2018-03-30'}
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%8E%E5%9F%8E%E5%A4%A7%E9%81%93%E4%BB%A5%E8%A5%BF%E4%B8%AD%E4%BA%A4%E9%94%A6%E8%87%B4 HTTP/1.1" 200 136
2018-04-12 12:30:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjjzaatbs/>
{'lat': 31.97475979445248,
 'lng': 118.81085768852734,
 'location': '南京项目地址：明城大道以西中交锦致',
 'name': '中交锦致',
 'price': 0,
 'when': '2017-07-15'}
2018-04-12 12:30:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytaaycz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:30:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyhsabezj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:30:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djzcfycsgcabfky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:30:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkapysaatgt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BB%84%E5%AE%B6%E5%9C%A9%E8%B7%AF%E8%9E%8D%E5%88%9B%E7%B2%BE%E5%BD%A9%E5%A4%A9%E5%9C%B0 HTTP/1.1" 200 134
2018-04-12 12:30:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rcjctdaaxrj/>
{'lat': 32.09573605816086,
 'lng': 118.80169499478319,
 'location': '南京项目地址：黄家圩路融创精彩天地',
 'name': '融创精彩天地',
 'price': ' 350',
 'when': '2016-11-05'}
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E7%91%B6%E8%B7%AF7%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%89%9B%E9%A6%96%E5%B1%B1%E5%A4%A7%E9%81%93121%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfytaaycz/>
{'lat': 32.09198071246321,
 'lng': 118.65432397571688,
 'location': '南京项目地址：七瑶路7号',
 'name': '明发悦庭',
 'price': ' 18500',
 'when': '2017-09-16'}
2018-04-12 12:30:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rachsaahns/>
{'lat': 31.918954454210063,
 'lng': 118.75165574782486,
 'location': '南京项目地址：牛首山大道121号',
 'name': '瑞安翠湖山',
 'price': ' 20000',
 'when': '2018-04-03'}
2018-04-12 12:30:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E5%B1%B1%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E5%92%8C%E5%B1%B1 HTTP/1.1" 200 135
2018-04-12 12:30:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xcpyhsabezj/>
{'lat': 32.04095857741548,
 'lng': 118.85225558502222,
 'location': '南京项目地址：钟山路新城璞樾和山',
 'name': '新城璞樾和山',
 'price': ' 30000',
 'when': '2018-02-14'}
2018-04-12 12:30:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%8F%E5%B8%82%E8%A1%97%E9%81%93%E7%94%B5%E5%BB%BA%E4%B8%AD%E5%82%A8%E6%B3%9B%E6%82%A6%E5%9F%8E%E5%B8%82%E5%B9%BF%E5%9C%BA HTTP/1.1" 200 134
2018-04-12 12:30:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djzcfycsgcabfky/>
{'lat': 32.10631834473104,
 'lng': 118.796087672078,
 'location': '南京项目地址：小市街道电建中储泛悦城市广场',
 'name': '电建中储泛悦城市广场',
 'price': ' 35900',
 'when': '2017-12-28'}
2018-04-12 12:30:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%B4%E8%B4%A4%E8%B7%AF19%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:09 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.110827426049745,
 'lng': 118.84457333169928,
 'location': '南京项目地址：兴贤路19号',
 'name': '嘉誉山',
 'price': ' 29000',
 'when': '2017-07-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfxlsyaaedw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E4%BA%94%E8%B7%AF%E9%87%91%E6%B5%A6%E7%B4%AB%E5%BE%A1%E4%B8%9C%E6%96%B9 HTTP/1.1" 200 134
2018-04-12 12:30:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1312287642796,
 'lng': 118.84117460118358,
 'location': '南京项目地址：经五路金浦紫御东方',
 'name': '金浦紫御东方',
 'price': ' 28600',
 'when': '2017-11-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BB%93%E5%AE%B6%E5%B7%B7%E4%B8%87%E7%A7%91%E5%AE%89%E5%93%81%E5%9B%AD%E8%88%8D HTTP/1.1" 200 131
2018-04-12 12:30:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkapysaatgt/>
{'lat': 31.9649933148731,
 'lng': 118.76593279846456,
 'location': '南京项目地址：仓家巷万科安品园舍',
 'name': '万科安品园舍',
 'price': 0,
 'when': '2016-06-20'}
2018-04-12 12:30:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg21> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zgtjyxsaatpp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%B7%E5%8E%9A%E8%A1%9710%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.923030009156427,
 'lng': 118.78848868837916,
 'location': '南京项目地址：康厚街10号',
 'name': '九间堂',
 'price': ' 2200',
 'when': '2018-04-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%99%BD%E9%A9%AC%E8%B7%AF90%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dfxlsyaaedw/>
{'lat': 32.08732150414787,
 'lng': 118.63490312801513,
 'location': '南京项目地址：白马路90号',
 'name': '东方熙龙山院',
 'price': 0,
 'when': '2012-12-20'}
2018-04-12 12:30:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycjydfaauoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hynhycaakrk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg9> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djhfscaalag/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sybjbdaamiq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:30:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97169%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ycjydfaauoe/>
{'lat': 32.05156767640222,
 'lng': 118.89683388187007,
 'location': '南京项目地址：马群街169号',
 'name': '银城君颐东方',
 'price': ' 43000',
 'when': '2017-12-02'}
2018-04-12 12:30:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%92%8C%E7%87%95%E8%B7%AF%E8%91%9B%E6%B4%B2%E5%9D%9D%E6%8B%9B%E5%95%86%E7%B4%AB%E9%83%A1%E8%98%AD%E5%9B%AD HTTP/1.1" 200 132
2018-04-12 12:30:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E6%A1%A5%E5%8D%97%E8%B7%AF108%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1265750663835,
 'lng': 118.83957790985149,
 'location': '南京项目地址：和燕路葛洲坝招商紫郡蘭园',
 'name': '葛洲坝招商紫郡兰园',
 'price': 0,
 'when': '2017-10-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zgtjyxsaatpp/>
{'lat': 31.865478012062233,
 'lng': 118.61613434356234,
 'location': '南京项目地址：宁桥南路108号',
 'name': '中国铁建原香颂',
 'price': 0,
 'when': '2017-09-30'}
2018-04-12 12:30:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%A2%A8%E6%A0%91%E5%9B%AD%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.934076010618092,
 'lng': 118.9482089800879,
 'location': '南京项目地址：淳化街道梨树园路9号',
 'name': '万科金域东方',
 'price': ' 23800',
 'when': '2018-03-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hynxnzxaavzr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyzsgcxablwc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:30:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:30:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E9%AB%98%E8%B7%AF50%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:30:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hynhycaakrk/>
{'lat': 31.344984216195197,
 'lng': 118.92722832470832,
 'location': '南京项目地址：双高路50号',
 'name': '花样年花样城',
 'price': ' 8500',
 'when': '2017-12-06'}
2018-04-12 12:30:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdzxfhaatqu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg22> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E4%BA%94%E8%B7%AF%E7%94%B5%E5%BB%BA%E6%B5%B7%E8%B5%8B%E5%B0%9A%E5%9F%8E HTTP/1.1" 200 141
2018-04-12 12:30:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djhfscaalag/>
{'lat': 32.137634319277,
 'lng': 118.84295688872218,
 'location': '南京项目地址：经五路电建海赋尚城',
 'name': '电建海赋尚城',
 'price': ' 25800',
 'when': '2018-01-31'}
2018-04-12 12:30:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E4%B8%AD%E5%A4%AE%E5%8C%97%E8%B7%AF%E6%B2%B3%E8%B7%AF%E9%81%931%E5%8F%B7 HTTP/1.1" 200 134
2018-04-12 12:30:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1027477897518,
 'lng': 118.78834230949631,
 'location': '南京项目地址：鼓楼区中央北路河路道1号',
 'name': '花样年喜年中心',
 'price': ' 23000',
 'when': '2016-09-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yfltaacfl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yqszaatdm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdfchtaadlc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzscyfaapqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjgxtaasun/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rqgdyxaacoj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A2%A8%E6%A0%91%E5%9B%AD%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.934076010618092,
 'lng': 118.9482089800879,
 'location': '南京项目地址：梨树园路10号',
 'name': '弘阳禹洲时光春晓',
 'price': ' 23600',
 'when': '2018-01-10'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%86%E5%86%9B%E5%A4%A7%E9%81%93129%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:30:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.912818603145553,
 'lng': 118.79794097426038,
 'location': '南京项目地址：将军大道129号',
 'name': '雍福龙庭',
 'price': 0,
 'when': '2017-01-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E5%B1%B1%E8%A1%97%E9%81%93%E9%98%B3%E6%98%8E%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:30:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.059437385842024,
 'lng': 118.96418417578569,
 'location': '南京项目地址：汤山街道阳明路99号',
 'name': '云栖山庄',
 'price': 0,
 'when': '2016-09-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E4%B8%9C%E5%8D%97%E8%B7%AF%E9%87%91%E5%9C%B0%E4%B8%AD%E5%BF%83%E9%A3%8E%E5%8D%8E HTTP/1.1" 200 136
2018-04-12 12:30:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jdzxfhaatqu/>
{'lat': 31.981980257155737,
 'lng': 118.70237986022788,
 'location': '南京项目地址：江东南路金地中心风华',
 'name': '金地中心风华',
 'price': 0,
 'when': '2017-11-19'}
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_drylwaatss/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E9%A3%9E%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.104949086157944,
 'lng': 118.82824103380696,
 'location': '南京项目地址：华飞路1号',
 'name': '恒大翡翠华庭',
 'price': ' 32000',
 'when': '2017-07-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%9F%E8%B7%AF30%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%98%89%E4%B8%9A%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sybjbdaamiq/>
{'lat': 32.10314358339629,
 'lng': 118.74617782513008,
 'location': '南京项目地址：龙江路30号',
 'name': '深业滨江半岛',
 'price': ' 38700',
 'when': '2017-12-25'}
2018-04-12 12:30:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_drylwaatss/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：嘉业路8号',
 'name': '恒大悦澜湾',
 'price': ' 26500',
 'when': '2017-11-30'}
2018-04-12 12:30:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg23> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_shshyaacka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaazm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltxfaawiy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceke/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceki/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceke/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceki/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceku/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:30:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceku/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacene/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacene/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E8%8B%8F%E5%AE%81%E9%92%9F%E5%B1%B1%E6%9C%9D%E9%98%B3%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:30:18 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0913139891331,
 'lng': 118.89802397497581,
 'location': '南京项目地址：玄武大道苏宁钟山朝阳府',
 'name': '苏宁钟山朝阳府',
 'price': 0,
 'when': '2016-05-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg24> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceme/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceme/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:30:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:30:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E9%95%87%E5%81%87%E6%97%A5%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_shshyaacka/>
{'lat': 32.09294316228797,
 'lng': 118.52460713295669,
 'location': '南京项目地址：汤泉镇假日路8号',
 'name': '山河水花园',
 'price': ' 25000',
 'when': '2014-04-30'}
2018-04-12 12:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zyhfaaxbt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsylaatbk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mdjyslaadxi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacens/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%8C%E6%B1%9F%E6%95%85%E5%B1%85%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:30:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aaazm/>
{'lat': 31.865264410601366,
 'lng': 118.47517450362449,
 'location': '南京项目地址：乌江故居路8号',
 'name': '江岸景城',
 'price': ' 15000',
 'when': '2015-02-08'}
2018-04-12 12:30:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacens/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceod/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceph/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceod/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceph/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:20 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcaccii/>: HTTP status code is not handled or not allowed
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E4%B8%AD%E5%BB%BA%E5%9B%BD%E7%86%99%E5%8F%B0 HTTP/1.1" 200 142
2018-04-12 12:30:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.06590199137902,
 'lng': 118.65369290890968,
 'location': '南京项目地址：新浦路中建国熙台',
 'name': '中建国熙台',
 'price': 0,
 'when': '2017-12-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg25> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%B7%E9%99%A2%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08509008337853,
 'lng': 118.63412696869857,
 'location': '南京项目地址：海院路88号',
 'name': '融侨观邸',
 'price': ' 25500',
 'when': '2017-07-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg3> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcxylsaaccp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E7%86%9F%E8%A1%97%E9%81%93%E6%B6%A6%E6%B9%96%E5%A4%A7%E9%81%93398%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ltxfaawiy/>
{'lat': 31.873594814596018,
 'lng': 118.97674222511495,
 'location': '南京项目地址：湖熟街道润湖大道398号',
 'name': '梁台煦府',
 'price': 0,
 'when': '2016-12-10'}
2018-04-12 12:30:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%BE%E6%9D%A8%E8%B7%AF%E7%B4%AB%E8%89%BA%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 136
2018-04-12 12:30:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zyhfaaxbt/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：松杨路紫艺华府',
 'name': '紫艺华府',
 'price': 0,
 'when': '2018-01-19'}
2018-04-12 12:30:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceri/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%AC%E5%9C%B0%E8%B7%AF%E6%96%B0%E5%9F%8E%E9%A6%99%E6%82%A6%E6%BE%9C%E5%B1%B1 HTTP/1.1" 200 140
2018-04-12 12:30:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.131600315832,
 'lng': 118.9822212970358,
 'location': '南京项目地址：纬地路新城香悦澜山',
 'name': '新城香悦澜山',
 'price': 0,
 'when': '2017-04-10'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlysjaabvt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceri/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smcpaawml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltllxzaavtr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg26> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacera/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacera/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceor/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceos/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:30:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E7%87%95%E4%B8%9C%E8%B7%AF%E6%8B%9B%E5%95%861872%E5%85%AC%E5%9B%AD%E9%87%8C HTTP/1.1" 200 132
2018-04-12 12:30:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zsylaatbk/>
{'lat': 32.1265750663835,
 'lng': 118.83957790985149,
 'location': '南京项目地址：钟燕东路招商1872公园里',
 'name': '招商1872公园里',
 'price': 0,
 'when': '2017-03-08'}
2018-04-12 12:30:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceor/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceos/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BB%84%E5%B1%B1%E5%B2%AD%E8%B7%AF%E4%B9%9D%E6%9C%88%E6%A3%AE%E6%9E%97 HTTP/1.1" 200 143
2018-04-12 12:30:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mdjyslaadxi/>
{'lat': 32.08342667185487,
 'lng': 118.62232126700839,
 'location': '南京项目地址：黄山岭路九月森林',
 'name': '九月森林',
 'price': 0,
 'when': '2018-03-24'}
2018-04-12 12:30:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:30:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg10> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:30:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjmyaawmp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hymdaatgo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg11> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jrcfslaaudc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%85%89%E8%B7%AF67%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:25 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0310141948896,
 'lng': 118.81408773463262,
 'location': '南京项目地址：大光路67号',
 'name': '金陵雅颂居',
 'price': 0,
 'when': '2016-08-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hrxytdaatbu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:30:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:30:25 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:30:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg27> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:30:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcaceog/>: HTTP status code is not handled or not allowed
2018-04-12 12:30:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:30:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg28> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8F%8C%E8%B7%AF%E4%B8%96%E8%8C%82%E5%9F%8E%E5%93%81 HTTP/1.1" 200 145
2018-04-12 12:30:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97666251592093,
 'lng': 118.76671169042649,
 'location': '南京项目地址：宁双路世茂城品',
 'name': '世茂城品',
 'price': 0,
 'when': '2017-06-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%95%E5%BA%9C%E4%B8%9C%E8%B7%AF228%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjmyaawmp/>
{'lat': 32.12191964138096,
 'lng': 118.81329580556283,
 'location': '南京项目地址：幕府东路228号',
 'name': '紫金铭苑',
 'price': 0,
 'when': '2017-07-24'}
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smmxjaakrd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dhjxhcxymsaavuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:30:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E5%8D%97%E8%B7%AF688%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.915202323802344,
 'lng': 118.86477525813511,
 'location': '南京项目地址：秣陵街道竹山南路688号',
 'name': '罗托鲁拉小镇',
 'price': 0,
 'when': '2017-11-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg4> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytaaava/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sfssaaqqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdhfaaelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjybjgjaagoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jyzjfaagmw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwqlnhyaaaux/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:30:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:30:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:30:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacete/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:30:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacete/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9C%88%E5%AE%89%E8%A1%9711%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hymdaatgo/>
{'lat': 32.02460861962323,
 'lng': 118.74210601897207,
 'location': '南京项目地址：月安街11号',
 'name': '海玥名都',
 'price': 0,
 'when': '2017-04-21'}
2018-04-12 12:30:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%80%E8%A1%977%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.02198720429714,
 'lng': 118.76589413719202,
 'location': '南京项目地址：所街7号',
 'name': '华润新悦天地',
 'price': 0,
 'when': '2016-08-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:30:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg29> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:30:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceta/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:30:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:30:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceta/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:30:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg30> (referer: https://nj.fang.lianjia.com/loupan/pg/pg29)
2018-04-12 12:30:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:30:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:30:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceso/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:30:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceso/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%90%89%E5%B1%B1%E5%A4%A7%E9%81%939%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jrcfslaaudc/>
{'lat': 31.861380358744533,
 'lng': 118.77282264452263,
 'location': '南京项目地址：吉山大道9号',
 'name': '景瑞春风十里',
 'price': ' 19000',
 'when': '2017-06-06'}
2018-04-12 12:30:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sclfaakub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E6%A1%A5%E5%8C%97%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:30:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/>
{'lat': 32.01816879567414,
 'lng': 118.74715685147487,
 'location': '南京项目地址：大桥北路9号',
 'name': '弘阳印象华庭',
 'price': 0,
 'when': '2017-03-01'}
2018-04-12 12:30:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacers/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E8%83%A1%E6%A1%A5%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:32 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：江浦街道胡桥路9号',
 'name': '明发云庭',
 'price': 0,
 'when': '2018-02-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacers/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceth/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceth/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg31> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceul/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceul/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg32> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceue/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:30:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceue/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceva/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceva/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E7%91%9E%E6%96%87%E8%B7%AF199%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smmxjaakrd/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：淳化街道瑞文路199号',
 'name': '世茂梦享家',
 'price': 0,
 'when': '2016-04-30'}
2018-04-12 12:30:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E8%A1%97%E9%81%93%E5%B0%9A%E5%B3%B0%E5%B0%9A%E6%B0%B4 HTTP/1.1" 200 139
2018-04-12 12:30:34 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.097852651559236,
 'lng': 118.51451267002572,
 'location': '南京项目地址：汤泉街道尚峰尚水',
 'name': '尚峰尚水',
 'price': ' 500',
 'when': '2017-04-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceud/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceud/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:30:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:30:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:30:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dhjxhcxymsaavuz/>
{'lat': 32.123523391191696,
 'lng': 118.72947850536069,
 'location': '南京项目地址：浦珠北路59号',
 'name': '大华锦绣华城香鸢美颂',
 'price': ' 24600',
 'when': '2017-11-25'}
2018-04-12 12:30:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znjyaaksn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E5%8F%B0%E5%8C%BA%E8%B5%9B%E8%99%B9%E6%A1%A5%E8%A1%97%E9%81%93 HTTP/1.1" 200 139
2018-04-12 12:30:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99525360625542,
 'lng': 118.76410088763129,
 'location': '南京项目地址：雨花台区赛虹桥街道',
 'name': '恒大华府',
 'price': 0,
 'when': '2017-02-13'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacews/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E6%B5%A6%E8%B7%AF96%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.068138157816925,
 'lng': 118.67819018794667,
 'location': '南京项目地址：天浦路96号',
 'name': '雅居乐滨江国际',
 'price': ' 28000',
 'when': '2017-11-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacews/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%9C%B0%E9%93%81%E4%BA%8C%E5%8F%B7%E7%BA%BF%E5%A4%A9%E8%BF%88%E5%B9%BF%E5%9C%BA%E6%B2%B9%E5%9D%8A%E6%A1%A5%E7%AB%99 HTTP/1.1" 200 139
2018-04-12 12:30:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sclfaakub/>
{'lat': 31.971841104007034,
 'lng': 118.72764980327469,
 'location': '南京项目地址：建邺地铁二号线天迈广场油坊桥站',
 'name': '首创立方',
 'price': ' 20000',
 'when': '2016-04-01'}
2018-04-12 12:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_mfptmhjaaqjj/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wycaakob/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_fhhrdxaaclk/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_xhycbmlsaakqw/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_heshyhggaakok/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_htygjczgcaakog/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:30:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B3%B0%E5%B1%B1%E8%B7%AF%E9%87%91%E9%9A%85%E7%B4%AB%E9%87%91%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:30:38 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99647068073844,
 'lng': 118.74219268227752,
 'location': '南京项目地址：泰山路金隅紫金府',
 'name': '金隅紫京府',
 'price': ' 643',
 'when': '2017-12-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8D%8E%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:30:38 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.31827364260565,
 'lng': 118.81844075425253,
 'location': '南京项目地址：龙池街道龙华路66号',
 'name': '骋望七里楠花园',
 'price': 0,
 'when': '2016-08-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_gkrjeqaatpa/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:30:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_cwydaaasz/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:30:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg5> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:30:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dsljaayua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:30:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrxhmdaatqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:30:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BD%AF%E4%BB%B6%E5%A4%A7%E9%81%93%E4%B8%AD%E5%8D%97%E9%94%A6%E8%8B%91 HTTP/1.1" 200 144
2018-04-12 12:30:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_znjyaaksn/>
{'lat': 31.984256699458975,
 'lng': 118.75651496529456,
 'location': '南京项目地址：软件大道中南锦苑',
 'name': '中南锦苑',
 'price': 0,
 'when': '2016-09-03'}
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg12> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aadlk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltllxzaacjt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyfqsaaaclf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkysjaalru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_attycaadid/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%AF%E9%99%B5%E8%B7%AF7%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aadlk/>
{'lat': 32.08813762841439,
 'lng': 118.87777963354526,
 'location': '南京项目地址：环陵路7号',
 'name': '钟山国际高尔夫',
 'price': 0,
 'when': '2013-06-01'}
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lsqcjqaacmb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E5%8D%97%E8%B7%AF688%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ltllxzaacjt/>
{'lat': 31.915202323802344,
 'lng': 118.86477525813511,
 'location': '南京项目地址：秣陵街道竹山南路688号',
 'name': '罗托鲁拉小镇',
 'price': 0,
 'when': '2016-04-30'}
2018-04-12 12:30:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%8E%B1%E8%8C%B5%E8%BE%BE%E8%B7%AF12%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.950984236736673,
 'lng': 118.86091033640727,
 'location': '南京项目地址：莱茵达路12号',
 'name': '都市丽景',
 'price': 0,
 'when': '2017-01-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhsyhaalja/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfzjgjaarco/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjjcyxaabaj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rqycaawis/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njbgyaaldy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yztaadtx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:30:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blxjyaabaz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:30:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%A1%AB%E6%B9%96%E4%B8%9C%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xyfqsaaaclf/>
{'lat': 31.947722743322984,
 'lng': 118.88189242724522,
 'location': '南京项目地址：衫湖东路18号',
 'name': '星叶枫情水岸',
 'price': 0,
 'when': '2015-03-06'}
2018-04-12 12:30:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E5%85%83%E8%B7%AF%E4%B8%AD%E8%B7%AF128%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04694030889066,
 'lng': 118.80071471620052,
 'location': '南京项目地址：天元路中路128号',
 'name': '中锐星湖名邸',
 'price': 0,
 'when': '2017-04-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mlysaaawr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:30:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E7%81%B5%E8%A1%9750%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:30:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkysjaalru/>
{'lat': 32.044111682631645,
 'lng': 118.87556409864904,
 'location': '南京项目地址：钟灵街50号',
 'name': '五矿晏山居',
 'price': 0,
 'when': '2017-07-14'}
2018-04-12 12:30:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E6%BA%AA%E8%A1%97%E9%81%93%E7%94%98%E6%B3%89%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.759965542424297,
 'lng': 118.72924045440054,
 'location': '南京项目地址：横溪街道甘泉湖路1号',
 'name': '中浩山屿湖',
 'price': 0,
 'when': '2017-06-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A6%E6%B7%AE%E5%A4%A7%E9%81%93399%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_attycaadid/>
{'lat': 31.645263048037307,
 'lng': 119.0541065336066,
 'location': '南京项目地址：秦淮大道399号',
 'name': '爱涛天岳城',
 'price': 0,
 'when': '2018-01-08'}
2018-04-12 12:30:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhjyaadjj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hjfhsaahno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fdyzsyxaampu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BC%A0%E6%95%A6%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:46 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：张敦路59号',
 'name': '明发珠江国际',
 'price': ' 27800',
 'when': '2016-04-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%A5%E5%87%A4%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lsqcjqaacmb/>
{'lat': 31.78379644297444,
 'lng': 118.86052299785104,
 'location': '南京项目地址：来凤路18号',
 'name': '朗诗青春街区',
 'price': 0,
 'when': '2017-11-30'}
2018-04-12 12:30:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:30:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:46 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05876455593678,
 'lng': 118.62066377476616,
 'location': '南京项目地址：雨山西路89号',
 'name': '北江锦城',
 'price': ' 24300',
 'when': '2017-11-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E6%B9%96%E8%B7%AF100%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhjyaadjj/>
{'lat': 31.696231584053706,
 'lng': 119.11840755372283,
 'location': '南京项目地址：金湖路100号',
 'name': '金湖家园',
 'price': 0,
 'when': '2011-08-18'}
2018-04-12 12:30:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E4%B8%87%E5%AE%89%E5%8D%97%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:48 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.962191115716916,
 'lng': 118.88690470266143,
 'location': '南京项目地址：东山街道万安南路9号',
 'name': '融侨悦城',
 'price': 0,
 'when': '2018-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E9%9C%9E%E6%96%87%E9%BC%8E%E8%B7%AF1%E5%8F%B7%EF%BC%88%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E4%B8%8E%E5%AD%A6%E6%9E%97%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:30:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hjfhsaahno/>
{'lat': 32.11865857092845,
 'lng': 118.91214765162765,
 'location': '南京项目地址：栖霞文鼎路1号（玄武大道与学林路交汇处）',
 'name': '恒基富荟山',
 'price': 0,
 'when': '2014-10-30'}
2018-04-12 12:30:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E9%A9%AC%E7%BE%A4%E8%A1%972%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_fdyzsyxaampu/>
{'lat': 32.05578425340213,
 'lng': 118.89966428083703,
 'location': '南京项目地址：马群街道马群街2号',
 'name': '复地御钟山二期',
 'price': 0,
 'when': '2014-07-19'}
2018-04-12 12:30:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htygjczgcaakog/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_heshyhggaakok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xhycbmlsaakqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%91%A1%E5%9B%AD%E8%B7%AF%E4%BB%81%E6%81%92%E7%BB%BF%E6%B4%B2%E6%96%B0%E5%B2%9B HTTP/1.1" 200 143
2018-04-12 12:30:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/>
{'lat': 32.03377176667957,
 'lng': 118.70845022618616,
 'location': '南京项目地址：葡园路仁恒绿洲新岛',
 'name': '仁恒绿洲新岛',
 'price': 0,
 'when': '2017-11-19'}
2018-04-12 12:30:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%89%9B%E9%A6%96%E5%A4%A7%E9%81%93%E5%BA%86%E5%85%B4%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:50 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.886978323966712,
 'lng': 118.71252324038538,
 'location': '南京项目地址：牛首大道庆兴路8号',
 'name': '南京碧桂园',
 'price': 0,
 'when': '2017-09-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E6%B7%B3%E6%BA%AA%E9%95%87%E5%AE%9D%E5%A1%94%E8%B7%AF269%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_htygjczgcaakog/>
{'lat': 31.33618242769404,
 'lng': 118.9089895903361,
 'location': '南京项目地址：高淳淳溪镇宝塔路269号',
 'name': '红太阳国际财智广场',
 'price': 0,
 'when': '2016-04-10'}
2018-04-12 12:30:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_heshyhggaakok/>
{'lat': 31.393150940897428,
 'lng': 118.97196008794114,
 'location': '南京项目地址：双湖路1号',
 'name': '海尔双湖壹号公馆',
 'price': ' 8300',
 'when': '2017-09-27'}
2018-04-12 12:30:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E7%99%BD%E9%A9%AC%E8%B7%AF%E4%B8%8E%E7%8B%AE%E5%B1%B1%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:30:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xhycbmlsaakqw/>
{'lat': 32.08258412514195,
 'lng': 118.63632209768683,
 'location': '南京项目地址：浦口区白马路与狮山路交汇处',
 'name': '旭辉银城白马澜山',
 'price': 0,
 'when': '2017-12-25'}
2018-04-12 12:30:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfptmhjaaqjj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wycaakob/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg13> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:30:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fhhrdxaaclk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:30:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%87%A4%E6%B1%87%E5%A4%A7%E9%81%93%E6%98%8E%E5%8F%91%E6%B5%A6%E6%B3%B0%E6%A2%A6%E5%B9%BB%E5%AE%B6 HTTP/1.1" 200 143
2018-04-12 12:30:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfptmhjaaqjj/>
{'lat': 31.92740779796182,
 'lng': 118.64778341958687,
 'location': '南京项目地址：凤汇大道明发浦泰梦幻家',
 'name': '明发浦泰梦幻家',
 'price': 0,
 'when': '2017-09-05'}
2018-04-12 12:30:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%9D%E9%BE%99%E5%B1%B1%E8%B7%AF%E4%B8%87%E6%82%A6%E5%9F%8E HTTP/1.1" 200 143
2018-04-12 12:30:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wycaakob/>
{'lat': 31.369820090663627,
 'lng': 118.95197910453356,
 'location': '南京项目地址：九龙山路万悦城',
 'name': '万悦城',
 'price': 0,
 'when': '2017-05-03'}
2018-04-12 12:30:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E5%B9%B3%E5%8D%97%E8%B7%AF%E4%B8%8E%E7%99%BD%E4%B8%8B%E8%B7%AF%E4%BA%A4%E7%95%8C%E5%A4%84 HTTP/1.1" 200 136
2018-04-12 12:30:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_fhhrdxaaclk/>
{'lat': 32.03553521855789,
 'lng': 118.79736364858033,
 'location': '南京项目地址：太平南路与白下路交界处',
 'name': '凤凰和睿大厦',
 'price': ' 22000',
 'when': '时间待定'}
2018-04-12 12:30:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycyfsaaftx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:30:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xwhjmgcaadxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:30:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%86%E5%86%9B%E5%A4%A7%E9%81%93%E9%9F%A9%E5%BA%9C%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.94294979560223,
 'lng': 118.78826271962814,
 'location': '南京项目地址：将军大道韩府路18号',
 'name': '滟紫台',
 'price': 0,
 'when': '2014-10-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E5%90%89%E5%8D%B0%E5%A4%A7%E9%81%934199%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ycyfsaaftx/>
{'lat': 31.878871395291938,
 'lng': 118.78266735426757,
 'location': '南京项目地址：江宁区淳化街道吉印大道4199号',
 'name': '银城一方山',
 'price': 0,
 'when': '2016-01-01'}
2018-04-12 12:30:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwyhcaadvo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:30:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycyfsaafsp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:30:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aafrg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:30:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ssyfhyyxaafss/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:30:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrrjcaaeov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:30:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tzyyxaafsh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:30:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%AE%E8%B7%AF201%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:30:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xwhjmgcaadxy/>
{'lat': 32.07904243541421,
 'lng': 118.78987490852688,
 'location': '南京项目地址：中央路201号',
 'name': '玄武湖金茂广场御景华府',
 'price': 0,
 'when': '2009-11-01'}
2018-04-12 12:30:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9B%A2%E5%B1%B1%E8%A5%BF%E8%B7%AF26%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cwyhcaadvo/>
{'lat': 31.69267717506764,
 'lng': 119.0207176406826,
 'location': '南京项目地址：团山西路26号',
 'name': '创维乐活城',
 'price': ' 6800',
 'when': '2017-09-29'}
2018-04-12 12:30:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E5%90%89%E5%8D%B0%E5%A4%A7%E9%81%934199%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ycyfsaafsp/>
{'lat': 31.878871395291938,
 'lng': 118.78266735426757,
 'location': '南京项目地址：江宁区淳化街道吉印大道4199号',
 'name': '银城一方山',
 'price': 0,
 'when': '2015-11-13'}
2018-04-12 12:30:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9F%8E%E5%8D%97%E6%B2%B3%E8%B7%AF%E4%BF%9D%E5%88%A9%E8%A5%BF%E6%B1%9F%E6%9C%88 HTTP/1.1" 200 141
2018-04-12 12:30:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04810818480485,
 'lng': 118.66452157400175,
 'location': '南京项目地址：城南河路保利西江月',
 'name': '保利西江月',
 'price': 0,
 'when': '2017-05-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_zjhfaafcw/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:30:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_blzygyaaavy/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:30:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jlhbskpaaeco/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:30:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:30:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_cwydaaasz/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:30:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_gkrjeqaatpa/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:30:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rshfaatdn/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:30:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_smzsysaakkg/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:30:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg33> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:30:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg33> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:30:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E5%87%A4%E6%BB%A8%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aafrg/>
{'lat': 32.207695799701774,
 'lng': 118.74507388427848,
 'location': '南京项目地址：大厂凤滨路18号',
 'name': '福基九龙新城',
 'price': 0,
 'when': '2011-05-06'}
2018-04-12 12:30:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%A8%E6%BA%AA%E5%A4%A7%E9%81%931000%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:30:57 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滨溪大道1000号',
 'name': '牧龙原墅',
 'price': ' 23000',
 'when': '2015-04-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:30:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zlxyaatbm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:30:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rshfaatdn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:30:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smzsysaakkg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:30:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg34> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg35> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:30:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF126%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:30:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ssyfhyyxaafss/>
{'lat': 32.11862130443328,
 'lng': 118.70782125782063,
 'location': '南京项目地址：浦珠北路126号',
 'name': '山水云房花园',
 'price': ' 23000',
 'when': '2017-05-22'}
2018-04-12 12:30:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:30:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacext/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:30:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacext/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:30:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:30:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgydxyxabrtv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:30:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:30:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfbzxcabmjd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:30:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:31:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E9%B9%8F%E5%B1%B1%E8%B7%AF28%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:00 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.924654849950382,
 'lng': 118.90626134667176,
 'location': '南京项目地址：淳化街道鹏山路28号',
 'name': '中粮祥云',
 'price': 0,
 'when': '2016-11-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdljaatpb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:31:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rshycaaksj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:31:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lyzyaarxs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:31:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lntsyaatqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:31:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:31:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E6%A1%A5%E8%A5%BF%E8%B7%AF162%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:00 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.33635869765098,
 'lng': 118.84812434355814,
 'location': '南京项目地址：雄州街道桥西路162号',
 'name': '荣盛华府',
 'price': 0,
 'when': '2017-07-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E9%A9%AC%E8%B7%AF%E4%B8%96%E8%8C%82%E6%8B%9B%E5%95%86%E8%AF%AD%E5%B1%B1 HTTP/1.1" 200 143
2018-04-12 12:31:00 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.07140443035624,
 'lng': 118.91366956082265,
 'location': '南京项目地址：金马路世茂招商语山',
 'name': '世茂招商语山',
 'price': 0,
 'when': '2016-10-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg6> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:31:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%95%87%E5%8D%97%E6%B2%B3%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zrrjcaaeov/>
{'lat': 32.06209076570978,
 'lng': 118.68209046428447,
 'location': '南京项目地址：镇南河路99号',
 'name': '正荣润江城',
 'price': 0,
 'when': '2017-07-05'}
2018-04-12 12:31:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E8%B7%AF588%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tzyyxaafsh/>
{'lat': 31.92671560623449,
 'lng': 118.85742595575786,
 'location': '南京项目地址：江宁区秣陵街道竹山路588号',
 'name': '天泽苑',
 'price': ' 28000',
 'when': '2018-02-03'}
2018-04-12 12:31:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyascaapvm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:31:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aafrw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:31:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A6%E5%B1%B1%E8%A1%97%E9%81%93123%E5%9C%B0%E5%9D%97 HTTP/1.1" 200 136
2018-04-12 12:31:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyascaapvm/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：秦山街道123地块',
 'name': '弘阳爱上城',
 'price': 0,
 'when': '2015-11-20'}
2018-04-12 12:31:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: HousePriceNJ)
2018-04-12 12:31:01 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.3.1, w3lib 1.18.0, Twisted 17.9.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-38-generic-x86_64-with-Ubuntu-16.04-xenial
2018-04-12 12:31:01 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'HousePriceNJ.spiders', 'BOT_NAME': 'HousePriceNJ', 'FEED_EXPORT_ENCODING': 'utf-8', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['HousePriceNJ.spiders']}
2018-04-12 12:31:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-04-12 12:31:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-04-12 12:31:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-04-12 12:31:01 [scrapy.middleware] INFO: Enabled item pipelines:
['HousePriceNJ.pipelines.HousepricenjPipeline']
2018-04-12 12:31:01 [scrapy.core.engine] INFO: Spider opened
2018-04-12 12:31:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:31:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6027
2018-04-12 12:31:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%A4%A7%E9%81%938%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgydxyxabrtv/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华大道8号',
 'name': '碧桂园大学印象',
 'price': ' 16000',
 'when': '2017-11-11'}
2018-04-12 12:31:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ylfablzi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:31:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhysabqwl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:31:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smrlaarsf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:02 [scrapy.extensions.logstats] INFO: Crawled 330 pages (at 157 pages/min), scraped 165 items (at 15 items/min)
2018-04-12 12:31:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%95%BF%E6%B1%9F%E8%B7%AF%E8%A5%BF%E4%BE%A7%E6%98%8E%E5%8F%91%E5%8C%97%E7%AB%99%E6%96%B0%E5%9F%8E HTTP/1.1" 200 135
2018-04-12 12:31:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfbzxcabmjd/>
{'lat': 32.04955537268256,
 'lng': 118.8014603106721,
 'location': '南京项目地址：长江路西侧明发北站新城',
 'name': '明发北站新城',
 'price': 0,
 'when': '2017-11-22'}
2018-04-12 12:31:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B3%B0%E5%B1%B1%E8%A5%BF%E8%B7%AF%E5%BE%A1%E6%BE%9C%E5%BA%9C HTTP/1.1" 200 135
2018-04-12 12:31:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ylfablzi/>
{'lat': 32.15139493848411,
 'lng': 118.71872790211911,
 'location': '南京项目地址：泰山西路御澜府',
 'name': '御澜府',
 'price': ' 25800',
 'when': '2017-11-08'}
2018-04-12 12:31:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E6%B9%96%E8%A1%97%E9%81%93%E9%80%9A%E6%B2%B3%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhysabqwl/>
{'lat': 32.45045312201094,
 'lng': 118.94784796098479,
 'location': '南京项目地址：金牛湖街道通河路9号',
 'name': '嘉恒有山',
 'price': ' 13500',
 'when': '2017-12-16'}
2018-04-12 12:31:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%92%E9%BA%9F%E8%A1%97%E9%81%93%E8%A2%81%E5%AE%B6%E8%BE%B9%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:02 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.02524213109228,
 'lng': 118.92961737976174,
 'location': '南京项目地址：麒麟街道袁家边路9号',
 'name': '恒大龙珺',
 'price': 0,
 'when': '2017-07-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%87%A4%E9%9B%86%E5%A4%A7%E9%81%936%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aafrw/>
{'lat': 31.93439038369555,
 'lng': 118.66586279443327,
 'location': '南京项目地址：凤集大道6号',
 'name': '石林大公园',
 'price': 0,
 'when': '2012-08-08'}
2018-04-12 12:31:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdyhfdaaavg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:31:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaadt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:31:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg14> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:31:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cjfjaaazu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:31:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jzycsgcaachb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:31:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wdmaacfw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:31:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yclxjaaces/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:31:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyyjwaacdv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:31:03 [scrapy.extensions.logstats] INFO: Crawled 132 pages (at 58 pages/min), scraped 110 items (at 50 items/min)
2018-04-12 12:31:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E7%94%B5%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdyhfdaaavg/>
{'lat': 32.107868121583785,
 'lng': 118.81988199561275,
 'location': '南京项目地址：华电路1号',
 'name': '中电颐和府邸',
 'price': 0,
 'when': '2017-12-26'}
2018-04-12 12:31:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:04 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://nj.fang.lianjia.com/robots.txt> (referer: None)
2018-04-12 12:31:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%87%E6%99%AF%E5%8C%97%E8%B7%AF%E4%BF%9D%E5%88%A9%E5%A0%82%E6%82%A6 HTTP/1.1" 200 143
2018-04-12 12:31:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aaadt/>
{'lat': 31.987086765521944,
 'lng': 118.81312602132991,
 'location': '南京项目地址：汇景北路保利堂悦',
 'name': '保利堂悦',
 'price': 0,
 'when': '2017-01-18'}
2018-04-12 12:31:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg1> (referer: None)
2018-04-12 12:31:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E8%B7%AF%E8%8D%A3%E9%87%8C HTTP/1.1" 200 135
2018-04-12 12:31:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smrlaarsf/>
{'lat': 32.13159618531885,
 'lng': 118.73518389787502,
 'location': '南京项目地址：浦珠路荣里',
 'name': '世茂荣里',
 'price': 0,
 'when': '2018-03-28'}
2018-04-12 12:31:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xycabkna/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:04 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-04-12 12:31:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smcpabovv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hqcfctyabooo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%9F%E7%81%AB%E8%B7%AF%E6%98%9F%E6%82%A6%E5%9F%8E HTTP/1.1" 200 136
2018-04-12 12:31:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xycabkna/>
{'lat': 32.16673496276866,
 'lng': 118.70268689027152,
 'location': '南京项目地址：星火路星悦城',
 'name': '星悦城',
 'price': ' 16000',
 'when': '2018-02-24'}
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E6%9E%97%E5%9C%BA%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.32446249240832,
 'lng': 118.85133622323109,
 'location': '南京项目地址：龙池街道林场路1号',
 'name': '荣盛花语城',
 'price': 0,
 'when': '2017-08-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8F%8C%E8%B7%AF%E4%B8%96%E8%8C%82%E5%9F%8E%E5%93%81 HTTP/1.1" 200 145
2018-04-12 12:31:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smcpabovv/>
{'lat': 31.97666251592093,
 'lng': 118.76671169042649,
 'location': '南京项目地址：宁双路世茂城品',
 'name': '世茂城品',
 'price': ' 37000',
 'when': '2018-02-01'}
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05876455593678,
 'lng': 118.62066377476616,
 'location': '南京项目地址：雨山西路89号',
 'name': '路易庄园',
 'price': ' 25000',
 'when': '2018-01-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg2> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B7%A5%E5%86%9C%E8%B7%AF%E5%92%8C%E7%96%8F%E6%B8%AF%E5%A4%A7%E9%81%93%E4%BA%A4%E6%B1%87%E5%A4%84%E5%8D%8E%E4%BE%A8%E5%9F%8E%E7%BF%A1%E7%BF%A0%E5%A4%A9%E5%9F%9F HTTP/1.1" 200 135
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%BC%E8%87%B4%E8%A5%BF%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hqcfctyabooo/>
{'lat': 32.14946210342667,
 'lng': 118.9979559714333,
 'location': '南京项目地址：工农路和疏港大道交汇处华侨城翡翠天域',
 'name': '华侨城翡翠天域',
 'price': ' 25500',
 'when': '2018-03-31'}
2018-04-12 12:31:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：格致西路1号',
 'name': '鲁能泰山7号院',
 'price': 0,
 'when': '2017-07-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg36> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcznyyabnqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjllycabmje/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:31:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_slhjzxabiuf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jysaatdp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jpzydfaatdk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%B4%E8%B4%A4%E8%B7%AF19%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.110827426049745,
 'lng': 118.84457333169928,
 'location': '南京项目地址：兴贤路19号',
 'name': '嘉誉山',
 'price': ' 29000',
 'when': '2017-07-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hynxnzxaavzr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdjjtaadjb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyzsgcxablwc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A5%94%E9%A9%AC%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E9%92%9F%E5%B1%B1 HTTP/1.1" 200 136
2018-04-12 12:31:06 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08330568277308,
 'lng': 118.91771165983776,
 'location': '南京项目地址：奔马路新城璞樾钟山',
 'name': '新城璞樾钟山',
 'price': 0,
 'when': '2017-12-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E5%8C%97%E8%B7%AF645%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cjfjaaazu/>
{'lat': 32.09263358876117,
 'lng': 118.74039547747762,
 'location': '南京项目地址：中山北路645号',
 'name': '长江峰景',
 'price': 0,
 'when': '2010-12-30'}
2018-04-12 12:31:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%A7%E9%BE%99%E6%B9%96%E5%A4%A7%E9%81%931%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:07 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.731203746093776,
 'lng': 119.0553388291052,
 'location': '南京项目地址：卧龙湖大道1号',
 'name': '卧龙湖小镇',
 'price': ' 13500',
 'when': '2018-02-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlhbskpaaeco/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:31:07 [scrapy.extensions.logstats] INFO: Crawled 53 pages (at 53 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:31:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E6%B8%85%E6%B0%B4%E4%BA%AD%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:07 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.919765529265728,
 'lng': 118.81406744370776,
 'location': '南京项目地址：秣陵街道清水亭西路188号',
 'name': '九龙湖别墅',
 'price': 0,
 'when': '2016-11-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B4%E9%98%B3%E6%B1%9F%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rcznyyabnqr/>
{'lat': 31.341189718000248,
 'lng': 118.91511603391415,
 'location': '南京项目地址：水阳江路99号',
 'name': '融创中南御园',
 'price': ' 11000',
 'when': '2018-01-02'}
2018-04-12 12:31:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxlshslaasuo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdqsyjabirk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxhfaarwx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcjxthyabmmo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:31:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_undefinedaaqhr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:31:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg7> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwydaaasz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blzygyaaavy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E4%BA%94%E8%B7%AF%E9%87%91%E6%B5%A6%E7%B4%AB%E5%BE%A1%E4%B8%9C%E6%96%B9 HTTP/1.1" 200 134
2018-04-12 12:31:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1312287642796,
 'lng': 118.84117460118358,
 'location': '南京项目地址：经五路金浦紫御东方',
 'name': '金浦紫御东方',
 'price': ' 28600',
 'when': '2017-11-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjeqaatpa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rczyaarxa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjydfabjyv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcylggaatbq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%B9%A4%E9%B8%A3%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10341702868925,
 'lng': 118.90268150938394,
 'location': '南京项目地址：鹤鸣路68号',
 'name': '骋望云邸',
 'price': 0,
 'when': '2015-12-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjhfaafcw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E4%B8%AD%E5%A4%AE%E5%8C%97%E8%B7%AF%E6%B2%B3%E8%B7%AF%E9%81%931%E5%8F%B7 HTTP/1.1" 200 134
2018-04-12 12:31:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1027477897518,
 'lng': 118.78834230949631,
 'location': '南京项目地址：鼓楼区中央北路河路道1号',
 'name': '花样年喜年中心',
 'price': ' 23000',
 'when': '2016-09-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E6%B8%85%E8%B7%AF%E4%BD%B3%E5%85%86%E4%B8%9A%E5%9F%8E%E5%B8%82%E5%B9%BF%E5%9C%BA HTTP/1.1" 200 144
2018-04-12 12:31:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jzycsgcaachb/>
{'lat': 31.975496662881305,
 'lng': 118.71114275142682,
 'location': '南京项目地址：太清路佳兆业城市广场',
 'name': '佳兆业城市广场',
 'price': ' 300',
 'when': '2017-11-19'}
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%95%BF%E4%BA%AD%E8%A1%9759%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.914770739009395,
 'lng': 118.83304208150336,
 'location': '南京项目地址：秣陵街道长亭街59号',
 'name': '保利中央公园东苑',
 'price': 0,
 'when': '2017-06-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%B7%E5%8E%9A%E8%A1%9710%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.923030009156427,
 'lng': 118.78848868837916,
 'location': '南京项目地址：康厚街10号',
 'name': '九间堂',
 'price': ' 2200',
 'when': '2018-04-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境桂山堂',
 'price': ' 32000',
 'when': '2017-07-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxyscaadwd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jstygqcaaayk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%8A%E6%B2%B3%E6%96%B0%E5%9F%8E%E9%9B%85%E5%B1%85%E4%B9%90%E6%9E%97%E8%AF%AD%E5%9F%8E HTTP/1.1" 200 136
2018-04-12 12:31:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yjllycabmje/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：汊河新城雅居乐林语城',
 'name': '雅居乐林语城',
 'price': 0,
 'when': '2017-12-16'}
2018-04-12 12:31:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E5%A4%A7%E8%A1%97%E5%8D%87%E9%BE%99%E6%B1%87%E9%87%91%E4%B8%AD%E5%BF%83 HTTP/1.1" 200 134
2018-04-12 12:31:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_slhjzxabiuf/>
{'lat': 31.98712298032158,
 'lng': 118.71726900636072,
 'location': '南京项目地址：江山大街升龙汇金中心',
 'name': '升龙汇金中心',
 'price': ' 29000',
 'when': '2015-03-15'}
2018-04-12 12:31:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg37> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E8%B7%AF6%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jxlshslaasuo/>
{'lat': 32.132337610018176,
 'lng': 118.739274526947,
 'location': '南京项目地址：江山路6号',
 'name': '金象朗诗红树林',
 'price': 0,
 'when': '2017-10-28'}
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E9%87%8C%E6%A1%A5%E5%8C%97%E8%B7%AF%E9%87%91%E5%9C%B0%E6%B5%85%E5%B1%B1%E8%89%BA%E5%A2%83 HTTP/1.1" 200 143
2018-04-12 12:31:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jdqsyjabirk/>
{'lat': 32.094157269152994,
 'lng': 118.65780350461823,
 'location': '南京项目地址：七里桥北路金地浅山艺境',
 'name': '金地浅山艺境',
 'price': ' 40000',
 'when': '2016-06-01'}
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%9F%E8%B7%AF%EF%BC%88%E5%8D%97%E4%BA%AC%E8%A5%BF%E7%AB%99%E8%A5%BF%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 140
2018-04-12 12:31:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jxhfaarwx/>
{'lat': 32.10087185564733,
 'lng': 118.74873294286502,
 'location': '南京项目地址：龙江路（南京西站西侧）',
 'name': '锦绣华府',
 'price': 0,
 'when': '2016-05-21'}
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A1%83%E6%BA%AA%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rcjxthyabmmo/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：桃溪路1号',
 'name': '融创玖溪桃花源',
 'price': ' 395',
 'when': '2018-03-25'}
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF%E4%B8%87%E8%BE%BE%E8%8C%82 HTTP/1.1" 200 135
2018-04-12 12:31:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wdmaacfw/>
{'lat': 32.13304989681055,
 'lng': 118.9886366904625,
 'location': '南京项目地址：守敬路万达茂',
 'name': '万达茂',
 'price': 0,
 'when': '2015-10-31'}
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A2%A8%E6%A0%91%E5%9B%AD%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.934076010618092,
 'lng': 118.9482089800879,
 'location': '南京项目地址：梨树园路10号',
 'name': '弘阳禹洲时光春晓',
 'price': ' 23600',
 'when': '2018-01-10'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%A6%E5%8C%96%E8%B7%AF611%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_undefinedaaqhr/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：麦化路611号',
 'name': '电建洺悦府',
 'price': ' 22000',
 'when': '2017-12-22'}
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E5%88%9B%E6%96%B0%E4%B8%9C%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:31:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yclxjaaces/>
{'lat': 31.8838176413981,
 'lng': 118.88290815941363,
 'location': '南京项目地址：秣陵街道创新东路2号',
 'name': '银城蓝溪郡',
 'price': 0,
 'when': '2016-04-16'}
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF%E5%92%8C%E5%B9%BF%E7%94%B5%E5%8D%97%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:31:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0621065277938,
 'lng': 118.61903334846893,
 'location': '南京项目地址：雨山西路和广电南路交汇处',
 'name': '融创臻园',
 'price': 0,
 'when': '2017-12-07'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jljqhfaakts/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E7%9A%8B%E6%A1%A5%E8%A1%97%E9%81%93%E7%BD%91%E6%9D%BF%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xyyjwaacdv/>
{'lat': 32.10966291802278,
 'lng': 118.8313789586822,
 'location': '南京项目地址：迈皋桥街道网板路8号',
 'name': '星叶瑜憬湾',
 'price': ' 29500',
 'when': '2018-03-27'}
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A1%BE%E5%AE%B6%E8%90%A5%E8%B7%AF%E7%B4%AB%E9%87%91%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:31:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.044802270791855,
 'lng': 118.8854034320355,
 'location': '南京项目地址：顾家营路紫金华府',
 'name': '紫金华府',
 'price': 0,
 'when': '2017-12-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hrxflaakqa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyhgssaarrc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E7%A5%9E%E5%87%A4%E8%B7%AF1169%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.000159660995386,
 'lng': 118.95595120578673,
 'location': '南京项目地址：东山街道神凤路1169号',
 'name': '鸿信云深处',
 'price': ' 1762',
 'when': '2013-07-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg15> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:31:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bllsaaazg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:31:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_pjhfyxaaaze/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:31:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%A2%A8%E6%A0%91%E5%9B%AD%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.934076010618092,
 'lng': 118.9482089800879,
 'location': '南京项目地址：淳化街道梨树园路9号',
 'name': '万科金域东方',
 'price': ' 23800',
 'when': '2018-03-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E4%BF%AE%E6%96%87%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jljqhfaakts/>
{'lat': 31.90070775306782,
 'lng': 118.91608440725392,
 'location': '南京项目地址：江宁区淳化街道修文路3号',
 'name': '金轮津桥华府',
 'price': 0,
 'when': '2016-07-22'}
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfmyaaknx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hbypyaakof/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djsmyhaakuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ytsyhaaksk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_atssydaaktt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jsczgcaakng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sjxnfabhsz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:31:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E5%8D%8E%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.32157817364182,
 'lng': 118.81476070379864,
 'location': '南京项目地址：龙华路8号',
 'name': '金盛田阳光青城',
 'price': 0,
 'when': '2016-06-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wylzqhyaatpq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rsldrfaawky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BB%99%E6%9E%97%E8%A1%97%E9%81%93%E4%BF%9D%E5%88%A9%E7%A4%BC%E5%A2%85 HTTP/1.1" 200 137
2018-04-12 12:31:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bllsaaazg/>
{'lat': 32.11097695649148,
 'lng': 118.9295337061967,
 'location': '南京项目地址：仙林街道保利礼墅',
 'name': '保利礼墅',
 'price': 0,
 'when': '2015-06-20'}
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyyshhyaaazr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhjjaabbi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ckxdyyaabax/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hycsxjaawkm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlxlfaawai/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lgwxdhaavvc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%87%95%E5%AD%90%E7%9F%B6%E8%A1%97%E9%81%93%E8%9E%8D%E5%88%9B%E7%8E%89%E5%85%B0%E5%85%AC%E9%A6%86 HTTP/1.1" 200 137
2018-04-12 12:31:15 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.15160833098263,
 'lng': 118.84955152284388,
 'location': '南京项目地址：燕子矶街道融创玉兰公馆',
 'name': '融创玉兰公馆',
 'price': 0,
 'when': '2018-02-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gzbzszjlyabaiw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:31:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlysjaabvt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:31:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E6%B7%B3%E6%BA%AA%E9%95%87%E6%85%A2%E5%9F%8E%E5%A4%A7%E9%81%9368%E5%8F%B7%EF%BC%88%E9%AB%98%E6%B7%B3%E6%96%B0%E4%BD%93%E8%82%B2%E4%B8%AD%E5%BF%83%E5%8C%97%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 136
2018-04-12 12:31:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dfmyaaknx/>
{'lat': 31.33915369585837,
 'lng': 118.89224328829025,
 'location': '南京项目地址：高淳淳溪镇慢城大道68号（高淳新体育中心北侧）',
 'name': '东方曼园',
 'price': 0,
 'when': '2016-01-23'}
2018-04-12 12:31:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzjqlaaqji/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:31:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%A7%E5%8C%96%E8%A1%97%E9%81%93%E5%89%8D%E5%A1%98%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:15 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.138809818069916,
 'lng': 118.89732473396684,
 'location': '南京项目地址：尧化街道前塘路9号',
 'name': '华润幸福里',
 'price': ' 18500',
 'when': '2017-09-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E6%96%B0%E5%8D%8E%E8%A5%BF%E8%B7%AF458%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_pjhfyxaaaze/>
{'lat': 32.20805330579511,
 'lng': 118.7399702187509,
 'location': '南京项目地址：大厂新华西路458号',
 'name': '盘金华府',
 'price': 0,
 'when': '2014-06-21'}
2018-04-12 12:31:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BE%8A%E5%B1%B1%E5%8C%97%E8%B7%AF%E6%98%9F%E5%8F%B6%E7%BE%8A%E5%B1%B1%E6%B9%96%E8%8A%B1%E5%9B%AD HTTP/1.1" 200 136
2018-04-12 12:31:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xyyshhyaaazr/>
{'lat': 32.12228406250346,
 'lng': 118.9464675340093,
 'location': '南京项目地址：羊山北路星叶羊山湖花园',
 'name': '星叶羊山湖花园',
 'price': 0,
 'when': '2014-10-25'}
2018-04-12 12:31:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%92%8C%E7%87%95%E8%B7%AF%E8%91%9B%E6%B4%B2%E5%9D%9D%E6%8B%9B%E5%95%86%E7%B4%AB%E9%83%A1%E8%98%AD%E5%9B%AD HTTP/1.1" 200 132
2018-04-12 12:31:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1265750663835,
 'lng': 118.83957790985149,
 'location': '南京项目地址：和燕路葛洲坝招商紫郡蘭园',
 'name': '葛洲坝招商紫郡兰园',
 'price': 0,
 'when': '2017-10-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg3> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:31:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yqszaatdm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:31:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdfchtaadlc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:31:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smcpaawml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:31:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcxylsaaccp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:31:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yfltaacfl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:31:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8D%97%E8%B7%AF117%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hbypyaakof/>
{'lat': 31.324725434771544,
 'lng': 118.90167334739824,
 'location': '南京项目地址：淳南路117号',
 'name': '湖滨一品苑',
 'price': 0,
 'when': '2011-04-20'}
2018-04-12 12:31:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%B0%B7%E9%87%8C%E8%A1%97%E9%81%93%E6%82%A6%E6%B9%96%E8%B7%AF16%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.865723915051426,
 'lng': 118.73198543798807,
 'location': '南京项目地址：谷里街道悦湖路16号',
 'name': '碧桂园湖光山色',
 'price': ' 900',
 'when': '2017-12-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djgyaabbs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%86%B6%E6%B5%A6%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhjjaabbi/>
{'lat': 32.34747334123522,
 'lng': 118.867418077437,
 'location': '南京项目地址：冶浦路99号',
 'name': '龙海骏景',
 'price': 0,
 'when': '2017-08-03'}
2018-04-12 12:31:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%85%89%E8%B7%AF67%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%90%E5%B1%B1%E8%B7%AF208%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:19 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0310141948896,
 'lng': 118.81408773463262,
 'location': '南京项目地址：大光路67号',
 'name': '金陵雅颂居',
 'price': 0,
 'when': '2016-08-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djsmyhaakuc/>
{'lat': 31.99841267184827,
 'lng': 118.730251217879,
 'location': '南京项目地址：庐山路208号',
 'name': '德基世贸壹号',
 'price': ' 37000',
 'when': '2014-10-28'}
2018-04-12 12:31:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzscyfaapqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:31:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjgxtaasun/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:31:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E5%85%83%E4%B8%AD%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:19 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.93623568074372,
 'lng': 118.84629476472597,
 'location': '南京项目地址：天元中路99号',
 'name': '武夷绿洲沁荷苑',
 'price': 0,
 'when': '2017-07-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E7%8E%8B%E6%A1%A5%E8%B7%AF28%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ckxdyyaabax/>
{'lat': 32.33955818255956,
 'lng': 118.84800376222998,
 'location': '南京项目地址：雄州街道王桥路28号',
 'name': '城开新都雅苑',
 'price': 0,
 'when': '2017-11-01'}
2018-04-12 12:31:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E5%9B%BA%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ytsyhaaksk/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：永固路3号',
 'name': '亚泰山语湖',
 'price': 0,
 'when': '2017-09-08'}
2018-04-12 12:31:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E9%9E%8D%E8%A1%97%E9%81%93%E9%B9%AD%E5%B2%9B%E5%8D%97%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:21 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.5387256198191,
 'lng': 118.81897438994582,
 'location': '南京项目地址：马鞍街道鹭岛南路3号',
 'name': '荣盛鹭岛荣府',
 'price': ' 11500',
 'when': '2018-03-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhgjsqaatbj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyjfaatdo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_yzyyxsaawjw/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E5%B1%B1%E8%A1%97%E9%81%93%E9%98%B3%E6%98%8E%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:21 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.059437385842024,
 'lng': 118.96418417578569,
 'location': '南京项目地址：汤山街道阳明路99号',
 'name': '云栖山庄',
 'price': 0,
 'when': '2016-09-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E9%95%87%E6%B1%9F%E6%98%9F%E6%A1%A5%E7%BA%BF HTTP/1.1" 200 138
2018-04-12 12:31:21 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09369697857316,
 'lng': 118.52483283221608,
 'location': '南京项目地址：汤泉镇江星桥线',
 'name': '大吉公元',
 'price': 0,
 'when': '2016-09-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E8%97%8F%E5%A4%A7%E9%81%9312%E5%8F%B7%E5%BC%98%E9%98%B3 HTTP/1.1" 200 137
2018-04-12 12:31:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hycsxjaawkm/>
{'lat': 31.94682158034673,
 'lng': 118.67416296037928,
 'location': '南京项目地址：龙藏大道12号弘阳',
 'name': '弘阳春上西江',
 'price': 0,
 'when': '2016-11-27'}
2018-04-12 12:31:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E9%9D%96%E8%B7%AF599%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_atssydaaktt/>
{'lat': 31.966100163341842,
 'lng': 118.85850571579324,
 'location': '南京项目地址：文靖路599号',
 'name': '爱涛尚书云邸',
 'price': 0,
 'when': '2016-03-09'}
2018-04-12 12:31:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E9%A3%9E%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.104949086157944,
 'lng': 118.82824103380696,
 'location': '南京项目地址：华飞路1号',
 'name': '恒大翡翠华庭',
 'price': ' 32000',
 'when': '2017-07-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E5%AE%81%E8%B7%AF31%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jsczgcaakng/>
{'lat': 32.09653621784545,
 'lng': 118.78217765020526,
 'location': '南京项目地址：建宁路31号',
 'name': '金盛财智广场',
 'price': 0,
 'when': '2012-09-16'}
2018-04-12 12:31:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%87%95%E5%AD%90%E7%9F%B6%E8%A1%97%E9%81%93%E4%B8%AD%E8%88%AA%E5%9B%BD%E9%99%85%E7%A4%BE%E5%8C%BA HTTP/1.1" 200 137
2018-04-12 12:31:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.15160833098263,
 'lng': 118.84955152284388,
 'location': '南京项目地址：燕子矶街道中航国际社区',
 'name': '中航国际社区',
 'price': 0,
 'when': '2017-10-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8D%97%E8%A1%97%E9%81%93%E9%87%91%E8%BD%AE%E6%98%9F%E7%AB%8B%E6%96%B9 HTTP/1.1" 200 136
2018-04-12 12:31:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlxlfaawai/>
{'lat': 31.99799477275822,
 'lng': 118.78177238865749,
 'location': '南京项目地址：宁南街道金轮星立方',
 'name': '金轮星立方',
 'price': ' 60000',
 'when': '2015-12-04'}
2018-04-12 12:31:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8F%A0%E6%B3%89%E8%A5%BF%E8%B7%AF%E4%B8%89%E9%87%91%E9%91%AB%E5%AE%81%E5%BA%9C HTTP/1.1" 200 142
2018-04-12 12:31:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sjxnfabhsz/>
{'lat': 32.05495625325235,
 'lng': 118.63701904801674,
 'location': '南京项目地址：珠泉西路三金鑫宁府',
 'name': '三金鑫宁府',
 'price': ' 25600',
 'when': '2017-12-09'}
2018-04-12 12:31:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E6%96%B0%E8%B7%AF%E5%BC%98%E9%98%B3%E7%87%95%E6%B1%9F%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:31:25 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.14416255725624,
 'lng': 118.83407420848347,
 'location': '南京项目地址：太新路弘阳燕江府',
 'name': '弘阳燕江府',
 'price': ' 25800',
 'when': '2016-12-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hsjlwaaqfu/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_gsyaapuz/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_flcaapqv/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jdqsyjaapwt/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_klhfaadjw/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_cpcaagvp/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg38> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_sfjyaaftm/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8F%8C%E8%B7%AF%E4%B8%96%E8%8C%82%E5%9F%8E%E5%93%81 HTTP/1.1" 200 145
2018-04-12 12:31:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97666251592093,
 'lng': 118.76671169042649,
 'location': '南京项目地址：宁双路世茂城品',
 'name': '世茂城品',
 'price': 0,
 'when': '2017-06-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg8> (referer: https://nj.fang.lianjia.com/loupan/pg/pg7)
2018-04-12 12:31:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzyyxsaawjw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:31:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E4%B9%90%E8%B7%AF%E6%B4%AA%E5%AE%B6%E5%9B%AD1%E5%8F%B7 HTTP/1.1" 200 143
2018-04-12 12:31:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lgwxdhaavvc/>
{'lat': 32.0053428312632,
 'lng': 118.80204028545512,
 'location': '南京项目地址：永乐路洪家园1号',
 'name': '绿国万象都荟',
 'price': ' 50000',
 'when': '2015-11-17'}
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_zslxgkaayyp/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_mlhwjaayyg/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrs/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_xtjaawkz/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jhysaayxj/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_mfxsjaaeoe/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_zdxmlyzxaavxy/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg16> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mlhwjaayyg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%B5%9B%E8%99%B9%E6%A1%A5%E8%A1%97%E9%81%93%E7%A6%B9%E6%B4%B2%E5%90%89%E5%BA%86%E9%87%8C HTTP/1.1" 200 142
2018-04-12 12:31:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yzjqlaaqji/>
{'lat': 32.01411065563163,
 'lng': 118.76650360603985,
 'location': '南京项目地址：赛虹桥街道禹洲吉庆里',
 'name': '禹洲吉庆里',
 'price': 0,
 'when': '2016-05-26'}
2018-04-12 12:31:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%AC%E5%9C%B0%E8%B7%AF%E6%96%B0%E5%9F%8E%E9%A6%99%E6%82%A6%E6%BE%9C%E5%B1%B1 HTTP/1.1" 200 140
2018-04-12 12:31:28 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.131600315832,
 'lng': 118.9822212970358,
 'location': '南京项目地址：纬地路新城香悦澜山',
 'name': '新城香悦澜山',
 'price': 0,
 'when': '2017-04-10'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg38> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:31:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%96%84%E6%B0%B4%E6%B9%BE%E8%A5%BF%E4%BE%A7%E7%A6%B9%E6%B4%B2%E6%98%A0%E6%9C%88%E6%BA%AA%E5%B1%B1 HTTP/1.1" 200 143
2018-04-12 12:31:28 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.958704964869618,
 'lng': 118.73669664435383,
 'location': '南京项目地址：善水湾西侧禹洲映月溪山',
 'name': '禹洲映月溪山',
 'price': 0,
 'when': '2017-04-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sfjyaaftm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:31:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg9> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:31:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfxlsyaaedw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:31:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfryaaknc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:31:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhmdaakpp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:31:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hynhycaakrk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:31:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cfdszgaacay/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:31:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rachsaahns/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:31:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flcaapqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:31:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkpysaafgz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%99%BD%E9%A9%AC%E8%B7%AF90%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08732150414787,
 'lng': 118.63490312801513,
 'location': '南京项目地址：白马路90号',
 'name': '东方熙龙山院',
 'price': 0,
 'when': '2012-12-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%8B%9C%E5%B2%97%E8%B7%AF%E5%A4%A7%E5%8F%91%E8%9E%8D%E6%82%A6 HTTP/1.1" 200 144
2018-04-12 12:31:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.03761727573808,
 'lng': 118.87577728900419,
 'location': '南京项目地址：双拜岗路大发融悦',
 'name': '大发融悦',
 'price': 0,
 'when': '2016-04-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E5%9B%BA%E5%9F%8E%E9%95%87%E8%82%B2%E6%89%8D%E8%A5%BF%E8%B7%AF91%E5%8F%B7%EF%BC%88%E5%AE%81%E5%AE%A3%E5%85%AC%E8%B7%AF%E4%B8%9C%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:31:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.31262210058944,
 'lng': 118.97510527831135,
 'location': '南京项目地址：高淳固城镇育才西路91号（宁宣公路东侧）',
 'name': '景湖名都',
 'price': 0,
 'when': '2014-11-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E9%AB%98%E8%B7%AF50%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.344984216195197,
 'lng': 118.92722832470832,
 'location': '南京项目地址：双高路50号',
 'name': '花样年花样城',
 'price': ' 8500',
 'when': '2017-12-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E9%95%87%E8%A5%BF%E5%B1%B1%E5%A4%B4 HTTP/1.1" 200 133
2018-04-12 12:31:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mlhwjaayyg/>
{'lat': 31.954170205823228,
 'lng': 118.93133649576195,
 'location': '南京项目地址：淳化镇西山头',
 'name': '梅龙湖无界',
 'price': 0,
 'when': '2015-10-15'}
2018-04-12 12:31:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg17> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:31:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xtjaawkz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdxmlyzxaavxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zslxgkaayyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfxsjaaeoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjwlcaawkw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:31:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhysaayxj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8F%A3%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xtjaawkz/>
{'lat': 32.323376930598535,
 'lng': 118.8191838325704,
 'location': '南京项目地址：龙池街道龙口路9号',
 'name': '香缇郡',
 'price': 0,
 'when': '2016-10-20'}
2018-04-12 12:31:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%86%E5%86%9B%E5%A4%A7%E9%81%93129%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:30 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.912818603145553,
 'lng': 118.79794097426038,
 'location': '南京项目地址：将军大道129号',
 'name': '雍福龙庭',
 'price': 0,
 'when': '2017-01-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rqgdyxaacoj/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ltllxzaavtr/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E7%89%8C%E7%9F%B3%E5%A4%A7%E8%A1%97288%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sfjyaaftm/>
{'lat': 31.391466237256026,
 'lng': 119.00002643556175,
 'location': '南京项目地址：双牌石大街288号',
 'name': '双富嘉园',
 'price': 0,
 'when': '2017-01-07'}
2018-04-12 12:31:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gsyaapuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:31:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdqsyjaapwt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:31:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cpcaagvp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:31:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hsjlwaaqfu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:31:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E9%BA%92%E8%B7%AF277%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_flcaapqv/>
{'lat': 32.01565712729463,
 'lng': 118.88669095266192,
 'location': '南京项目地址：东麒路277号',
 'name': '富力城',
 'price': 0,
 'when': '2012-11-29'}
2018-04-12 12:31:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93231%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkpysaafgz/>
{'lat': 32.11764716703607,
 'lng': 118.67514525451335,
 'location': '南京项目地址：江浦街道沿山大道231号',
 'name': '万科璞悦山',
 'price': 0,
 'when': '2017-04-25'}
2018-04-12 12:31:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E5%8D%97%E8%B7%AF5%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99997241005109,
 'lng': 118.78497177739231,
 'location': '南京项目地址：雨花南路5号',
 'name': '长发都市诸公',
 'price': ' 864',
 'when': '2015-10-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%91%E6%99%BA%E8%B7%AF9%E5%8F%B7%E3%80%8110%E5%8F%B7%E3%80%8111%E5%8F%B7%E3%80%8112%E5%8F%B7%E3%80%8113%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdxmlyzxaavxy/>
{'lat': 31.97029556775504,
 'lng': 118.81089211249278,
 'location': '南京项目地址：民智路9号、10号、11号、12号、13号',
 'name': '证大喜玛拉雅中心',
 'price': ' 20000',
 'when': '2018-01-06'}
2018-04-12 12:31:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E8%8B%8F%E5%AE%81%E9%92%9F%E5%B1%B1%E6%9C%9D%E9%98%B3%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:31:32 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0913139891331,
 'lng': 118.89802397497581,
 'location': '南京项目地址：玄武大道苏宁钟山朝阳府',
 'name': '苏宁钟山朝阳府',
 'price': 0,
 'when': '2016-05-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E4%B8%AD%E5%BB%BA%E5%9B%BD%E7%86%99%E5%8F%B0 HTTP/1.1" 200 142
2018-04-12 12:31:32 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.06590199137902,
 'lng': 118.65369290890968,
 'location': '南京项目地址：新浦路中建国熙台',
 'name': '中建国熙台',
 'price': 0,
 'when': '2017-12-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg4> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hrxytdaatbu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jyzjfaagmw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytaaava/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%80%E8%A1%977%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:33 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.02198720429714,
 'lng': 118.76589413719202,
 'location': '南京项目地址：所街7号',
 'name': '华润新悦天地',
 'price': 0,
 'when': '2016-08-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwqlnhyaaaux/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A1%B6%E5%B1%B1%E8%A1%97%E9%81%93%E5%AE%9A%E5%90%91%E6%B2%B3%E8%A5%BF%E4%BE%A7 HTTP/1.1" 200 139
2018-04-12 12:31:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gsyaapuz/>
{'lat': 32.12858574755484,
 'lng': 118.69544350619863,
 'location': '南京项目地址：顶山街道定向河西侧',
 'name': '观山悦',
 'price': ' 25500',
 'when': '2017-12-27'}
2018-04-12 12:31:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%89%9B%E9%A6%96%E5%B1%B1%E5%A4%A7%E9%81%93121%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:33 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.918954454210063,
 'lng': 118.75165574782486,
 'location': '南京项目地址：牛首山大道121号',
 'name': '瑞安翠湖山',
 'price': ' 20000',
 'when': '2018-04-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jfnsaaelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:31:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E9%87%8C%E6%A1%A5%E5%8C%97%E8%B7%AF%E9%87%91%E5%9C%B0%E6%B5%85%E5%B1%B1%E8%89%BA%E5%A2%83 HTTP/1.1" 200 143
2018-04-12 12:31:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jdqsyjaapwt/>
{'lat': 32.094157269152994,
 'lng': 118.65780350461823,
 'location': '南京项目地址：七里桥北路金地浅山艺境',
 'name': '金地浅山艺境',
 'price': 0,
 'when': '2016-08-14'}
2018-04-12 12:31:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BC%98%E6%99%AF%E5%A4%A7%E9%81%933888%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:33 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.902158491130926,
 'lng': 118.90369318104928,
 'location': '南京项目地址：弘景大道3888号',
 'name': '景枫你山',
 'price': 0,
 'when': '2016-08-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E6%96%B0%E8%B7%AF%E6%8B%9B%E5%95%86%E5%85%B0%E6%BA%AA%E8%B0%B7 HTTP/1.1" 200 136
2018-04-12 12:31:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zslxgkaayyp/>
{'lat': 31.65760622534108,
 'lng': 119.04859890125368,
 'location': '南京项目地址：永新路招商兰溪谷',
 'name': '招商兰溪谷',
 'price': 0,
 'when': '2017-11-02'}
2018-04-12 12:31:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg10> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%8E%E5%9F%8E%E5%A4%A7%E9%81%93%E4%B8%87%E7%A7%91%E9%83%BD%E8%8D%9F%E5%8D%97%E8%8B%91 HTTP/1.1" 200 136
2018-04-12 12:31:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrs/>
{'lat': 31.97475979445248,
 'lng': 118.81085768852734,
 'location': '南京项目地址：明城大道万科都荟南苑',
 'name': '万科星荟',
 'price': 0,
 'when': '2017-07-12'}
2018-04-12 12:31:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93%E4%B8%8E%E8%B4%A2%E5%85%AB%E8%B7%AF%E4%BA%A4%E5%8F%89%E5%8F%A3%EF%BC%88%E5%A4%A7%E9%A9%AC%E5%B1%B1%E8%B7%AF6%E5%8F%B7%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:31:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfxsjaaeoe/>
{'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：浦口江浦街道沿山大道与财八路交叉口（大马山路6号）',
 'name': '明发香山郡',
 'price': ' 26000',
 'when': '2017-07-22'}
2018-04-12 12:31:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_shshyaacka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hymdaatgo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E5%8F%8C%E5%AE%A2%E8%B7%AF97%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjwlcaawkw/>
{'lat': 32.34349204726423,
 'lng': 118.84417012307615,
 'location': '南京项目地址：雄州街道双客路97号',
 'name': '紫晶未来城',
 'price': 0,
 'when': '2016-09-07'}
2018-04-12 12:31:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:35 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B3%B0%E5%B1%B1%E8%B7%AF%E9%87%91%E9%9A%85%E7%B4%AB%E9%87%91%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:31:35 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99647068073844,
 'lng': 118.74219268227752,
 'location': '南京项目地址：泰山路金隅紫金府',
 'name': '金隅紫京府',
 'price': ' 643',
 'when': '2017-12-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:35 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E7%A6%84%E5%A4%A7%E9%81%931%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cpcaagvp/>
{'lat': 31.79647196501264,
 'lng': 118.86518619158387,
 'location': '南京项目地址：天禄大道1号',
 'name': '翠屏城',
 'price': ' 11900',
 'when': '2017-11-08'}
2018-04-12 12:31:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E7%83%AD%E6%B2%B3%E5%8D%97%E8%B7%AF%E8%A1%97%E9%81%93 HTTP/1.1" 200 136
2018-04-12 12:31:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hsjlwaaqfu/>
{'lat': 32.08119544876564,
 'lng': 118.74690286637158,
 'location': '南京项目地址：鼓楼区热河南路街道',
 'name': '恒盛金陵湾',
 'price': ' 37500',
 'when': '2017-12-29'}
2018-04-12 12:31:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg39> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sjtcaacko/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E6%B9%96%E8%A1%97%E9%81%93%E9%80%9A%E6%B2%B3%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhysaayxj/>
{'lat': 32.45045312201094,
 'lng': 118.94784796098479,
 'location': '南京项目地址：金牛湖街道通河路9号',
 'name': '嘉恒有山',
 'price': ' 9550',
 'when': '2017-12-16'}
2018-04-12 12:31:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg18> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:31:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sswhykpaawjt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:31:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njbjzbjdswqabcno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:31:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyjfabhht/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:31:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E8%83%A1%E6%A1%A5%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:37 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：江浦街道胡桥路9号',
 'name': '明发云庭',
 'price': 0,
 'when': '2018-02-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdhfaaelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjybjgjaagoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sfssaaqqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjeqaatpa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwydaaasz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9B%A2%E5%B1%B1%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sjtcaacko/>
{'lat': 31.698645656477684,
 'lng': 119.02620947633312,
 'location': '南京项目地址：团山路1号',
 'name': '世纪天城',
 'price': 0,
 'when': '2016-07-19'}
2018-04-12 12:31:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ylcsjqaadxn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_akszsfaaabj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zlhyaabas/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gcdtljaacgp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaaws/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smwtxcaacap/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djhfaabvz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A2%85%E5%85%B4%E8%B7%AF%E5%96%84%E6%B0%B4%E6%B9%BE%E8%8A%B1%E5%9B%AD HTTP/1.1" 200 144
2018-04-12 12:31:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sswhykpaawjt/>
{'lat': 31.958704964869618,
 'lng': 118.73669664435383,
 'location': '南京项目地址：梅兴路善水湾花园',
 'name': '善水湾花园',
 'price': 0,
 'when': '2013-03-30'}
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tyljxyabgtm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdwryabhfp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blsdgcabdzt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zgtjqxcabefw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wdmabepd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:31:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E9%95%87%E5%81%87%E6%97%A5%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09294316228797,
 'lng': 118.52460713295669,
 'location': '南京项目地址：汤泉镇假日路8号',
 'name': '山河水花园',
 'price': ' 25000',
 'when': '2014-04-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sybjbdaamiq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycjydfaauoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jrcfslaaudc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dhjxhcxymsaavuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjmyaawmp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8D%8E%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:31:40 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.31827364260565,
 'lng': 118.81844075425253,
 'location': '南京项目地址：龙池街道龙华路66号',
 'name': '骋望七里楠花园',
 'price': 0,
 'when': '2016-08-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%8C%AF%E5%85%B4%E8%B7%AF180%E5%8F%B7%E3%80%81%E8%83%A5%E6%BA%AA%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ylcsjqaadxn/>
{'lat': 31.298993439267697,
 'lng': 119.07494337758881,
 'location': '南京项目地址：振兴路180号、胥溪路9号',
 'name': '垠领城市街区',
 'price': 0,
 'when': '2016-06-01'}
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E6%9E%A2%E8%A5%BF%E8%B7%AF%E5%A5%A5%E5%85%8B%E6%96%AF%E9%92%9F%E5%B1%B1%E5%BA%9C HTTP/1.1" 200 142
2018-04-12 12:31:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_akszsfaaabj/>
{'lat': 32.09514392116203,
 'lng': 118.91396510333544,
 'location': '南京项目地址：文枢西路奥克斯钟山府',
 'name': '奥克斯钟山府',
 'price': 0,
 'when': '2018-01-29'}
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%B0%E6%B3%BD%E8%B7%AF118%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zlhyaabas/>
{'lat': 31.998126980049786,
 'lng': 118.88957460317951,
 'location': '南京项目地址：丰泽路118号',
 'name': '中粮鸿云',
 'price': 0,
 'when': '2017-09-08'}
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E7%87%95%E6%B1%9F%E8%B7%AF201%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_njbjzbjdswqabcno/>
{'lat': 32.06860445880062,
 'lng': 118.76505691316264,
 'location': '南京项目地址：鼓楼区燕江路201号',
 'name': '江山汇金',
 'price': ' 17100',
 'when': '2014-05-07'}
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%9B%84%E5%B7%9E%E5%8D%97%E8%B7%AF333%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gcdtljaacgp/>
{'lat': 32.32400440901211,
 'lng': 118.8261801952043,
 'location': '南京项目地址：龙池街道雄州南路333号',
 'name': '冠城大通蓝郡',
 'price': 0,
 'when': '2017-08-20'}
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%BF%E8%A5%BF%E5%9F%82%E5%A4%A7%E8%A1%97100%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aaaws/>
{'lat': 32.09061065715351,
 'lng': 118.67518410377791,
 'location': '南京项目地址：广西埂大街100号',
 'name': '华润国际社区',
 'price': 0,
 'when': '2017-12-28'}
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9C%88%E5%AE%89%E8%A1%9711%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.02460861962323,
 'lng': 118.74210601897207,
 'location': '南京项目地址：月安街11号',
 'name': '海玥名都',
 'price': 0,
 'when': '2017-04-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zyhfaaxbt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%9F%E8%B7%AF30%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10314358339629,
 'lng': 118.74617782513008,
 'location': '南京项目地址：龙江路30号',
 'name': '深业滨江半岛',
 'price': ' 38700',
 'when': '2017-12-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E5%8F%B0%E5%8C%BA%E8%B5%9B%E8%99%B9%E6%A1%A5%E8%A1%97%E9%81%93 HTTP/1.1" 200 139
2018-04-12 12:31:42 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99525360625542,
 'lng': 118.76410088763129,
 'location': '南京项目地址：雨花台区赛虹桥街道',
 'name': '恒大华府',
 'price': 0,
 'when': '2017-02-13'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E6%96%B0%E8%B7%AF%E5%BC%98%E9%98%B3%E7%87%95%E6%B1%9F%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:31:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyjfabhht/>
{'lat': 32.14416255725624,
 'lng': 118.83407420848347,
 'location': '南京项目地址：太新路弘阳燕江府',
 'name': '弘阳燕江府',
 'price': 0,
 'when': '2017-06-30'}
2018-04-12 12:31:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_2jbjhabhfk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:31:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E9%80%9A%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smwtxcaacap/>
{'lat': 32.08452501199852,
 'lng': 118.74076903872225,
 'location': '南京项目地址：南通路89号',
 'name': '世茂外滩新城',
 'price': ' 35900',
 'when': '时间待定'}
2018-04-12 12:31:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E6%A2%81%E8%A1%97%E9%81%93%E7%91%9E%E6%88%90%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djhfaabvz/>
{'lat': 32.331850449520935,
 'lng': 118.94026095169839,
 'location': '南京项目地址：横梁街道瑞成路9号',
 'name': '东骏华府',
 'price': 0,
 'when': '2013-12-29'}
2018-04-12 12:31:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_klhfaadjw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97169%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05156767640222,
 'lng': 118.89683388187007,
 'location': '南京项目地址：马群街169号',
 'name': '银城君颐东方',
 'price': ' 43000',
 'when': '2017-12-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%90%89%E5%B1%B1%E5%A4%A7%E9%81%939%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.861380358744533,
 'lng': 118.77282264452263,
 'location': '南京项目地址：吉山大道9号',
 'name': '景瑞春风十里',
 'price': ' 19000',
 'when': '2017-06-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.123523391191696,
 'lng': 118.72947850536069,
 'location': '南京项目地址：浦珠北路59号',
 'name': '大华锦绣华城香鸢美颂',
 'price': ' 24600',
 'when': '2017-11-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E6%B5%A6%E8%B7%AF96%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.068138157816925,
 'lng': 118.67819018794667,
 'location': '南京项目地址：天浦路96号',
 'name': '雅居乐滨江国际',
 'price': ' 28000',
 'when': '2017-11-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%95%E5%BA%9C%E4%B8%9C%E8%B7%AF228%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12191964138096,
 'lng': 118.81329580556283,
 'location': '南京项目地址：幕府东路228号',
 'name': '紫金铭苑',
 'price': 0,
 'when': '2017-07-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E8%A1%97%E9%81%93%E5%B0%9A%E5%B3%B0%E5%B0%9A%E6%B0%B4 HTTP/1.1" 200 139
2018-04-12 12:31:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.097852651559236,
 'lng': 118.51451267002572,
 'location': '南京项目地址：汤泉街道尚峰尚水',
 'name': '尚峰尚水',
 'price': ' 500',
 'when': '2017-04-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境桂山堂',
 'price': ' 32000',
 'when': '2017-07-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%B9%A4%E9%B8%A3%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10341702868925,
 'lng': 118.90268150938394,
 'location': '南京项目地址：鹤鸣路68号',
 'name': '骋望云邸',
 'price': 0,
 'when': '2015-12-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltllxzaavtr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:31:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rqgdyxaacoj/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E4%B8%83%E9%87%8C%E8%B7%AF%E4%B8%8E%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:31:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tyljxyabgtm/>
{'lat': 32.0913457771416,
 'lng': 118.65014507465395,
 'location': '南京项目地址：江浦街道七里路与沿山大道交汇处',
 'name': '通宇林景熙园',
 'price': 0,
 'when': '2017-08-02'}
2018-04-12 12:31:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%87%B4%E8%BF%9C%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_klhfaadjw/>
{'lat': 31.64677206867821,
 'lng': 119.04738826030771,
 'location': '南京项目地址：致远路68号',
 'name': '康利华府',
 'price': 0,
 'when': '2018-01-01'}
2018-04-12 12:31:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg40> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:31:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gcbgyaaejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:31:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjszaabur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%BE%E6%9D%A8%E8%B7%AF%E7%B4%AB%E8%89%BA%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 136
2018-04-12 12:31:46 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：松杨路紫艺华府',
 'name': '紫艺华府',
 'price': 0,
 'when': '2018-01-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsylaatbk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E7%87%95%E4%B8%9C%E8%B7%AF%E6%8B%9B%E5%95%861872%E5%85%AC%E5%9B%AD%E9%87%8C HTTP/1.1" 200 132
2018-04-12 12:31:46 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1265750663835,
 'lng': 118.83957790985149,
 'location': '南京项目地址：钟燕东路招商1872公园里',
 'name': '招商1872公园里',
 'price': 0,
 'when': '2017-03-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg11> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:31:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E5%8D%97%E8%B7%AF688%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:46 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.915202323802344,
 'lng': 118.86477525813511,
 'location': '南京项目地址：秣陵街道竹山南路688号',
 'name': '罗托鲁拉小镇',
 'price': 0,
 'when': '2017-11-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrxhmdaatqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjhfaafcw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfzjgjaarco/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:31:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njbgyaaldy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yztaadtx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaazm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xhycbmlsaakqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:31:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltxfaawiy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E5%8C%97%E8%B7%AF279%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jdwryabhfp/>
{'lat': 32.08261037776124,
 'lng': 118.76973175941542,
 'location': '南京项目地址：中山北路279号',
 'name': '金鼎湾如院',
 'price': 0,
 'when': '2015-10-17'}
2018-04-12 12:31:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E6%BA%AA%E9%95%87%E7%9F%B3%E8%87%BC%E6%B9%96%E5%8C%97%E8%B7%AF76%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gcbgyaaejs/>
{'lat': 31.344123311690005,
 'lng': 118.89682926137152,
 'location': '南京项目地址：淳溪镇石臼湖北路76号',
 'name': '高淳碧桂园',
 'price': 0,
 'when': '2018-03-26'}
2018-04-12 12:31:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_slzxcaawcm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:31:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E5%85%83%E8%B7%AF%E4%B8%AD%E8%B7%AF128%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:49 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04694030889066,
 'lng': 118.80071471620052,
 'location': '南京项目地址：天元路中路128号',
 'name': '中锐星湖名邸',
 'price': 0,
 'when': '2017-04-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg5> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjjcyxaabaj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rqycaawis/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%8C%E6%B1%9F%E6%95%85%E5%B1%85%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:49 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.865264410601366,
 'lng': 118.47517450362449,
 'location': '南京项目地址：乌江故居路8号',
 'name': '江岸景城',
 'price': ' 15000',
 'when': '2015-02-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mdjyslaadxi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:31:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sclfaakub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:31:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%96%B0%E6%B5%A6%E8%B7%AF128%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_blsdgcabdzt/>
{'lat': 32.07216834555913,
 'lng': 118.65572949722356,
 'location': '南京项目地址：江浦街道新浦路128号',
 'name': '宝隆时代广场',
 'price': ' 16500',
 'when': '2017-11-04'}
2018-04-12 12:31:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E4%B8%81%E5%AE%B6%E5%B1%B1%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bjszaabur/>
{'lat': 32.24351789402061,
 'lng': 118.78205578787639,
 'location': '南京项目地址：大厂丁家山路2号',
 'name': '碧景山庄',
 'price': 0,
 'when': '2015-02-11'}
2018-04-12 12:31:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hcwjaauyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:31:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycdyfaauuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:31:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlhbskpaaekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:31:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%AD%E5%90%88%E5%8C%BA%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E7%8E%8B%E6%A1%A5%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 134
2018-04-12 12:31:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_slzxcaawcm/>
{'lat': 32.33244867233251,
 'lng': 118.84063470707173,
 'location': '南京项目地址：六合区雄州街道王桥路99号',
 'name': '石林中心城',
 'price': 0,
 'when': '2017-10-29'}
2018-04-12 12:31:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B9%96%E5%A4%A7%E9%81%93%E5%92%8C%E6%98%8C%E6%B9%BE%E6%99%AF HTTP/1.1" 200 142
2018-04-12 12:31:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hcwjaauyp/>
{'lat': 31.9254387597965,
 'lng': 118.67555812585326,
 'location': '南京项目地址：新湖大道和昌湾景',
 'name': '和昌湾景',
 'price': 0,
 'when': '2017-07-03'}
2018-04-12 12:31:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%B7%E7%A6%8F%E5%B7%B771%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ycdyfaauuz/>
{'lat': 32.02535577253019,
 'lng': 118.84839752545017,
 'location': '南京项目地址：海福巷71号',
 'name': '银城东岳府',
 'price': 0,
 'when': '2017-03-30'}
2018-04-12 12:31:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E6%B8%85%E6%B0%B4%E4%BA%AD%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlhbskpaaekk/>
{'lat': 31.919765529265728,
 'lng': 118.81406744370776,
 'location': '南京项目地址：秣陵街道清水亭西路188号',
 'name': '九龙湖别墅',
 'price': 0,
 'when': '2016-11-18'}
2018-04-12 12:31:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hjjlmyaadyi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:31:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzhybhlaawbr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:31:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A1%BE%E5%AE%B6%E8%90%A5%E8%B7%AF%E7%B4%AB%E9%87%91%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:31:51 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.044802270791855,
 'lng': 118.8854034320355,
 'location': '南京项目地址：顾家营路紫金华府',
 'name': '紫金华府',
 'price': 0,
 'when': '2017-12-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg41> (referer: https://nj.fang.lianjia.com/loupan/pg/pg40)
2018-04-12 12:31:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E7%86%9F%E8%A1%97%E9%81%93%E7%81%B5%E9%A1%BA%E5%8C%97%E8%B7%AF211%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:31:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hjjlmyaadyi/>
{'lat': 31.873002120783894,
 'lng': 118.98550482825115,
 'location': '南京项目地址：湖熟街道灵顺北路211号',
 'name': '恒建金陵美域',
 'price': 0,
 'when': '2015-10-09'}
2018-04-12 12:31:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhjlmzaawjd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:31:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rdxfcaaekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:31:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E7%99%BD%E9%A9%AC%E8%B7%AF%E4%B8%8E%E7%8B%AE%E5%B1%B1%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:31:51 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08258412514195,
 'lng': 118.63632209768683,
 'location': '南京项目地址：浦口区白马路与狮山路交汇处',
 'name': '旭辉银城白马澜山',
 'price': 0,
 'when': '2017-12-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E7%86%9F%E8%A1%97%E9%81%93%E6%B6%A6%E6%B9%96%E5%A4%A7%E9%81%93398%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:51 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.873594814596018,
 'lng': 118.97674222511495,
 'location': '南京项目地址：湖熟街道润湖大道398号',
 'name': '梁台煦府',
 'price': 0,
 'when': '2016-12-10'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_djhfscaalag/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:31:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znjyaaksn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:31:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E5%B0%A7%E8%B7%AF327%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zgtjqxcabefw/>
{'lat': 32.12259447503586,
 'lng': 118.84063643989731,
 'location': '南京项目地址：迈尧路327号',
 'name': '中国铁建青秀城',
 'price': 0,
 'when': '2014-12-20'}
2018-04-12 12:31:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF%E4%B8%87%E8%BE%BE%E8%8C%82 HTTP/1.1" 200 135
2018-04-12 12:31:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wdmabepd/>
{'lat': 32.13304989681055,
 'lng': 118.9886366904625,
 'location': '南京项目地址：守敬路万达茂',
 'name': '万达茂',
 'price': ' 17000',
 'when': '2018-03-24'}
2018-04-12 12:31:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bgybasjabgyc/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hyyzsgyxabgwq/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:31:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_njcfgcabgvg/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bltyabgvd/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:31:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_2jbjhabhfk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 45, in parse_html
    item["name"] = response.xpath('//h1/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:31:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bltyabgvd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:31:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njcfgcabgvg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:31:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BC%A0%E6%95%A6%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：张敦路59号',
 'name': '明发珠江国际',
 'price': ' 27800',
 'when': '2016-04-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%89%9B%E9%A6%96%E5%A4%A7%E9%81%93%E5%BA%86%E5%85%B4%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.886978323966712,
 'lng': 118.71252324038538,
 'location': '南京项目地址：牛首大道庆兴路8号',
 'name': '南京碧桂园',
 'price': 0,
 'when': '2017-09-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B6%A6%E5%AF%BF%E5%8C%97%E8%B7%AF599%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yzhybhlaawbr/>
{'lat': 31.859401199797308,
 'lng': 118.60077001053546,
 'location': '南京项目地址：润寿北路599号',
 'name': '禹洲弘阳滨湖里',
 'price': 0,
 'when': '2016-12-24'}
2018-04-12 12:31:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BB%84%E5%B1%B1%E5%B2%AD%E8%B7%AF%E4%B9%9D%E6%9C%88%E6%A3%AE%E6%9E%97 HTTP/1.1" 200 143
2018-04-12 12:31:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08342667185487,
 'lng': 118.62232126700839,
 'location': '南京项目地址：黄山岭路九月森林',
 'name': '九月森林',
 'price': 0,
 'when': '2018-03-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%9C%B0%E9%93%81%E4%BA%8C%E5%8F%B7%E7%BA%BF%E5%A4%A9%E8%BF%88%E5%B9%BF%E5%9C%BA%E6%B2%B9%E5%9D%8A%E6%A1%A5%E7%AB%99 HTTP/1.1" 200 139
2018-04-12 12:31:54 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.971841104007034,
 'lng': 118.72764980327469,
 'location': '南京项目地址：建邺地铁二号线天迈广场油坊桥站',
 'name': '首创立方',
 'price': ' 20000',
 'when': '2016-04-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BD%AF%E4%BB%B6%E5%A4%A7%E9%81%93%E4%B8%AD%E5%8D%97%E9%94%A6%E8%8B%91 HTTP/1.1" 200 144
2018-04-12 12:31:54 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.984256699458975,
 'lng': 118.75651496529456,
 'location': '南京项目地址：软件大道中南锦苑',
 'name': '中南锦苑',
 'price': 0,
 'when': '2016-09-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_heshyhggaakok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:31:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fhhrdxaaclk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:31:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wycaakob/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:31:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:54 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.393150940897428,
 'lng': 118.97196008794114,
 'location': '南京项目地址：双湖路1号',
 'name': '海尔双湖壹号公馆',
 'price': ' 8300',
 'when': '2017-09-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htygjczgcaakog/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:31:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfptmhjaaqjj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:31:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkysjaalru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:31:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E5%B9%B3%E5%8D%97%E8%B7%AF%E4%B8%8E%E7%99%BD%E4%B8%8B%E8%B7%AF%E4%BA%A4%E7%95%8C%E5%A4%84 HTTP/1.1" 200 136
2018-04-12 12:31:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.03553521855789,
 'lng': 118.79736364858033,
 'location': '南京项目地址：太平南路与白下路交界处',
 'name': '凤凰和睿大厦',
 'price': ' 22000',
 'when': '时间待定'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%9D%E9%BE%99%E5%B1%B1%E8%B7%AF%E4%B8%87%E6%82%A6%E5%9F%8E HTTP/1.1" 200 143
2018-04-12 12:31:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.369820090663627,
 'lng': 118.95197910453356,
 'location': '南京项目地址：九龙山路万悦城',
 'name': '万悦城',
 'price': 0,
 'when': '2017-05-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%94%E5%A4%A9%E5%A4%A7%E8%A1%97%E4%BF%9D%E5%88%A9%E5%A4%A9%E6%82%A6 HTTP/1.1" 200 145
2018-04-12 12:31:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bltyabgvd/>
{'lat': 32.03108091466837,
 'lng': 118.73254774489833,
 'location': '南京项目地址：应天大街保利天悦',
 'name': '保利天悦',
 'price': 0,
 'when': '2017-11-18'}
2018-04-12 12:31:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyzsgyxabgwq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:31:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgybasjabgyc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%86%E5%86%9B%E5%A4%A7%E9%81%93%E9%9F%A9%E5%BA%9C%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.94294979560223,
 'lng': 118.78826271962814,
 'location': '南京项目地址：将军大道韩府路18号',
 'name': '滟紫台',
 'price': 0,
 'when': '2014-10-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%B1%B1%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_njcfgcabgvg/>
{'lat': 32.09260114030094,
 'lng': 118.81803364578863,
 'location': '南京项目地址：红山路88号',
 'name': '南京常发广场',
 'price': ' 25000',
 'when': '2015-08-05'}
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%83%9C%E5%A4%AA%E8%B7%AF%E9%87%91%E8%BE%89%E9%87%91%E9%99%B5%E9%93%AD%E8%91%97 HTTP/1.1" 200 135
2018-04-12 12:31:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhjlmzaawjd/>
{'lat': 31.95061810100132,
 'lng': 118.82058772867562,
 'location': '南京项目地址：胜太路金辉金陵铭著',
 'name': '金辉金陵铭著',
 'price': 0,
 'when': '2016-11-17'}
2018-04-12 12:31:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E6%B7%B3%E6%BA%AA%E9%95%87%E5%AE%9D%E5%A1%94%E8%B7%AF269%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:57 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.33618242769404,
 'lng': 118.9089895903361,
 'location': '南京项目地址：高淳淳溪镇宝塔路269号',
 'name': '红太阳国际财智广场',
 'price': 0,
 'when': '2016-04-10'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E5%87%A4%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyzsgyxabgwq/>
{'lat': 31.652751200874587,
 'lng': 119.0233543470155,
 'location': '南京项目地址：栖凤路68号',
 'name': '弘阳禹洲时光印象',
 'price': 0,
 'when': '2017-12-27'}
2018-04-12 12:31:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05876455593678,
 'lng': 118.62066377476616,
 'location': '南京项目地址：雨山西路89号',
 'name': '北江锦城',
 'price': ' 24300',
 'when': '2017-11-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B9%E5%B7%9E%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rdxfcaaekr/>
{'lat': 32.365988858238566,
 'lng': 118.85472132611994,
 'location': '南京项目地址：方州路68号',
 'name': '荣鼎幸福城',
 'price': 0,
 'when': '2018-01-24'}
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E4%B8%87%E5%AE%89%E5%8D%97%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:31:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.962191115716916,
 'lng': 118.88690470266143,
 'location': '南京项目地址：东山街道万安南路9号',
 'name': '融侨悦城',
 'price': 0,
 'when': '2018-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blxjyaabaz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dsljaayua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhsyhaalja/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mlysaaawr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9F%8E%E5%8D%97%E6%B2%B3%E8%B7%AF%E4%BF%9D%E5%88%A9%E8%A5%BF%E6%B1%9F%E6%9C%88 HTTP/1.1" 200 141
2018-04-12 12:31:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04810818480485,
 'lng': 118.66452157400175,
 'location': '南京项目地址：城南河路保利西江月',
 'name': '保利西江月',
 'price': 0,
 'when': '2017-05-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg42> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%8E%B1%E8%8C%B5%E8%BE%BE%E8%B7%AF12%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.950984236736673,
 'lng': 118.86091033640727,
 'location': '南京项目地址：莱茵达路12号',
 'name': '都市丽景',
 'price': 0,
 'when': '2017-01-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E6%BA%AA%E8%A1%97%E9%81%93%E7%94%98%E6%B3%89%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:31:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.759965542424297,
 'lng': 118.72924045440054,
 'location': '南京项目地址：横溪街道甘泉湖路1号',
 'name': '中浩山屿湖',
 'price': 0,
 'when': '2017-06-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldgjhdaazxm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:31:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxcjyaawif/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:31:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%87%A4%E6%B1%87%E5%A4%A7%E9%81%93%E6%98%8E%E5%8F%91%E6%B5%A6%E6%B3%B0%E6%A2%A6%E5%B9%BB%E5%AE%B6 HTTP/1.1" 200 143
2018-04-12 12:31:59 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.92740779796182,
 'lng': 118.64778341958687,
 'location': '南京项目地址：凤汇大道明发浦泰梦幻家',
 'name': '明发浦泰梦幻家',
 'price': 0,
 'when': '2017-09-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:31:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:31:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%81%E9%98%B3%E4%B8%9C%E8%B7%AF901%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:31:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgybasjabgyc/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滁阳东路901号',
 'name': '碧桂园北岸世家',
 'price': 0,
 'when': '2017-07-26'}
2018-04-12 12:32:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg19> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:32:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%A8%E6%BA%AA%E5%A4%A7%E9%81%931000%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:00 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滨溪大道1000号',
 'name': '牧龙原墅',
 'price': ' 23000',
 'when': '2015-04-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rqgdyxaacoj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg20> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E8%A1%97%E9%81%93%E5%9C%B0%E7%A7%80%E8%B7%AF522%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:32:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ldgjhdaazxm/>
{'lat': 31.8405098656495,
 'lng': 118.58998001860118,
 'location': '南京项目地址：江宁街道地秀路522号',
 'name': '绿地国际花都',
 'price': ' 20000',
 'when': '2016-09-30'}
2018-04-12 12:32:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hysyabchh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:32:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wnsscdsjjqabelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:32:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhcjzcabbrp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:32:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyshsjabcfs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:32:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jngcabbex/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:32:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkapysaatgt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%8C%BA%E5%B7%B4%E5%B1%B1%E8%B7%AF38%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hxcjyaawif/>
{'lat': 32.008675496084074,
 'lng': 118.73063170639526,
 'location': '南京项目地址：建邺区巴山路38号',
 'name': '华新城璟园',
 'price': 0,
 'when': '2016-05-15'}
2018-04-12 12:32:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_thnjyzaatgz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjgxtabgdk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%9C%88%E5%8D%8E%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hysyabchh/>
{'lat': 31.93624759256761,
 'lng': 118.90840306958252,
 'location': '南京项目地址：江宁区淳化街道月华路8号',
 'name': '弘阳上院',
 'price': ' 23000',
 'when': '2015-02-18'}
2018-04-12 12:32:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BB%93%E5%AE%B6%E5%B7%B7%E4%B8%87%E7%A7%91%E5%AE%89%E5%93%81%E5%9B%AD%E8%88%8D HTTP/1.1" 200 131
2018-04-12 12:32:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkapysaatgt/>
{'lat': 31.9649933148731,
 'lng': 118.76593279846456,
 'location': '南京项目地址：仓家巷万科安品园舍',
 'name': '万科安品园舍',
 'price': 0,
 'when': '2016-06-20'}
2018-04-12 12:32:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_pthtxsqabgbq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjjzaatbs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E7%81%B5%E8%A1%9750%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.044111682631645,
 'lng': 118.87556409864904,
 'location': '南京项目地址：钟灵街50号',
 'name': '五矿晏山居',
 'price': 0,
 'when': '2017-07-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg12> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:32:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:32:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: HousePriceNJ)
2018-04-12 12:32:02 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.3.1, w3lib 1.18.0, Twisted 17.9.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 17.5.0 (OpenSSL 1.1.0g  2 Nov 2017), cryptography 2.1.4, Platform Linux-4.13.0-38-generic-x86_64-with-Ubuntu-16.04-xenial
2018-04-12 12:32:02 [scrapy.crawler] INFO: Overridden settings: {'FEED_EXPORT_ENCODING': 'utf-8', 'SPIDER_MODULES': ['HousePriceNJ.spiders'], 'ROBOTSTXT_OBEY': True, 'NEWSPIDER_MODULE': 'HousePriceNJ.spiders', 'BOT_NAME': 'HousePriceNJ'}
2018-04-12 12:32:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2018-04-12 12:32:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-04-12 12:32:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-04-12 12:32:02 [scrapy.middleware] INFO: Enabled item pipelines:
['HousePriceNJ.pipelines.HousepricenjPipeline']
2018-04-12 12:32:02 [scrapy.core.engine] INFO: Spider opened
2018-04-12 12:32:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:32:02 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6030
2018-04-12 12:32:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aadlk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:32:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_attycaadid/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:32:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhjyaadjj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:32:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltllxzaacjt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:32:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:02 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://nj.fang.lianjia.com/robots.txt> (referer: None)
2018-04-12 12:32:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg1> (referer: None)
2018-04-12 12:32:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%B7%E9%99%A2%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:02 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08509008337853,
 'lng': 118.63412696869857,
 'location': '南京项目地址：海院路88号',
 'name': '融侨观邸',
 'price': ' 25500',
 'when': '2017-07-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg6> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rshfaatdn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smzsysaakkg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lyzyaarxs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlhbskpaaeco/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blzygyaaavy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:03 [scrapy.extensions.logstats] INFO: Crawled 52 pages (at 52 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:32:03 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-04-12 12:32:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E6%B4%B2%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wnsscdsjjqabelo/>
{'lat': 32.16240412601025,
 'lng': 118.75041249708227,
 'location': '南京项目地址：浦洲路66号',
 'name': '威尼斯水城第十九街区',
 'price': ' 20600',
 'when': '2017-11-11'}
2018-04-12 12:32:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg2> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E5%8D%97%E8%B7%AF501%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_thnjyzaatgz/>
{'lat': 32.026788843993685,
 'lng': 118.78769049901827,
 'location': '南京项目地址：中山南路501号',
 'name': '泰禾南京院子',
 'price': 0,
 'when': '2017-06-06'}
2018-04-12 12:32:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcylggaatbq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rczyaarxa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%AF%E9%99%B5%E8%B7%AF7%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08813762841439,
 'lng': 118.87777963354526,
 'location': '南京项目地址：环陵路7号',
 'name': '钟山国际高尔夫',
 'price': 0,
 'when': '2013-06-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyfqsaaaclf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:32:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lsqcjqaacmb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:32:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hjfhsaahno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:32:04 [scrapy.extensions.logstats] INFO: Crawled 108 pages (at 55 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:32:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E6%A1%A5%E8%A5%BF%E8%B7%AF162%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.33635869765098,
 'lng': 118.84812434355814,
 'location': '南京项目地址：雄州街道桥西路162号',
 'name': '荣盛华府',
 'price': 0,
 'when': '2017-07-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zlxyaatbm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lntsyaatqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E8%BE%B9%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhcjzcabbrp/>
{'lat': 32.095733750047245,
 'lng': 118.74065486319363,
 'location': '南京项目地址：江边路1号',
 'name': '龙湖春江紫宸',
 'price': 0,
 'when': '2017-03-30'}
2018-04-12 12:32:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E4%B8%AD%E5%BB%BA%E5%9B%BD%E7%86%99%E5%8F%B0 HTTP/1.1" 200 142
2018-04-12 12:32:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjgxtabgdk/>
{'lat': 32.06590199137902,
 'lng': 118.65369290890968,
 'location': '南京项目地址：新浦路中建国熙台',
 'name': '中建国熙台',
 'price': 0,
 'when': '2017-06-16'}
2018-04-12 12:32:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyhsabezj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytaaycz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:05 [scrapy.extensions.logstats] INFO: Crawled 174 pages (at 42 pages/min), scraped 148 items (at 38 items/min)
2018-04-12 12:32:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%87%95%E5%AD%90%E7%9F%B6%E8%A1%97%E9%81%93%E8%9E%8D%E5%88%9B%E7%8E%89%E5%85%B0%E5%85%AC%E9%A6%86 HTTP/1.1" 200 137
2018-04-12 12:32:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rcylggaatbq/>
{'lat': 32.15160833098263,
 'lng': 118.84955152284388,
 'location': '南京项目地址：燕子矶街道融创玉兰公馆',
 'name': '融创玉兰公馆',
 'price': 0,
 'when': '2018-02-25'}
2018-04-12 12:32:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jysaatdp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jpzydfaatdk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gzbzszjlyabaiw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdjjtaadjb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF%E5%92%8C%E5%B9%BF%E7%94%B5%E5%8D%97%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:32:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rczyaarxa/>
{'lat': 32.0621065277938,
 'lng': 118.61903334846893,
 'location': '南京项目地址：雨山西路和广电南路交汇处',
 'name': '融创臻园',
 'price': 0,
 'when': '2017-12-07'}
2018-04-12 12:32:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A6%E6%B7%AE%E5%A4%A7%E9%81%93399%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:06 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.645263048037307,
 'lng': 119.0541065336066,
 'location': '南京项目地址：秦淮大道399号',
 'name': '爱涛天岳城',
 'price': 0,
 'when': '2018-01-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E9%A9%AC%E8%B7%AF%E4%B8%96%E8%8C%82%E6%8B%9B%E5%95%86%E8%AF%AD%E5%B1%B1 HTTP/1.1" 200 143
2018-04-12 12:32:07 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.07140443035624,
 'lng': 118.91366956082265,
 'location': '南京项目地址：金马路世茂招商语山',
 'name': '世茂招商语山',
 'price': 0,
 'when': '2016-10-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E5%B1%B1%E8%A5%BF%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%ADS1%E7%A7%A6%E6%B7%AE%E4%B8%96%E5%AE%B6 HTTP/1.1" 200 137
2018-04-12 12:32:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyshsjabcfs/>
{'lat': 31.648311742573938,
 'lng': 118.91514343402882,
 'location': '南京项目地址：横山西路碧桂园S1秦淮世家',
 'name': '碧桂园S1秦淮世家',
 'price': 0,
 'when': '2017-11-30'}
2018-04-12 12:32:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%AD%E5%90%88%E9%95%BF%E6%B1%9F%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_pthtxsqabgbq/>
{'lat': 32.13531269255433,
 'lng': 118.74226588429522,
 'location': '南京项目地址：江山路9号',
 'name': '浦泰和天下三期',
 'price': 0,
 'when': '2017-11-11'}
2018-04-12 12:32:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jngcabbex/>
{'lat': 32.347517586163555,
 'lng': 118.84876979582978,
 'location': '南京项目地址：六合长江路1号',
 'name': '金宁广场',
 'price': ' 13000',
 'when': '2010-11-06'}
2018-04-12 12:32:07 [scrapy.extensions.logstats] INFO: Crawled 390 pages (at 60 pages/min), scraped 222 items (at 57 items/min)
2018-04-12 12:32:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg43> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znjyabaye/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:32:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A5%94%E9%A9%AC%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E9%92%9F%E5%B1%B1 HTTP/1.1" 200 136
2018-04-12 12:32:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xcpyzsaauyn/>
{'lat': 32.08330568277308,
 'lng': 118.91771165983776,
 'location': '南京项目地址：奔马路新城璞樾钟山',
 'name': '新城璞樾钟山',
 'price': 0,
 'when': '2017-12-02'}
2018-04-12 12:32:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyzsgcxablwc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hynxnzxaavzr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htssyjabatw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:32:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfysyfaayds/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hlgjabatq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:32:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E6%B9%96%E8%B7%AF100%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.696231584053706,
 'lng': 119.11840755372283,
 'location': '南京项目地址：金湖路100号',
 'name': '金湖家园',
 'price': 0,
 'when': '2011-08-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:09 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05876455593678,
 'lng': 118.62066377476616,
 'location': '南京项目地址：雨山西路89号',
 'name': '路易庄园',
 'price': ' 25000',
 'when': '2018-01-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%8E%E5%9F%8E%E5%A4%A7%E9%81%93%E4%BB%A5%E8%A5%BF%E4%B8%AD%E4%BA%A4%E9%94%A6%E8%87%B4 HTTP/1.1" 200 136
2018-04-12 12:32:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjjzaatbs/>
{'lat': 31.97475979445248,
 'lng': 118.81085768852734,
 'location': '南京项目地址：明城大道以西中交锦致',
 'name': '中交锦致',
 'price': 0,
 'when': '2017-07-15'}
2018-04-12 12:32:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkddhabexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%B4%E8%B4%A4%E8%B7%AF19%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jysaatdp/>
{'lat': 32.110827426049745,
 'lng': 118.84457333169928,
 'location': '南京项目地址：兴贤路19号',
 'name': '嘉誉山',
 'price': ' 29000',
 'when': '2017-07-09'}
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BD%AF%E4%BB%B6%E5%A4%A7%E9%81%93%E4%B8%AD%E5%8D%97%E9%94%A6%E8%8B%91 HTTP/1.1" 200 144
2018-04-12 12:32:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_znjyabaye/>
{'lat': 31.984256699458975,
 'lng': 118.75651496529456,
 'location': '南京项目地址：软件大道中南锦苑',
 'name': '中南锦苑',
 'price': ' 150',
 'when': '2017-03-22'}
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_heshyhggabgfc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wyqcwjblzxabgnj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcthyabgvb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znsjyyaaynl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ydhczxabgkt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E4%BA%94%E8%B7%AF%E9%87%91%E6%B5%A6%E7%B4%AB%E5%BE%A1%E4%B8%9C%E6%96%B9 HTTP/1.1" 200 134
2018-04-12 12:32:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jpzydfaatdk/>
{'lat': 32.1312287642796,
 'lng': 118.84117460118358,
 'location': '南京项目地址：经五路金浦紫御东方',
 'name': '金浦紫御东方',
 'price': ' 28600',
 'when': '2017-11-06'}
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BA%91%E9%94%A6%E8%B7%AF%E5%AE%8F%E5%9B%BE%E4%B8%8A%E6%B0%B4%E4%BA%91%E9%94%A6 HTTP/1.1" 200 144
2018-04-12 12:32:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_htssyjabatw/>
{'lat': 32.021247988570856,
 'lng': 118.74727426898808,
 'location': '南京项目地址：云锦路宏图上水云锦',
 'name': '宏图上水云锦一期',
 'price': ' 55000',
 'when': '2017-01-01'}
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E5%8D%97%E8%B7%AF688%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.915202323802344,
 'lng': 118.86477525813511,
 'location': '南京项目地址：秣陵街道竹山南路688号',
 'name': '罗托鲁拉小镇',
 'price': 0,
 'when': '2016-04-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fdyzsyxaampu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:32:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_smmxjaakrd/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:32:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E6%B8%85%E6%B0%B4%E4%BA%AD%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.919765529265728,
 'lng': 118.81406744370776,
 'location': '南京项目地址：秣陵街道清水亭西路188号',
 'name': '九龙湖别墅',
 'price': 0,
 'when': '2016-11-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E5%B1%B1%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E5%92%8C%E5%B1%B1 HTTP/1.1" 200 135
2018-04-12 12:32:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xcpyhsabezj/>
{'lat': 32.04095857741548,
 'lng': 118.85225558502222,
 'location': '南京项目地址：钟山路新城璞樾和山',
 'name': '新城璞樾和山',
 'price': ' 30000',
 'when': '2018-02-14'}
2018-04-12 12:32:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%92%8C%E7%87%95%E8%B7%AF%E8%91%9B%E6%B4%B2%E5%9D%9D%E6%8B%9B%E5%95%86%E7%B4%AB%E9%83%A1%E8%98%AD%E5%9B%AD HTTP/1.1" 200 132
2018-04-12 12:32:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gzbzszjlyabaiw/>
{'lat': 32.1265750663835,
 'lng': 118.83957790985149,
 'location': '南京项目地址：和燕路葛洲坝招商紫郡蘭园',
 'name': '葛洲坝招商紫郡兰园',
 'price': 0,
 'when': '2017-10-31'}
2018-04-12 12:32:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93%E5%92%8C%E8%8A%B1%E5%8D%89%E5%A4%A7%E9%81%93%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:32:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfysyfaayds/>
{'lat': 32.08114358586541,
 'lng': 118.64442572426861,
 'location': '南京项目地址：沿山大道和花卉大道交汇处',
 'name': '明发阅山悦府',
 'price': 0,
 'when': '2018-02-11'}
2018-04-12 12:32:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%B7%E5%8E%9A%E8%A1%9710%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdjjtaadjb/>
{'lat': 31.923030009156427,
 'lng': 118.78848868837916,
 'location': '南京项目地址：康厚街10号',
 'name': '九间堂',
 'price': ' 2200',
 'when': '2018-04-08'}
2018-04-12 12:32:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%A1%AB%E6%B9%96%E4%B8%9C%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.947722743322984,
 'lng': 118.88189242724522,
 'location': '南京项目地址：衫湖东路18号',
 'name': '星叶枫情水岸',
 'price': 0,
 'when': '2015-03-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A2%A8%E6%A0%91%E5%9B%AD%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyzsgcxablwc/>
{'lat': 31.934076010618092,
 'lng': 118.9482089800879,
 'location': '南京项目地址：梨树园路10号',
 'name': '弘阳禹洲时光春晓',
 'price': ' 23600',
 'when': '2018-01-10'}
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%A5%E5%87%A4%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.78379644297444,
 'lng': 118.86052299785104,
 'location': '南京项目地址：来凤路18号',
 'name': '朗诗青春街区',
 'price': 0,
 'when': '2017-11-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E9%9C%9E%E6%96%87%E9%BC%8E%E8%B7%AF1%E5%8F%B7%EF%BC%88%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E4%B8%8E%E5%AD%A6%E6%9E%97%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:32:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.11865857092845,
 'lng': 118.91214765162765,
 'location': '南京项目地址：栖霞文鼎路1号（玄武大道与学林路交汇处）',
 'name': '恒基富荟山',
 'price': 0,
 'when': '2014-10-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_djhfscaalag/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%95%BF%E4%BA%AD%E8%A1%9759%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.914770739009395,
 'lng': 118.83304208150336,
 'location': '南京项目地址：秣陵街道长亭街59号',
 'name': '保利中央公园东苑',
 'price': 0,
 'when': '2017-06-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rshycaaksj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdljaatpb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hxyscaadwd/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hrxflaakqa/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E9%B9%8F%E5%B1%B1%E8%B7%AF28%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:14 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.924654849950382,
 'lng': 118.90626134667176,
 'location': '南京项目地址：淳化街道鹏山路28号',
 'name': '中粮祥云',
 'price': 0,
 'when': '2016-11-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E7%91%B6%E8%B7%AF7%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfytaaycz/>
{'lat': 32.09198071246321,
 'lng': 118.65432397571688,
 'location': '南京项目地址：七瑶路7号',
 'name': '明发悦庭',
 'price': ' 18500',
 'when': '2017-09-16'}
2018-04-12 12:32:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacejk/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%A7%E8%A1%9781%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:32:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hlgjabatq/>
{'lat': 32.0574390450143,
 'lng': 118.78971204573793,
 'location': '南京项目地址：中大街81号',
 'name': '海伦国际',
 'price': ' 12730',
 'when': '2017-10-31'}
2018-04-12 12:32:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E4%B8%AD%E5%A4%AE%E5%8C%97%E8%B7%AF%E6%B2%B3%E8%B7%AF%E9%81%931%E5%8F%B7 HTTP/1.1" 200 134
2018-04-12 12:32:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hynxnzxaavzr/>
{'lat': 32.1027477897518,
 'lng': 118.78834230949631,
 'location': '南京项目地址：鼓楼区中央北路河路道1号',
 'name': '花样年喜年中心',
 'price': ' 23000',
 'when': '2016-09-21'}
2018-04-12 12:32:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jlysjaabvt/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E9%A9%AC%E7%BE%A4%E8%A1%972%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:15 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05578425340213,
 'lng': 118.89966428083703,
 'location': '南京项目地址：马群街道马群街2号',
 'name': '复地御钟山二期',
 'price': 0,
 'when': '2014-07-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_xwhjmgcaadxy/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hxcaabwu/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_gxzrtcaabuc/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg3> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg13> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:32:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yqszaatdm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smcpaawml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yfltaacfl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gfdyaadlv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:32:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdfchtaadlc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcxylsaaccp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%BC%E8%87%B4%E8%A5%BF%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：格致西路1号',
 'name': '鲁能泰山7号院',
 'price': 0,
 'when': '2017-07-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E5%B1%B1%E8%A1%97%E9%81%93%E9%98%B3%E6%98%8E%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yqszaatdm/>
{'lat': 32.059437385842024,
 'lng': 118.96418417578569,
 'location': '南京项目地址：汤山街道阳明路99号',
 'name': '云栖山庄',
 'price': 0,
 'when': '2016-09-11'}
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8F%8C%E8%B7%AF%E4%B8%96%E8%8C%82%E5%9F%8E%E5%93%81 HTTP/1.1" 200 145
2018-04-12 12:32:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smcpaawml/>
{'lat': 31.97666251592093,
 'lng': 118.76671169042649,
 'location': '南京项目地址：宁双路世茂城品',
 'name': '世茂城品',
 'price': 0,
 'when': '2017-06-23'}
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%86%E5%86%9B%E5%A4%A7%E9%81%93129%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yfltaacfl/>
{'lat': 31.912818603145553,
 'lng': 118.79794097426038,
 'location': '南京项目地址：将军大道129号',
 'name': '雍福龙庭',
 'price': 0,
 'when': '2017-01-25'}
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%AB%99%E4%B8%9C%E4%BA%8C%E8%B7%AF%E4%B8%87%E7%A7%91%E5%A4%A7%E9%83%BD%E4%BC%9A HTTP/1.1" 200 136
2018-04-12 12:32:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkddhabexa/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：站东二路万科大都会',
 'name': '万科大都会',
 'price': 0,
 'when': '2018-03-30'}
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E9%A3%9E%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdfchtaadlc/>
{'lat': 32.104949086157944,
 'lng': 118.82824103380696,
 'location': '南京项目地址：华飞路1号',
 'name': '恒大翡翠华庭',
 'price': ' 32000',
 'when': '2017-07-05'}
2018-04-12 12:32:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacejo/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_drylwaatss/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%AC%E5%9C%B0%E8%B7%AF%E6%96%B0%E5%9F%8E%E9%A6%99%E6%82%A6%E6%BE%9C%E5%B1%B1 HTTP/1.1" 200 140
2018-04-12 12:32:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xcxylsaaccp/>
{'lat': 32.131600315832,
 'lng': 118.9822212970358,
 'location': '南京项目地址：纬地路新城香悦澜山',
 'name': '新城香悦澜山',
 'price': 0,
 'when': '2017-04-10'}
2018-04-12 12:32:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjgxtaasun/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzscyfaapqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjydfabjyv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg1)
2018-04-12 12:32:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdzxfhaatqu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_heshyhggabgfc/>
{'lat': 31.393150940897428,
 'lng': 118.97196008794114,
 'location': '南京项目地址：双湖路1号',
 'name': '海尔双湖壹号公馆',
 'price': 0,
 'when': '2017-06-26'}
2018-04-12 12:32:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E9%BE%99%E5%87%A4%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wyqcwjblzxabgnj/>
{'lat': 31.943934853497655,
 'lng': 118.94156811107989,
 'location': '南京项目地址：淳化街道龙凤路2号',
 'name': '万宇汽车五金博览中心',
 'price': 0,
 'when': '2016-05-25'}
2018-04-12 12:32:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E4%B8%9C%E5%8D%97%E8%B7%AF%E9%87%91%E5%9C%B0%E4%B8%AD%E5%BF%83%E9%A3%8E%E5%8D%8E HTTP/1.1" 200 136
2018-04-12 12:32:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jdzxfhaatqu/>
{'lat': 31.981980257155737,
 'lng': 118.70237986022788,
 'location': '南京项目地址：江东南路金地中心风华',
 'name': '金地中心风华',
 'price': 0,
 'when': '2017-11-19'}
2018-04-12 12:32:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcjctdaaxrj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zgtjyxsaatpp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E9%93%9C%E8%B7%AF%E5%9B%BD%E5%BA%9C%E5%A4%A7%E9%99%A2 HTTP/1.1" 200 145
2018-04-12 12:32:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E6%9E%97%E5%9C%BA%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:18 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.868615425164933,
 'lng': 118.97393347470582,
 'location': '南京项目地址：汤铜路国府大院',
 'name': '国府大院',
 'price': 0,
 'when': '2016-05-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:18 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.32446249240832,
 'lng': 118.85133622323109,
 'location': '南京项目地址：龙池街道林场路1号',
 'name': '荣盛花语城',
 'price': 0,
 'when': '2017-08-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jjhtaabzh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:32:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smmxjaakrd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:32:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwyhcaadvo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:32:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:32:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjdhaacak/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:32:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E4%B8%AD%E5%BB%BA%E5%9B%BD%E7%86%99%E5%8F%B0 HTTP/1.1" 200 142
2018-04-12 12:32:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjgxtaasun/>
{'lat': 32.06590199137902,
 'lng': 118.65369290890968,
 'location': '南京项目地址：新浦路中建国熙台',
 'name': '中建国熙台',
 'price': 0,
 'when': '2017-12-02'}
2018-04-12 12:32:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rqgdyxaacoj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytaaava/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjybjgjaagoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BB%84%E5%AE%B6%E5%9C%A9%E8%B7%AF%E8%9E%8D%E5%88%9B%E7%B2%BE%E5%BD%A9%E5%A4%A9%E5%9C%B0 HTTP/1.1" 200 134
2018-04-12 12:32:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rcjctdaaxrj/>
{'lat': 32.09573605816086,
 'lng': 118.80169499478319,
 'location': '南京项目地址：黄家圩路融创精彩天地',
 'name': '融创精彩天地',
 'price': ' 350',
 'when': '2016-11-05'}
2018-04-12 12:32:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djzcfycsgcabfky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:32:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%A7%E9%BE%99%E6%B9%96%E5%A4%A7%E9%81%931%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.731203746093776,
 'lng': 119.0553388291052,
 'location': '南京项目地址：卧龙湖大道1号',
 'name': '卧龙湖小镇',
 'price': ' 13500',
 'when': '2018-02-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%93%BA%E5%B2%97%E8%A1%9728%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.924283790875556,
 'lng': 118.84223111805659,
 'location': '南京项目地址：秣陵街道铺岗街28号',
 'name': '骏景华庭',
 'price': 0,
 'when': '2015-08-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%92%E9%BA%9F%E8%A1%97%E9%81%93%E8%A2%81%E5%AE%B6%E8%BE%B9%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.02524213109228,
 'lng': 118.92961737976174,
 'location': '南京项目地址：麒麟街道袁家边路9号',
 'name': '恒大龙珺',
 'price': 0,
 'when': '2017-07-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E7%91%9E%E6%96%87%E8%B7%AF199%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：淳化街道瑞文路199号',
 'name': '世茂梦享家',
 'price': 0,
 'when': '2016-04-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djgyaabbs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzyyxsaawjw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E8%8B%8F%E5%AE%81%E9%92%9F%E5%B1%B1%E6%9C%9D%E9%98%B3%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:32:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_snzscyfaapqr/>
{'lat': 32.0913139891331,
 'lng': 118.89802397497581,
 'location': '南京项目地址：玄武大道苏宁钟山朝阳府',
 'name': '苏宁钟山朝阳府',
 'price': 0,
 'when': '2016-05-08'}
2018-04-12 12:32:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%A2%A8%E6%A0%91%E5%9B%AD%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkjydfabjyv/>
{'lat': 31.934076010618092,
 'lng': 118.9482089800879,
 'location': '南京项目地址：淳化街道梨树园路9号',
 'name': '万科金域东方',
 'price': ' 23800',
 'when': '2018-03-24'}
2018-04-12 12:32:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjeqaatpa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E6%A1%A5%E5%8D%97%E8%B7%AF108%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zgtjyxsaatpp/>
{'lat': 31.865478012062233,
 'lng': 118.61613434356234,
 'location': '南京项目地址：宁桥南路108号',
 'name': '中国铁建原香颂',
 'price': 0,
 'when': '2017-09-30'}
2018-04-12 12:32:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_drylwaatss/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:32:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%8F%E5%B8%82%E8%A1%97%E9%81%93%E7%94%B5%E5%BB%BA%E4%B8%AD%E5%82%A8%E6%B3%9B%E6%82%A6%E5%9F%8E%E5%B8%82%E5%B9%BF%E5%9C%BA HTTP/1.1" 200 134
2018-04-12 12:32:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djzcfycsgcabfky/>
{'lat': 32.10631834473104,
 'lng': 118.796087672078,
 'location': '南京项目地址：小市街道电建中储泛悦城市广场',
 'name': '电建中储泛悦城市广场',
 'price': ' 35900',
 'when': '2017-12-28'}
2018-04-12 12:32:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E5%B1%B1%E8%A1%97%E9%81%93%E9%BA%92%E9%BA%9F%E9%97%A8%E5%A4%A7%E9%81%936699%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lcthyabgvb/>
{'lat': 32.04571553461317,
 'lng': 119.02176299880456,
 'location': '南京项目地址：汤山街道麒麟门大道6699号',
 'name': '绿城桃花源',
 'price': 0,
 'when': '2018-03-31'}
2018-04-12 12:32:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9B%A2%E5%B1%B1%E8%A5%BF%E8%B7%AF26%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:22 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.69267717506764,
 'lng': 119.0207176406826,
 'location': '南京项目地址：团山西路26号',
 'name': '创维乐活城',
 'price': ' 6800',
 'when': '2017-09-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E9%95%87%E6%B1%9F%E6%98%9F%E6%A1%A5%E7%BA%BF HTTP/1.1" 200 138
2018-04-12 12:32:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09369697857316,
 'lng': 118.52483283221608,
 'location': '南京项目地址：汤泉镇江星桥线',
 'name': '大吉公元',
 'price': 0,
 'when': '2016-09-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhgjsqaatbj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jstygqcaaayk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wylzqhyaatpq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyjfaatdo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyhgssaarrc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hrxflaakqa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%96%84%E6%B0%B4%E6%B9%BE%E8%A5%BF%E4%BE%A7%E7%A6%B9%E6%B4%B2%E6%98%A0%E6%9C%88%E6%BA%AA%E5%B1%B1 HTTP/1.1" 200 143
2018-04-12 12:32:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.958704964869618,
 'lng': 118.73669664435383,
 'location': '南京项目地址：善水湾西侧禹洲映月溪山',
 'name': '禹洲映月溪山',
 'price': 0,
 'when': '2017-04-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%B7%E9%99%A2%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rqgdyxaacoj/>
{'lat': 32.08509008337853,
 'lng': 118.63412696869857,
 'location': '南京项目地址：海院路88号',
 'name': '融侨观邸',
 'price': ' 25500',
 'when': '2017-07-02'}
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%87%95%E5%AD%90%E7%9F%B6%E8%A1%97%E9%81%93%E4%B8%AD%E8%88%AA%E5%9B%BD%E9%99%85%E7%A4%BE%E5%8C%BA HTTP/1.1" 200 137
2018-04-12 12:32:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.15160833098263,
 'lng': 118.84955152284388,
 'location': '南京项目地址：燕子矶街道中航国际社区',
 'name': '中航国际社区',
 'price': 0,
 'when': '2017-10-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E5%8D%8E%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.32157817364182,
 'lng': 118.81476070379864,
 'location': '南京项目地址：龙华路8号',
 'name': '金盛田阳光青城',
 'price': 0,
 'when': '2016-06-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%98%89%E4%B8%9A%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_drylwaatss/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：嘉业路8号',
 'name': '恒大悦澜湾',
 'price': ' 26500',
 'when': '2017-11-30'}
2018-04-12 12:32:24 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:32:24 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcaccii/>: HTTP status code is not handled or not allowed
2018-04-12 12:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg21> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%91%A1%E5%9B%AD%E8%B7%AF%E4%BB%81%E6%81%92%E7%BB%BF%E6%B4%B2%E6%96%B0%E5%B2%9B HTTP/1.1" 200 143
2018-04-12 12:32:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.03377176667957,
 'lng': 118.70845022618616,
 'location': '南京项目地址：葡园路仁恒绿洲新岛',
 'name': '仁恒绿洲新岛',
 'price': 0,
 'when': '2017-11-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%91%E5%92%8C%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.976571884202652,
 'lng': 118.81231844287983,
 'location': '南京项目地址：民和路1号',
 'name': '万科九都荟',
 'price': 0,
 'when': '2015-11-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxcaabwu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zgtjqxcaaeox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyyjwaacdv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg14> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:32:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E8%83%A1%E6%A1%A5%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfytaaava/>
{'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：江浦街道胡桥路9号',
 'name': '明发云庭',
 'price': 0,
 'when': '2018-02-09'}
2018-04-12 12:32:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E6%B5%A6%E8%B7%AF96%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yjybjgjaagoo/>
{'lat': 32.068138157816925,
 'lng': 118.67819018794667,
 'location': '南京项目地址：天浦路96号',
 'name': '雅居乐滨江国际',
 'price': ' 28000',
 'when': '2017-11-06'}
2018-04-12 12:32:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E5%85%83%E4%B8%AD%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:25 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.93623568074372,
 'lng': 118.84629476472597,
 'location': '南京项目地址：天元中路99号',
 'name': '武夷绿洲沁荷苑',
 'price': 0,
 'when': '2017-07-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E4%B8%AD%E5%8D%97%E4%B8%96%E7%BA%AA%E9%9B%85%E8%8B%91 HTTP/1.1" 200 143
2018-04-12 12:32:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_znsjyyaaynl/>
{'lat': 32.04313070524712,
 'lng': 118.91670898739703,
 'location': '南京项目地址：马群街道中南世纪雅苑',
 'name': '中南世纪雅苑',
 'price': 0,
 'when': '2017-05-20'}
2018-04-12 12:32:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%AC%E5%AD%90%E6%B1%9F%E5%A4%A7%E9%81%93399%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.987082829704036,
 'lng': 118.69301154165758,
 'location': '南京项目地址：扬子江大道399号',
 'name': '海峡城',
 'price': 0,
 'when': '时间待定'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xwhjmgcaadxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:32:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gxzrtcaabuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:32:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djhfscaalag/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:32:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E5%B0%A7%E8%B7%AF327%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12259447503586,
 'lng': 118.84063643989731,
 'location': '南京项目地址：迈尧路327号',
 'name': '中国铁建青秀城',
 'price': 0,
 'when': '2016-06-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E7%9A%8B%E6%A1%A5%E8%A1%97%E9%81%93%E7%BD%91%E6%9D%BF%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10966291802278,
 'lng': 118.8313789586822,
 'location': '南京项目地址：迈皋桥街道网板路8号',
 'name': '星叶瑜憬湾',
 'price': ' 29500',
 'when': '2018-03-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gkrjeqaatpa/>
{'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境桂山堂',
 'price': ' 32000',
 'when': '2017-07-16'}
2018-04-12 12:32:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfzjgjaarco/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltllxzaavtr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlysjaabvt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg2)
2018-04-12 12:32:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E6%96%B0%E8%B7%AF%E5%BC%98%E9%98%B3%E7%87%95%E6%B1%9F%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:32:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.14416255725624,
 'lng': 118.83407420848347,
 'location': '南京项目地址：太新路弘阳燕江府',
 'name': '弘阳燕江府',
 'price': ' 25800',
 'when': '2016-12-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg22> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg23> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:32:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:32:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceme/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:32:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:32:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:32:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceme/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%AE%E8%B7%AF201%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.07904243541421,
 'lng': 118.78987490852688,
 'location': '南京项目地址：中央路201号',
 'name': '玄武湖金茂广场御景华府',
 'price': 0,
 'when': '2009-11-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%B2%BF%E5%B1%B1%E4%B8%9C%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09729036743584,
 'lng': 118.63965590436665,
 'location': '南京项目地址：浦口区江浦街道沿山东路188号',
 'name': '国信自然天城',
 'price': 0,
 'when': '2008-10-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:32:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%B0%B7%E9%87%8C%E8%A1%97%E9%81%93%E6%82%A6%E6%B9%96%E8%B7%AF16%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:30 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.865723915051426,
 'lng': 118.73198543798807,
 'location': '南京项目地址：谷里街道悦湖路16号',
 'name': '碧桂园湖光山色',
 'price': ' 900',
 'when': '2017-12-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg24> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BC%A0%E6%95%A6%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfzjgjaarco/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：张敦路59号',
 'name': '明发珠江国际',
 'price': ' 27800',
 'when': '2016-04-15'}
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg4> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwydaaasz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwqlnhyaaaux/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdhfaaelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sfssaaqqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%A7%E5%8C%96%E8%A1%97%E9%81%93%E5%89%8D%E5%A1%98%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:30 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.138809818069916,
 'lng': 118.89732473396684,
 'location': '南京项目地址：尧化街道前塘路9号',
 'name': '华润幸福里',
 'price': ' 18500',
 'when': '2017-09-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxyscaadwd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E5%8D%97%E8%B7%AF688%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ltllxzaavtr/>
{'lat': 31.915202323802344,
 'lng': 118.86477525813511,
 'location': '南京项目地址：秣陵街道竹山南路688号',
 'name': '罗托鲁拉小镇',
 'price': 0,
 'when': '2017-11-18'}
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%85%89%E8%B7%AF67%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlysjaabvt/>
{'lat': 32.0310141948896,
 'lng': 118.81408773463262,
 'location': '南京项目地址：大光路67号',
 'name': '金陵雅颂居',
 'price': 0,
 'when': '2016-08-14'}
2018-04-12 12:32:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%B9%A4%E9%B8%A3%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cwydaaasz/>
{'lat': 32.10341702868925,
 'lng': 118.90268150938394,
 'location': '南京项目地址：鹤鸣路68号',
 'name': '骋望云邸',
 'price': 0,
 'when': '2015-12-19'}
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%80%BB%E9%83%A8%E5%A4%A7%E9%81%93%E6%AF%85%E8%BE%BE%E6%B1%87%E5%88%9B%E4%B8%AD%E5%BF%83 HTTP/1.1" 200 136
2018-04-12 12:32:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ydhczxabgkt/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：总部大道毅达汇创中心',
 'name': '毅达汇创中心',
 'price': ' 24500',
 'when': '2017-06-05'}
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flshabfza/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jlxgmzabfmg/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jlxlfaayvm/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg44> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrt/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_dcjmyaatpv/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_undefinedaatan/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_lcslabfij/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceod/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceod/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E4%BA%94%E8%B7%AF%E7%94%B5%E5%BB%BA%E6%B5%B7%E8%B5%8B%E5%B0%9A%E5%9F%8E HTTP/1.1" 200 141
2018-04-12 12:32:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.137634319277,
 'lng': 118.84295688872218,
 'location': '南京项目地址：经五路电建海赋尚城',
 'name': '电建海赋尚城',
 'price': ' 25800',
 'when': '2018-01-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zssfaaeoa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:32:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_slthaaelu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:32:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg25> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B4%87%E6%96%87%E8%B7%AF68%E5%8F%B7(%E4%BD%93%E8%82%B2%E5%85%AC%E5%9B%AD%E5%8D%97300%E7%B1%B3) HTTP/1.1" 200 138
2018-04-12 12:32:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.636021305521947,
 'lng': 119.04381660119327,
 'location': '南京项目地址：崇文路68号(体育公园南300米)',
 'name': '中山首府',
 'price': 0,
 'when': '2017-07-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E7%A5%9E%E5%87%A4%E8%B7%AF1169%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:32 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.000159660995386,
 'lng': 118.95595120578673,
 'location': '南京项目地址：东山街道神凤路1169号',
 'name': '鸿信云深处',
 'price': ' 1762',
 'when': '2013-07-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg7> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8D%8E%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:32:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cwqlnhyaaaux/>
{'lat': 32.31827364260565,
 'lng': 118.81844075425253,
 'location': '南京项目地址：龙池街道龙华路66号',
 'name': '骋望七里楠花园',
 'price': 0,
 'when': '2016-08-19'}
2018-04-12 12:32:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E9%BA%92%E8%B7%AF277%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_flshabfza/>
{'lat': 32.01565712729463,
 'lng': 118.88669095266192,
 'location': '南京项目地址：东麒路277号',
 'name': '富力十号',
 'price': ' 900',
 'when': '2015-06-02'}
2018-04-12 12:32:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg8> (referer: https://nj.fang.lianjia.com/loupan/pg/pg7)
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceos/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg44> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:32:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceos/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlxgmzabfmg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg9> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_undefinedaatan/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcslabfij/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlxlfaayvm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfxlsyaaedw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:32:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%AF%9A%E4%BF%A1%E5%A4%A7%E9%81%93998%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlxgmzabfmg/>
{'lat': 31.91463660152268,
 'lng': 118.84551268108456,
 'location': '南京项目地址：诚信大道998号',
 'name': '金轮星光名座',
 'price': 0,
 'when': '2013-01-22'}
2018-04-12 12:32:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceor/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B2%B3%E8%B7%AF%E5%8D%87%E9%BE%99%E5%A4%A9%E6%B1%87 HTTP/1.1" 200 143
2018-04-12 12:32:33 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.970816439367926,
 'lng': 118.70513179041191,
 'location': '南京项目地址：新河路升龙天汇',
 'name': '升龙天汇',
 'price': 0,
 'when': '2017-11-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkcaabgm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_afgjaabiy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:32:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceor/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg15> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkcwjcaaenb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cywxsaacdj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:32:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfxsjaaeoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:32:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%80%E5%9B%AD%E8%B7%AF6%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:34 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.647940595364506,
 'lng': 119.03181041118783,
 'location': '南京项目地址：秀园路6号',
 'name': '万科城',
 'price': 0,
 'when': '2018-03-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:32:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E5%8F%B0%E5%8C%BA%E8%B5%9B%E8%99%B9%E6%A1%A5%E8%A1%97%E9%81%93 HTTP/1.1" 200 139
2018-04-12 12:32:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdhfaaelr/>
{'lat': 31.99525360625542,
 'lng': 118.76410088763129,
 'location': '南京项目地址：雨花台区赛虹桥街道',
 'name': '恒大华府',
 'price': 0,
 'when': '2017-02-13'}
2018-04-12 12:32:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacene/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacene/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg26> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:32:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceki/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:32:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceki/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:35 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E9%AB%98%E5%BA%99%E8%B7%AF%E6%9C%97%E8%AF%97%E7%86%99%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 141
2018-04-12 12:32:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_undefinedaatan/>
{'lat': 31.9752553808195,
 'lng': 118.69895635055644,
 'location': '南京项目地址：南高庙路朗诗熙华府',
 'name': '朗诗熙华府',
 'price': 0,
 'when': '2017-11-20'}
2018-04-12 12:32:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E5%AF%8C%E5%A1%98%E8%A1%978%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lcslabfij/>
{'lat': 31.97168171605523,
 'lng': 118.86003408519586,
 'location': '南京项目地址：东山街道富塘街8号',
 'name': '绿城深蓝',
 'price': 0,
 'when': '2018-02-11'}
2018-04-12 12:32:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:32:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%BD%E6%99%AF%E8%B7%AF%E8%89%BE%E8%8F%B2%E5%9B%BD%E9%99%85 HTTP/1.1" 200 145
2018-04-12 12:32:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.16648888960027,
 'lng': 118.70877040832077,
 'location': '南京项目地址：丽景路艾菲国际',
 'name': '艾菲国际',
 'price': 0,
 'when': '2015-04-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:32:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E8%A1%97%E9%81%93%E5%B0%9A%E5%B3%B0%E5%B0%9A%E6%B0%B4 HTTP/1.1" 200 139
2018-04-12 12:32:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sfssaaqqv/>
{'lat': 32.097852651559236,
 'lng': 118.51451267002572,
 'location': '南京项目地址：汤泉街道尚峰尚水',
 'name': '尚峰尚水',
 'price': ' 500',
 'when': '2017-04-22'}
2018-04-12 12:32:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jyzjfaagmw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B3%B0%E5%B1%B1%E8%B7%AF%E9%87%91%E9%9A%85%E7%B4%AB%E9%87%91%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:32:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jyzjfaagmw/>
{'lat': 31.99647068073844,
 'lng': 118.74219268227752,
 'location': '南京项目地址：泰山路金隅紫金府',
 'name': '金隅紫京府',
 'price': ' 643',
 'when': '2017-12-30'}
2018-04-12 12:32:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:32:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg5> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:32:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hrxytdaatbu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg3)
2018-04-12 12:32:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mlysaaawr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:37 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:32:37 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:32:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcaceog/>: HTTP status code is not handled or not allowed
2018-04-12 12:32:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg27> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%90%B4%E4%BE%AF%E8%A1%97158%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:38 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.973438574825735,
 'lng': 118.70282546018457,
 'location': '南京项目地址：吴侯街158号',
 'name': '五矿崇文金城',
 'price': 0,
 'when': '2017-11-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:32:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%99%BD%E9%A9%AC%E8%B7%AF90%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08732150414787,
 'lng': 118.63490312801513,
 'location': '南京项目地址：白马路90号',
 'name': '东方熙龙山院',
 'price': 0,
 'when': '2012-12-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sybjbdaamiq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhmdaakpp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hynhycaakrk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cfdszgaacay/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jfnsaaelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rachsaahns/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:32:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rsldrfaawky/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceri/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:32:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceri/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:32:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:32:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%80%E8%A1%977%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hrxytdaatbu/>
{'lat': 32.02198720429714,
 'lng': 118.76589413719202,
 'location': '南京项目地址：所街7号',
 'name': '华润新悦天地',
 'price': 0,
 'when': '2016-08-08'}
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhsyhaalja/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrxhmdaatqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjhfaafcw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njbgyaaldy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yztaadtx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjjcyxaabaj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8D%97%E8%A1%97%E9%81%93%E9%87%91%E8%BD%AE%E6%98%9F%E7%AB%8B%E6%96%B9 HTTP/1.1" 200 136
2018-04-12 12:32:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlxlfaayvm/>
{'lat': 31.99799477275822,
 'lng': 118.78177238865749,
 'location': '南京项目地址：宁南街道金轮星立方',
 'name': '金轮星立方',
 'price': ' 21000',
 'when': '2015-12-04'}
2018-04-12 12:32:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:32:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dcjmyaatpv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:32:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacela/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:32:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8F%8D%E7%8F%A0%E5%8D%97%E8%B7%AF199%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:32:40 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10124607362065,
 'lng': 118.707219725188,
 'location': '南京项目地址：珍珠南路199号',
 'name': '创源无想墅',
 'price': 0,
 'when': '2016-01-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%9F%E8%B7%AF30%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10314358339629,
 'lng': 118.74617782513008,
 'location': '南京项目地址：龙江路30号',
 'name': '深业滨江半岛',
 'price': ' 38700',
 'when': '2017-12-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E5%9B%BA%E5%9F%8E%E9%95%87%E8%82%B2%E6%89%8D%E8%A5%BF%E8%B7%AF91%E5%8F%B7%EF%BC%88%E5%AE%81%E5%AE%A3%E5%85%AC%E8%B7%AF%E4%B8%9C%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:32:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.31262210058944,
 'lng': 118.97510527831135,
 'location': '南京项目地址：高淳固城镇育才西路91号（宁宣公路东侧）',
 'name': '景湖名都',
 'price': 0,
 'when': '2014-11-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg28> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93%E4%B8%8E%E8%B4%A2%E5%85%AB%E8%B7%AF%E4%BA%A4%E5%8F%89%E5%8F%A3%EF%BC%88%E5%A4%A7%E9%A9%AC%E5%B1%B1%E8%B7%AF6%E5%8F%B7%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:32:42 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：浦口江浦街道沿山大道与财八路交叉口（大马山路6号）',
 'name': '明发香山郡',
 'price': ' 26000',
 'when': '2017-07-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_pjhfyxaaaze/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:32:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bllsaaazg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:32:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyyshhyaaazr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:32:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ckxdyyaabax/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:32:42 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:32:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%A8%E6%BA%AA%E5%A4%A7%E9%81%931000%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mlysaaawr/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滨溪大道1000号',
 'name': '牧龙原墅',
 'price': ' 23000',
 'when': '2015-04-24'}
2018-04-12 12:32:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E9%9D%96%E4%B8%9C%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dcjmyaatpv/>
{'lat': 31.96985873235598,
 'lng': 118.87182639943344,
 'location': '南京项目地址：文靖东路88号',
 'name': '东城金茂悦',
 'price': 0,
 'when': '2017-07-03'}
2018-04-12 12:32:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacela/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:32:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyshsjabryn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:32:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:32:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:32:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:32:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E9%AB%98%E8%B7%AF50%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:43 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.344984216195197,
 'lng': 118.92722832470832,
 'location': '南京项目地址：双高路50号',
 'name': '花样年花样城',
 'price': ' 8500',
 'when': '2017-12-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacera/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacera/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E6%96%B0%E5%8D%8E%E8%A5%BF%E8%B7%AF458%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:45 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.20805330579511,
 'lng': 118.7399702187509,
 'location': '南京项目地址：大厂新华西路458号',
 'name': '盘金华府',
 'price': 0,
 'when': '2014-06-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/>: Connection was refused by other side: 111: Connection refused.
2018-04-12 12:32:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BB%99%E6%9E%97%E8%A1%97%E9%81%93%E4%BF%9D%E5%88%A9%E7%A4%BC%E5%A2%85 HTTP/1.1" 200 137
2018-04-12 12:32:45 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.11097695649148,
 'lng': 118.9295337061967,
 'location': '南京项目地址：仙林街道保利礼墅',
 'name': '保利礼墅',
 'price': 0,
 'when': '2015-06-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_zrrjcaaeov/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E6%BA%AA%E8%A1%97%E9%81%93%E7%94%98%E6%B3%89%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhsyhaalja/>
{'lat': 31.759965542424297,
 'lng': 118.72924045440054,
 'location': '南京项目地址：横溪街道甘泉湖路1号',
 'name': '中浩山屿湖',
 'price': 0,
 'when': '2017-06-12'}
2018-04-12 12:32:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E5%8D%97%E8%B7%AF5%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:45 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99997241005109,
 'lng': 118.78497177739231,
 'location': '南京项目地址：雨花南路5号',
 'name': '长发都市诸公',
 'price': ' 864',
 'when': '2015-10-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E5%B1%B1%E8%A5%BF%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%ADS1%E7%A7%A6%E6%B7%AE%E4%B8%96%E5%AE%B6 HTTP/1.1" 200 137
2018-04-12 12:32:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyshsjabryn/>
{'lat': 31.648311742573938,
 'lng': 118.91514343402882,
 'location': '南京项目地址：横山西路碧桂园S1秦淮世家',
 'name': '碧桂园S1秦淮世家',
 'price': ' 60000',
 'when': '2018-03-17'}
2018-04-12 12:32:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BE%8A%E5%B1%B1%E5%8C%97%E8%B7%AF%E6%98%9F%E5%8F%B6%E7%BE%8A%E5%B1%B1%E6%B9%96%E8%8A%B1%E5%9B%AD HTTP/1.1" 200 136
2018-04-12 12:32:47 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12228406250346,
 'lng': 118.9464675340093,
 'location': '南京项目地址：羊山北路星叶羊山湖花园',
 'name': '星叶羊山湖花园',
 'price': 0,
 'when': '2014-10-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E5%85%83%E8%B7%AF%E4%B8%AD%E8%B7%AF128%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zrxhmdaatqp/>
{'lat': 32.04694030889066,
 'lng': 118.80071471620052,
 'location': '南京项目地址：天元路中路128号',
 'name': '中锐星湖名邸',
 'price': 0,
 'when': '2017-04-23'}
2018-04-12 12:32:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A1%BE%E5%AE%B6%E8%90%A5%E8%B7%AF%E7%B4%AB%E9%87%91%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:32:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjhfaafcw/>
{'lat': 32.044802270791855,
 'lng': 118.8854034320355,
 'location': '南京项目地址：顾家营路紫金华府',
 'name': '紫金华府',
 'price': 0,
 'when': '2017-12-25'}
2018-04-12 12:32:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BC%98%E6%99%AF%E5%A4%A7%E9%81%933888%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:47 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.902158491130926,
 'lng': 118.90369318104928,
 'location': '南京项目地址：弘景大道3888号',
 'name': '景枫你山',
 'price': 0,
 'when': '2016-08-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg29> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceth/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceth/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E7%8E%8B%E6%A1%A5%E8%B7%AF28%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:49 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.33955818255956,
 'lng': 118.84800376222998,
 'location': '南京项目地址：雄州街道王桥路28号',
 'name': '城开新都雅苑',
 'price': 0,
 'when': '2017-11-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:32:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg16> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:32:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%89%9B%E9%A6%96%E5%A4%A7%E9%81%93%E5%BA%86%E5%85%B4%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_njbgyaaldy/>
{'lat': 31.886978323966712,
 'lng': 118.71252324038538,
 'location': '南京项目地址：牛首大道庆兴路8号',
 'name': '南京碧桂园',
 'price': 0,
 'when': '2017-09-05'}
2018-04-12 12:32:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%8E%E5%9F%8E%E5%A4%A7%E9%81%93%E4%B8%87%E7%A7%91%E9%83%BD%E8%8D%9F%E5%8D%97%E8%8B%91 HTTP/1.1" 200 136
2018-04-12 12:32:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrt/>
{'lat': 31.97475979445248,
 'lng': 118.81085768852734,
 'location': '南京项目地址：明城大道万科都荟南苑',
 'name': '万科星荟',
 'price': 0,
 'when': '2017-10-29'}
2018-04-12 12:32:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%89%9B%E9%A6%96%E5%B1%B1%E5%A4%A7%E9%81%93121%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:49 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.918954454210063,
 'lng': 118.75165574782486,
 'location': '南京项目地址：牛首山大道121号',
 'name': '瑞安翠湖山',
 'price': ' 20000',
 'when': '2018-04-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg45> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:32:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:32:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:32:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%86%E5%86%9B%E5%A4%A7%E9%81%93%E9%9F%A9%E5%BA%9C%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yztaadtx/>
{'lat': 31.94294979560223,
 'lng': 118.78826271962814,
 'location': '南京项目地址：将军大道韩府路18号',
 'name': '滟紫台',
 'price': 0,
 'when': '2014-10-30'}
2018-04-12 12:32:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_dfryaaknc/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:32:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ycjydfaauoe/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_shshyaacka/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_djhfscaalag/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacete/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bjjcyxaabaj/>
{'lat': 32.05876455593678,
 'lng': 118.62066377476616,
 'location': '南京项目地址：雨山西路89号',
 'name': '北江锦城',
 'price': ' 24300',
 'when': '2017-11-01'}
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mlhwjaayyg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rqycaawis/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hycsxjaawkm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dsljaayua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xtjaawkz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:32:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_lntsyaatqn/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rshycaaksj/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlxlfaawai/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:32:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hdljaatpb/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdxmlyzxaavxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:32:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacete/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hymdaatgo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaazm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:32:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9C%88%E5%AE%89%E8%A1%9711%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:50 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.02460861962323,
 'lng': 118.74210601897207,
 'location': '南京项目地址：月安街11号',
 'name': '海玥名都',
 'price': 0,
 'when': '2017-04-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jrcfslaaudc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:32:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:32:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%8C%E6%B1%9F%E6%95%85%E5%B1%85%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:51 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.865264410601366,
 'lng': 118.47517450362449,
 'location': '南京项目地址：乌江故居路8号',
 'name': '江岸景城',
 'price': ' 15000',
 'when': '2015-02-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dhjxhcxymsaavuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:32:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacell/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacell/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:32:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg46> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E9%95%87%E8%A5%BF%E5%B1%B1%E5%A4%B4 HTTP/1.1" 200 133
2018-04-12 12:32:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.954170205823228,
 'lng': 118.93133649576195,
 'location': '南京项目地址：淳化镇西山头',
 'name': '梅龙湖无界',
 'price': 0,
 'when': '2015-10-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E4%B8%87%E5%AE%89%E5%8D%97%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rqycaawis/>
{'lat': 31.962191115716916,
 'lng': 118.88690470266143,
 'location': '南京项目地址：东山街道万安南路9号',
 'name': '融侨悦城',
 'price': 0,
 'when': '2018-03-30'}
2018-04-12 12:32:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zslxgkaayyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:32:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lgwxdhaavvc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:32:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhysaayxj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:32:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E8%97%8F%E5%A4%A7%E9%81%9312%E5%8F%B7%E5%BC%98%E9%98%B3 HTTP/1.1" 200 137
2018-04-12 12:32:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.94682158034673,
 'lng': 118.67416296037928,
 'location': '南京项目地址：龙藏大道12号弘阳',
 'name': '弘阳春上西江',
 'price': 0,
 'when': '2016-11-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8F%A3%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.323376930598535,
 'lng': 118.8191838325704,
 'location': '南京项目地址：龙池街道龙口路9号',
 'name': '香缇郡',
 'price': 0,
 'when': '2016-10-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacems/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacems/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:32:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%90%89%E5%B1%B1%E5%A4%A7%E9%81%939%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.861380358744533,
 'lng': 118.77282264452263,
 'location': '南京项目地址：吉山大道9号',
 'name': '景瑞春风十里',
 'price': ' 19000',
 'when': '2017-06-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mdjyslaadxi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:32:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltxfaawiy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:32:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg47> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceta/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:32:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceta/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:32:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceks/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:32:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceks/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%8E%B1%E8%8C%B5%E8%BE%BE%E8%B7%AF12%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dsljaayua/>
{'lat': 31.950984236736673,
 'lng': 118.86091033640727,
 'location': '南京项目地址：莱茵达路12号',
 'name': '都市丽景',
 'price': 0,
 'when': '2017-01-22'}
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlhbskpaaeco/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg6> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blxjyaabaz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg4)
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blzygyaaavy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacels/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacels/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg48> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8D%97%E8%A1%97%E9%81%93%E9%87%91%E8%BD%AE%E6%98%9F%E7%AB%8B%E6%96%B9 HTTP/1.1" 200 136
2018-04-12 12:32:54 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99799477275822,
 'lng': 118.78177238865749,
 'location': '南京项目地址：宁南街道金轮星立方',
 'name': '金轮星立方',
 'price': ' 60000',
 'when': '2015-12-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E6%B8%85%E6%B0%B4%E4%BA%AD%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlhbskpaaeco/>
{'lat': 31.919765529265728,
 'lng': 118.81406744370776,
 'location': '南京项目地址：秣陵街道清水亭西路188号',
 'name': '九龙湖别墅',
 'price': 0,
 'when': '2016-11-18'}
2018-04-12 12:32:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacema/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%91%E6%99%BA%E8%B7%AF9%E5%8F%B7%E3%80%8110%E5%8F%B7%E3%80%8111%E5%8F%B7%E3%80%8112%E5%8F%B7%E3%80%8113%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:54 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97029556775504,
 'lng': 118.81089211249278,
 'location': '南京项目地址：民智路9号、10号、11号、12号、13号',
 'name': '证大喜玛拉雅中心',
 'price': ' 20000',
 'when': '2018-01-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9F%8E%E5%8D%97%E6%B2%B3%E8%B7%AF%E4%BF%9D%E5%88%A9%E8%A5%BF%E6%B1%9F%E6%9C%88 HTTP/1.1" 200 141
2018-04-12 12:32:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_blxjyaabaz/>
{'lat': 32.04810818480485,
 'lng': 118.66452157400175,
 'location': '南京项目地址：城南河路保利西江月',
 'name': '保利西江月',
 'price': 0,
 'when': '2017-05-27'}
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sswhykpaawjt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:32:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:32:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacema/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E6%96%B0%E8%B7%AF%E6%8B%9B%E5%95%86%E5%85%B0%E6%BA%AA%E8%B0%B7 HTTP/1.1" 200 136
2018-04-12 12:32:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.65760622534108,
 'lng': 119.04859890125368,
 'location': '南京项目地址：永新路招商兰溪谷',
 'name': '招商兰溪谷',
 'price': 0,
 'when': '2017-11-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E4%B9%90%E8%B7%AF%E6%B4%AA%E5%AE%B6%E5%9B%AD1%E5%8F%B7 HTTP/1.1" 200 143
2018-04-12 12:32:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0053428312632,
 'lng': 118.80204028545512,
 'location': '南京项目地址：永乐路洪家园1号',
 'name': '绿国万象都荟',
 'price': ' 50000',
 'when': '2015-11-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:32:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.123523391191696,
 'lng': 118.72947850536069,
 'location': '南京项目地址：浦珠北路59号',
 'name': '大华锦绣华城香鸢美颂',
 'price': ' 24600',
 'when': '2017-11-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rsldrfaawky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:32:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg49> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:32:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacerg/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:32:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg50> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacerc/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:32:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacena/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%95%BF%E4%BA%AD%E8%A1%9759%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:32:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_blzygyaaavy/>
{'lat': 31.914770739009395,
 'lng': 118.83304208150336,
 'location': '南京项目地址：秣陵街道长亭街59号',
 'name': '保利中央公园东苑',
 'price': 0,
 'when': '2017-06-15'}
2018-04-12 12:32:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rshycaaksj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdljaatpb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lntsyaatqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rshfaatdn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smzsysaakkg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zlxyaatbm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lyzyaarxs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg5)
2018-04-12 12:32:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacena/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacent/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E6%B9%96%E8%A1%97%E9%81%93%E9%80%9A%E6%B2%B3%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:57 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.45045312201094,
 'lng': 118.94784796098479,
 'location': '南京项目地址：金牛湖街道通河路9号',
 'name': '嘉恒有山',
 'price': ' 9550',
 'when': '2017-12-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjwlcaawkw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg17> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:32:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacent/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:32:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BB%84%E5%B1%B1%E5%B2%AD%E8%B7%AF%E4%B9%9D%E6%9C%88%E6%A3%AE%E6%9E%97 HTTP/1.1" 200 143
2018-04-12 12:32:57 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08342667185487,
 'lng': 118.62232126700839,
 'location': '南京项目地址：黄山岭路九月森林',
 'name': '九月森林',
 'price': 0,
 'when': '2018-03-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceof/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceof/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceob/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:32:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceob/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:58 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:32:58 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:32:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacelq/>: HTTP status code is not handled or not allowed
2018-04-12 12:32:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:32:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:32:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:32:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg30> (referer: https://nj.fang.lianjia.com/loupan/pg/pg29)
2018-04-12 12:32:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E6%9E%97%E5%9C%BA%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rshycaaksj/>
{'lat': 32.32446249240832,
 'lng': 118.85133622323109,
 'location': '南京项目地址：龙池街道林场路1号',
 'name': '荣盛花语城',
 'price': 0,
 'when': '2017-08-05'}
2018-04-12 12:32:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceot/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:32:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%A7%E9%BE%99%E6%B9%96%E5%A4%A7%E9%81%931%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wlhxzaackd/>
{'lat': 31.731203746093776,
 'lng': 119.0553388291052,
 'location': '南京项目地址：卧龙湖大道1号',
 'name': '卧龙湖小镇',
 'price': ' 13500',
 'when': '2018-02-03'}
2018-04-12 12:32:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceot/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A2%85%E5%85%B4%E8%B7%AF%E5%96%84%E6%B0%B4%E6%B9%BE%E8%8A%B1%E5%9B%AD HTTP/1.1" 200 144
2018-04-12 12:32:59 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.958704964869618,
 'lng': 118.73669664435383,
 'location': '南京项目地址：梅兴路善水湾花园',
 'name': '善水湾花园',
 'price': 0,
 'when': '2013-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%92%E9%BA%9F%E8%A1%97%E9%81%93%E8%A2%81%E5%AE%B6%E8%BE%B9%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:32:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:32:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdljaatpb/>
{'lat': 32.02524213109228,
 'lng': 118.92961737976174,
 'location': '南京项目地址：麒麟街道袁家边路9号',
 'name': '恒大龙珺',
 'price': 0,
 'when': '2017-07-08'}
2018-04-12 12:32:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:32:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:32:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:32:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E7%86%9F%E8%A1%97%E9%81%93%E6%B6%A6%E6%B9%96%E5%A4%A7%E9%81%93398%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:32:59 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.873594814596018,
 'lng': 118.97674222511495,
 'location': '南京项目地址：湖熟街道润湖大道398号',
 'name': '梁台煦府',
 'price': 0,
 'when': '2016-12-10'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:32:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:32:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:33:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceow/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:33:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceow/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg51> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:33:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%8E%E5%9F%8E%E5%A4%A7%E9%81%93%E4%B8%87%E7%A7%91%E9%83%BD%E8%8D%9F%E5%8D%97%E8%8B%91 HTTP/1.1" 200 136
2018-04-12 12:33:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97475979445248,
 'lng': 118.81085768852734,
 'location': '南京项目地址：明城大道万科都荟南苑',
 'name': '万科星荟',
 'price': 0,
 'when': '2017-07-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%BC%E8%87%B4%E8%A5%BF%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lntsyaatqn/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：格致西路1号',
 'name': '鲁能泰山7号院',
 'price': 0,
 'when': '2017-07-19'}
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E6%A1%A5%E8%A5%BF%E8%B7%AF162%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rshfaatdn/>
{'lat': 32.33635869765098,
 'lng': 118.84812434355814,
 'location': '南京项目地址：雄州街道桥西路162号',
 'name': '荣盛华府',
 'price': 0,
 'when': '2017-07-15'}
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacers/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E9%A9%AC%E8%B7%AF%E4%B8%96%E8%8C%82%E6%8B%9B%E5%95%86%E8%AF%AD%E5%B1%B1 HTTP/1.1" 200 143
2018-04-12 12:33:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smzsysaakkg/>
{'lat': 32.07140443035624,
 'lng': 118.91366956082265,
 'location': '南京项目地址：金马路世茂招商语山',
 'name': '世茂招商语山',
 'price': 0,
 'when': '2016-10-29'}
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E9%9E%8D%E8%A1%97%E9%81%93%E9%B9%AD%E5%B2%9B%E5%8D%97%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.5387256198191,
 'lng': 118.81897438994582,
 'location': '南京项目地址：马鞍街道鹭岛南路3号',
 'name': '荣盛鹭岛荣府',
 'price': ' 11500',
 'when': '2018-03-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_shshyaacka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjmyaawmp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsylaatbk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zyhfaaxbt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg52> (referer: https://nj.fang.lianjia.com/loupan/pg/pg51)
2018-04-12 12:33:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacers/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E9%B9%8F%E5%B1%B1%E8%B7%AF28%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zlxyaatbm/>
{'lat': 31.924654849950382,
 'lng': 118.90626134667176,
 'location': '南京项目地址：淳化街道鹏山路28号',
 'name': '中粮祥云',
 'price': 0,
 'when': '2016-11-05'}
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg31> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E5%B1%B1%E8%A5%BF%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lyzyaarxs/>
{'lat': 32.05876455593678,
 'lng': 118.62066377476616,
 'location': '南京项目地址：雨山西路89号',
 'name': '路易庄园',
 'price': ' 25000',
 'when': '2018-01-19'}
2018-04-12 12:33:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E9%95%87%E5%81%87%E6%97%A5%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:02 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09294316228797,
 'lng': 118.52460713295669,
 'location': '南京项目地址：汤泉镇假日路8号',
 'name': '山河水花园',
 'price': ' 25000',
 'when': '2014-04-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:02 [scrapy.extensions.logstats] INFO: Crawled 87 pages (at 35 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:33:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:02 [scrapy.extensions.logstats] INFO: Crawled 474 pages (at 84 pages/min), scraped 239 items (at 17 items/min)
2018-04-12 12:33:02 [scrapy.extensions.logstats] INFO: Crawled 278 pages (at 104 pages/min), scraped 158 items (at 10 items/min)
2018-04-12 12:33:02 [scrapy.extensions.logstats] INFO: Crawled 57 pages (at 57 pages/min), scraped 50 items (at 50 items/min)
2018-04-12 12:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg53> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzyyxsaawjw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djgyaabbs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhgjsqaatbj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%96%84%E6%B0%B4%E6%B9%BE%E8%A5%BF%E4%BE%A7%E7%A6%B9%E6%B4%B2%E6%98%A0%E6%9C%88%E6%BA%AA%E5%B1%B1 HTTP/1.1" 200 143
2018-04-12 12:33:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yzyyxsaawjw/>
{'lat': 31.958704964869618,
 'lng': 118.73669664435383,
 'location': '南京项目地址：善水湾西侧禹洲映月溪山',
 'name': '禹洲映月溪山',
 'price': 0,
 'when': '2017-04-28'}
2018-04-12 12:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxyscaadwd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wylzqhyaatpq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jstygqcaaayk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceud/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceul/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceud/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceul/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceql/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg54> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceql/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E5%8F%8C%E5%AE%A2%E8%B7%AF97%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.34349204726423,
 'lng': 118.84417012307615,
 'location': '南京项目地址：雄州街道双客路97号',
 'name': '紫晶未来城',
 'price': 0,
 'when': '2016-09-07'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njbjzbjdswqabcno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wdmabepd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zgtjqxcabefw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrrjcaaeov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:33:04 [scrapy.extensions.logstats] INFO: Crawled 152 pages (at 44 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:33:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%95%E5%BA%9C%E4%B8%9C%E8%B7%AF228%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12191964138096,
 'lng': 118.81329580556283,
 'location': '南京项目地址：幕府东路228号',
 'name': '紫金铭苑',
 'price': 0,
 'when': '2017-07-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E7%87%95%E4%B8%9C%E8%B7%AF%E6%8B%9B%E5%95%861872%E5%85%AC%E5%9B%AD%E9%87%8C HTTP/1.1" 200 132
2018-04-12 12:33:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1265750663835,
 'lng': 118.83957790985149,
 'location': '南京项目地址：钟燕东路招商1872公园里',
 'name': '招商1872公园里',
 'price': 0,
 'when': '2017-03-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:33:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%BE%E6%9D%A8%E8%B7%AF%E7%B4%AB%E8%89%BA%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 136
2018-04-12 12:33:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：松杨路紫艺华府',
 'name': '紫艺华府',
 'price': 0,
 'when': '2018-01-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg10> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfryaaknc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycjydfaauoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djhfscaalag/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%8B%9C%E5%B2%97%E8%B7%AF%E5%A4%A7%E5%8F%91%E8%9E%8D%E6%82%A6 HTTP/1.1" 200 144
2018-04-12 12:33:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.03761727573808,
 'lng': 118.87577728900419,
 'location': '南京项目地址：双拜岗路大发融悦',
 'name': '大发融悦',
 'price': 0,
 'when': '2016-04-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97169%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05156767640222,
 'lng': 118.89683388187007,
 'location': '南京项目地址：马群街169号',
 'name': '银城君颐东方',
 'price': ' 43000',
 'when': '2017-12-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E9%95%87%E6%B1%9F%E6%98%9F%E6%A1%A5%E7%BA%BF HTTP/1.1" 200 138
2018-04-12 12:33:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djgyaabbs/>
{'lat': 32.09369697857316,
 'lng': 118.52483283221608,
 'location': '南京项目地址：汤泉镇江星桥线',
 'name': '大吉公元',
 'price': 0,
 'when': '2016-09-14'}
2018-04-12 12:33:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E4%BA%94%E8%B7%AF%E7%94%B5%E5%BB%BA%E6%B5%B7%E8%B5%8B%E5%B0%9A%E5%9F%8E HTTP/1.1" 200 141
2018-04-12 12:33:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.137634319277,
 'lng': 118.84295688872218,
 'location': '南京项目地址：经五路电建海赋尚城',
 'name': '电建海赋尚城',
 'price': ' 25800',
 'when': '2018-01-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smmxjaakrd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E7%87%95%E6%B1%9F%E8%B7%AF201%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:06 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.06860445880062,
 'lng': 118.76505691316264,
 'location': '南京项目地址：鼓楼区燕江路201号',
 'name': '江山汇金',
 'price': ' 17100',
 'when': '2014-05-07'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blsdgcabdzt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:33:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg32> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:33:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%87%95%E5%AD%90%E7%9F%B6%E8%A1%97%E9%81%93%E4%B8%AD%E8%88%AA%E5%9B%BD%E9%99%85%E7%A4%BE%E5%8C%BA HTTP/1.1" 200 137
2018-04-12 12:33:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhgjsqaatbj/>
{'lat': 32.15160833098263,
 'lng': 118.84955152284388,
 'location': '南京项目地址：燕子矶街道中航国际社区',
 'name': '中航国际社区',
 'price': 0,
 'when': '2017-10-30'}
2018-04-12 12:33:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rsldrfaawky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyhgssaarrc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E7%A5%9E%E5%87%A4%E8%B7%AF1169%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hxyscaadwd/>
{'lat': 32.000159660995386,
 'lng': 118.95595120578673,
 'location': '南京项目地址：东山街道神凤路1169号',
 'name': '鸿信云深处',
 'price': ' 1762',
 'when': '2013-07-14'}
2018-04-12 12:33:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:33:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E7%91%9E%E6%96%87%E8%B7%AF199%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：淳化街道瑞文路199号',
 'name': '世茂梦享家',
 'price': 0,
 'when': '2016-04-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htygjczgcaakog/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znjyaaksn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xhycbmlsaakqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E6%B7%B3%E6%BA%AA%E9%95%87%E5%AE%9D%E5%A1%94%E8%B7%AF269%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.33618242769404,
 'lng': 118.9089895903361,
 'location': '南京项目地址：高淳淳溪镇宝塔路269号',
 'name': '红太阳国际财智广场',
 'price': 0,
 'when': '2016-04-10'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF%E4%B8%87%E8%BE%BE%E8%8C%82 HTTP/1.1" 200 135
2018-04-12 12:33:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.13304989681055,
 'lng': 118.9886366904625,
 'location': '南京项目地址：守敬路万达茂',
 'name': '万达茂',
 'price': ' 17000',
 'when': '2018-03-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BD%AF%E4%BB%B6%E5%A4%A7%E9%81%93%E4%B8%AD%E5%8D%97%E9%94%A6%E8%8B%91 HTTP/1.1" 200 144
2018-04-12 12:33:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.984256699458975,
 'lng': 118.75651496529456,
 'location': '南京项目地址：软件大道中南锦苑',
 'name': '中南锦苑',
 'price': 0,
 'when': '2016-09-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E7%99%BD%E9%A9%AC%E8%B7%AF%E4%B8%8E%E7%8B%AE%E5%B1%B1%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:33:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08258412514195,
 'lng': 118.63632209768683,
 'location': '南京项目地址：浦口区白马路与狮山路交汇处',
 'name': '旭辉银城白马澜山',
 'price': 0,
 'when': '2017-12-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fhhrdxaaclk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceup/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfptmhjaaqjj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceup/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:33:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacett/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacett/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceue/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:33:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg55> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:33:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceue/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E5%85%83%E4%B8%AD%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wylzqhyaatpq/>
{'lat': 31.93623568074372,
 'lng': 118.84629476472597,
 'location': '南京项目地址：天元中路99号',
 'name': '武夷绿洲沁荷苑',
 'price': 0,
 'when': '2017-07-03'}
2018-04-12 12:33:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg33> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceus/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E5%B0%A7%E8%B7%AF327%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12259447503586,
 'lng': 118.84063643989731,
 'location': '南京项目地址：迈尧路327号',
 'name': '中国铁建青秀城',
 'price': 0,
 'when': '2014-12-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceus/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%95%87%E5%8D%97%E6%B2%B3%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.06209076570978,
 'lng': 118.68209046428447,
 'location': '南京项目地址：镇南河路99号',
 'name': '正荣润江城',
 'price': 0,
 'when': '2017-07-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyzsgyxabgwq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyjfabhht/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg18> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njcfgcabgvg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_2jbjhabhfk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgybasjabgyc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdwryabhfp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:33:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E5%B9%B3%E5%8D%97%E8%B7%AF%E4%B8%8E%E7%99%BD%E4%B8%8B%E8%B7%AF%E4%BA%A4%E7%95%8C%E5%A4%84 HTTP/1.1" 200 136
2018-04-12 12:33:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.03553521855789,
 'lng': 118.79736364858033,
 'location': '南京项目地址：太平南路与白下路交界处',
 'name': '凤凰和睿大厦',
 'price': ' 22000',
 'when': '时间待定'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg11> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wycaakob/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_heshyhggaakok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sclfaakub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceum/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceum/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E5%8D%8E%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jstygqcaaayk/>
{'lat': 32.32157817364182,
 'lng': 118.81476070379864,
 'location': '南京项目地址：龙华路8号',
 'name': '金盛田阳光青城',
 'price': 0,
 'when': '2016-06-12'}
2018-04-12 12:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hrxflaakqa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceww/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:33:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceww/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg56> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%96%B0%E6%B5%A6%E8%B7%AF128%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.07216834555913,
 'lng': 118.65572949722356,
 'location': '南京项目地址：江浦街道新浦路128号',
 'name': '宝隆时代广场',
 'price': ' 16500',
 'when': '2017-11-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E5%87%A4%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.652751200874587,
 'lng': 119.0233543470155,
 'location': '南京项目地址：栖凤路68号',
 'name': '弘阳禹洲时光印象',
 'price': 0,
 'when': '2017-12-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E6%96%B0%E8%B7%AF%E5%BC%98%E9%98%B3%E7%87%95%E6%B1%9F%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.14416255725624,
 'lng': 118.83407420848347,
 'location': '南京项目地址：太新路弘阳燕江府',
 'name': '弘阳燕江府',
 'price': 0,
 'when': '2017-06-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E6%A1%A5%E5%8C%97%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.01816879567414,
 'lng': 118.74715685147487,
 'location': '南京项目地址：大桥北路9号',
 'name': '弘阳印象华庭',
 'price': 0,
 'when': '2017-03-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%B1%B1%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09260114030094,
 'lng': 118.81803364578863,
 'location': '南京项目地址：红山路88号',
 'name': '南京常发广场',
 'price': ' 25000',
 'when': '2015-08-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_2jbjhabhfk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 45, in parse_html
    item["name"] = response.xpath('//h1/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceux/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceux/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg34> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E9%9E%8D%E8%A1%97%E9%81%93%E9%B9%AD%E5%B2%9B%E5%8D%97%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rsldrfaawky/>
{'lat': 32.5387256198191,
 'lng': 118.81897438994582,
 'location': '南京项目地址：马鞍街道鹭岛南路3号',
 'name': '荣盛鹭岛荣府',
 'price': ' 11500',
 'when': '2018-03-24'}
2018-04-12 12:33:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacext/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacext/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%87%A4%E6%B1%87%E5%A4%A7%E9%81%93%E6%98%8E%E5%8F%91%E6%B5%A6%E6%B3%B0%E6%A2%A6%E5%B9%BB%E5%AE%B6 HTTP/1.1" 200 143
2018-04-12 12:33:15 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.92740779796182,
 'lng': 118.64778341958687,
 'location': '南京项目地址：凤汇大道明发浦泰梦幻家',
 'name': '明发浦泰梦幻家',
 'price': 0,
 'when': '2017-09-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%81%E9%98%B3%E4%B8%9C%E8%B7%AF901%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:15 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滁阳东路901号',
 'name': '碧桂园北岸世家',
 'price': 0,
 'when': '2017-07-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E5%8C%97%E8%B7%AF279%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:15 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08261037776124,
 'lng': 118.76973175941542,
 'location': '南京项目地址：中山北路279号',
 'name': '金鼎湾如院',
 'price': 0,
 'when': '2015-10-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg19> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:33:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bltyabgvd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tyljxyabgtm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:33:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%94%E5%A4%A9%E5%A4%A7%E8%A1%97%E4%BF%9D%E5%88%A9%E5%A4%A9%E6%82%A6 HTTP/1.1" 200 145
2018-04-12 12:33:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.03108091466837,
 'lng': 118.73254774489833,
 'location': '南京项目地址：应天大街保利天悦',
 'name': '保利天悦',
 'price': 0,
 'when': '2017-11-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjgxtabgdk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:33:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%B0%B7%E9%87%8C%E8%A1%97%E9%81%93%E6%82%A6%E6%B9%96%E8%B7%AF16%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyhgssaarrc/>
{'lat': 31.865723915051426,
 'lng': 118.73198543798807,
 'location': '南京项目地址：谷里街道悦湖路16号',
 'name': '碧桂园湖光山色',
 'price': ' 900',
 'when': '2017-12-23'}
2018-04-12 12:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyjfaatdo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:33:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg57> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:33:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%9D%E9%BE%99%E5%B1%B1%E8%B7%AF%E4%B8%87%E6%82%A6%E5%9F%8E HTTP/1.1" 200 143
2018-04-12 12:33:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.369820090663627,
 'lng': 118.95197910453356,
 'location': '南京项目地址：九龙山路万悦城',
 'name': '万悦城',
 'price': 0,
 'when': '2017-05-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.393150940897428,
 'lng': 118.97196008794114,
 'location': '南京项目地址：双湖路1号',
 'name': '海尔双湖壹号公馆',
 'price': ' 8300',
 'when': '2017-09-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjjlhaaksm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bltyabmqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:33:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E4%B8%83%E9%87%8C%E8%B7%AF%E4%B8%8E%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:33:18 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0913457771416,
 'lng': 118.65014507465395,
 'location': '南京项目地址：江浦街道七里路与沿山大道交汇处',
 'name': '通宇林景熙园',
 'price': 0,
 'when': '2017-08-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg20> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:33:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyhsabezj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:33:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%A7%E5%8C%96%E8%A1%97%E9%81%93%E5%89%8D%E5%A1%98%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hrxflaakqa/>
{'lat': 32.138809818069916,
 'lng': 118.89732473396684,
 'location': '南京项目地址：尧化街道前塘路9号',
 'name': '华润幸福里',
 'price': ' 18500',
 'when': '2017-09-30'}
2018-04-12 12:33:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E4%B8%AD%E5%BB%BA%E5%9B%BD%E7%86%99%E5%8F%B0 HTTP/1.1" 200 142
2018-04-12 12:33:18 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.06590199137902,
 'lng': 118.65369290890968,
 'location': '南京项目地址：新浦路中建国熙台',
 'name': '中建国熙台',
 'price': 0,
 'when': '2017-06-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E6%96%B0%E8%B7%AF%E5%BC%98%E9%98%B3%E7%87%95%E6%B1%9F%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:33:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyjfaatdo/>
{'lat': 32.14416255725624,
 'lng': 118.83407420848347,
 'location': '南京项目地址：太新路弘阳燕江府',
 'name': '弘阳燕江府',
 'price': ' 25800',
 'when': '2016-12-29'}
2018-04-12 12:33:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%87%E6%99%AF%E5%8C%97%E8%B7%AF%E4%BF%9D%E5%88%A9%E5%A0%82%E6%82%A6 HTTP/1.1" 200 143
2018-04-12 12:33:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bltyabmqd/>
{'lat': 31.987086765521944,
 'lng': 118.81312602132991,
 'location': '南京项目地址：汇景北路保利堂悦',
 'name': '保利堂悦',
 'price': ' 350',
 'when': '2016-04-23'}
2018-04-12 12:33:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg35> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:33:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjllycabmje/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:33:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:33:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcjxthyabmmo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:33:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%8A%E6%B2%B3%E6%96%B0%E5%9F%8E%E9%9B%85%E5%B1%85%E4%B9%90%E6%9E%97%E8%AF%AD%E5%9F%8E HTTP/1.1" 200 136
2018-04-12 12:33:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yjllycabmje/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：汊河新城雅居乐林语城',
 'name': '雅居乐林语城',
 'price': 0,
 'when': '2017-12-16'}
2018-04-12 12:33:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E5%B1%B1%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E5%92%8C%E5%B1%B1 HTTP/1.1" 200 135
2018-04-12 12:33:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04095857741548,
 'lng': 118.85225558502222,
 'location': '南京项目地址：钟山路新城璞樾和山',
 'name': '新城璞樾和山',
 'price': ' 30000',
 'when': '2018-02-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwqlnhyabgpx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:33:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkapysaatgt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:33:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjjzaatbs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:33:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%9C%B0%E9%93%81%E4%BA%8C%E5%8F%B7%E7%BA%BF%E5%A4%A9%E8%BF%88%E5%B9%BF%E5%9C%BA%E6%B2%B9%E5%9D%8A%E6%A1%A5%E7%AB%99 HTTP/1.1" 200 139
2018-04-12 12:33:21 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.971841104007034,
 'lng': 118.72764980327469,
 'location': '南京项目地址：建邺地铁二号线天迈广场油坊桥站',
 'name': '首创立方',
 'price': ' 20000',
 'when': '2016-04-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg7> (referer: https://nj.fang.lianjia.com/loupan/pg/pg6)
2018-04-12 12:33:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%93%E6%BA%AA%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjjlhaaksm/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：卓溪路10号',
 'name': '中交锦兰荟',
 'price': 0,
 'when': '2016-07-07'}
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wymsyaakoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dphaakno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceug/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg12> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aadlk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltllxzaacjt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhjyaadjj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyfqsaaaclf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg8> (referer: https://nj.fang.lianjia.com/loupan/pg/pg7)
2018-04-12 12:33:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A1%83%E6%BA%AA%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rcjxthyabmmo/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：桃溪路1号',
 'name': '融创玖溪桃花源',
 'price': ' 395',
 'when': '2018-03-25'}
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ylfablzi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfbzxcabmjd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:33:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B3%B0%E5%B1%B1%E8%A5%BF%E8%B7%AF%E5%BE%A1%E6%BE%9C%E5%BA%9C HTTP/1.1" 200 135
2018-04-12 12:33:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ylfablzi/>
{'lat': 32.15139493848411,
 'lng': 118.71872790211911,
 'location': '南京项目地址：泰山西路御澜府',
 'name': '御澜府',
 'price': ' 25800',
 'when': '2017-11-08'}
2018-04-12 12:33:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg9> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfxlsyaaedw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jfnsaaelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhmdaakpp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8D%8E%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:33:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.31827364260565,
 'lng': 118.81844075425253,
 'location': '南京项目地址：龙池街道龙华路66号',
 'name': '骋望七里楠花园',
 'price': 0,
 'when': '2015-02-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%99%BD%E9%A9%AC%E8%B7%AF90%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dfxlsyaaedw/>
{'lat': 32.08732150414787,
 'lng': 118.63490312801513,
 'location': '南京项目地址：白马路90号',
 'name': '东方熙龙山院',
 'price': 0,
 'when': '2012-12-20'}
2018-04-12 12:33:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%AF%E9%99%B5%E8%B7%AF7%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08813762841439,
 'lng': 118.87777963354526,
 'location': '南京项目地址：环陵路7号',
 'name': '钟山国际高尔夫',
 'price': 0,
 'when': '2013-06-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkysjaalru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_attycaadid/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lsqcjqaacmb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hjfhsaahno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%95%BF%E6%B1%9F%E8%B7%AF%E8%A5%BF%E4%BE%A7%E6%98%8E%E5%8F%91%E5%8C%97%E7%AB%99%E6%96%B0%E5%9F%8E HTTP/1.1" 200 135
2018-04-12 12:33:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfbzxcabmjd/>
{'lat': 32.04955537268256,
 'lng': 118.8014603106721,
 'location': '南京项目地址：长江路西侧明发北站新城',
 'name': '明发北站新城',
 'price': 0,
 'when': '2017-11-22'}
2018-04-12 12:33:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:33:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceva/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:33:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetq/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:33:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetn/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:33:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BB%93%E5%AE%B6%E5%B7%B7%E4%B8%87%E7%A7%91%E5%AE%89%E5%93%81%E5%9B%AD%E8%88%8D HTTP/1.1" 200 131
2018-04-12 12:33:25 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.9649933148731,
 'lng': 118.76593279846456,
 'location': '南京项目地址：仓家巷万科安品园舍',
 'name': '万科安品园舍',
 'price': 0,
 'when': '2016-06-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytaaycz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:33:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsabdir/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:33:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BC%98%E6%99%AF%E5%A4%A7%E9%81%933888%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jfnsaaelc/>
{'lat': 31.902158491130926,
 'lng': 118.90369318104928,
 'location': '南京项目地址：弘景大道3888号',
 'name': '景枫你山',
 'price': 0,
 'when': '2016-08-26'}
2018-04-12 12:33:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetl/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:33:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xycabkna/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sjxnfabhsz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E5%B9%B3%E5%92%8C%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wymsyaakoe/>
{'lat': 31.943934853497655,
 'lng': 118.94156811107989,
 'location': '南京项目地址：淳化街道平和路8号',
 'name': '武夷名仕园',
 'price': 0,
 'when': '2015-10-21'}
2018-04-12 12:33:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgysjcbabisk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:33:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:33:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceve/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:33:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E5%8D%97%E8%B7%AF688%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.915202323802344,
 'lng': 118.86477525813511,
 'location': '南京项目地址：秣陵街道竹山南路688号',
 'name': '罗托鲁拉小镇',
 'price': 0,
 'when': '2016-04-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E6%B9%96%E8%B7%AF100%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.696231584053706,
 'lng': 119.11840755372283,
 'location': '南京项目地址：金湖路100号',
 'name': '金湖家园',
 'price': 0,
 'when': '2011-08-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%A1%AB%E6%B9%96%E4%B8%9C%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.947722743322984,
 'lng': 118.88189242724522,
 'location': '南京项目地址：衫湖东路18号',
 'name': '星叶枫情水岸',
 'price': 0,
 'when': '2015-03-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fdyzsyxaampu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E7%81%B5%E8%A1%9750%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.044111682631645,
 'lng': 118.87556409864904,
 'location': '南京项目地址：钟灵街50号',
 'name': '五矿晏山居',
 'price': 0,
 'when': '2017-07-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%8E%E5%9F%8E%E5%A4%A7%E9%81%93%E4%BB%A5%E8%A5%BF%E4%B8%AD%E4%BA%A4%E9%94%A6%E8%87%B4 HTTP/1.1" 200 136
2018-04-12 12:33:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97475979445248,
 'lng': 118.81085768852734,
 'location': '南京项目地址：明城大道以西中交锦致',
 'name': '中交锦致',
 'price': 0,
 'when': '2017-07-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcjctdaaxrj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:33:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E5%9B%BA%E5%9F%8E%E9%95%87%E8%82%B2%E6%89%8D%E8%A5%BF%E8%B7%AF91%E5%8F%B7%EF%BC%88%E5%AE%81%E5%AE%A3%E5%85%AC%E8%B7%AF%E4%B8%9C%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:33:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhmdaakpp/>
{'lat': 31.31262210058944,
 'lng': 118.97510527831135,
 'location': '南京项目地址：高淳固城镇育才西路91号（宁宣公路东侧）',
 'name': '景湖名都',
 'price': 0,
 'when': '2014-11-12'}
2018-04-12 12:33:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sybjbdaamiq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%9F%E8%B7%AF30%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sybjbdaamiq/>
{'lat': 32.10314358339629,
 'lng': 118.74617782513008,
 'location': '南京项目地址：龙江路30号',
 'name': '深业滨江半岛',
 'price': ' 38700',
 'when': '2017-12-25'}
2018-04-12 12:33:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg10> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%9F%E7%81%AB%E8%B7%AF%E6%98%9F%E6%82%A6%E5%9F%8E HTTP/1.1" 200 136
2018-04-12 12:33:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xycabkna/>
{'lat': 32.16673496276866,
 'lng': 118.70268689027152,
 'location': '南京项目地址：星火路星悦城',
 'name': '星悦城',
 'price': ' 16000',
 'when': '2018-02-24'}
2018-04-12 12:33:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gsyaapuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_shshyaacka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8F%A0%E6%B3%89%E8%A5%BF%E8%B7%AF%E4%B8%89%E9%87%91%E9%91%AB%E5%AE%81%E5%BA%9C HTTP/1.1" 200 142
2018-04-12 12:33:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sjxnfabhsz/>
{'lat': 32.05495625325235,
 'lng': 118.63701904801674,
 'location': '南京项目地址：珠泉西路三金鑫宁府',
 'name': '三金鑫宁府',
 'price': ' 25600',
 'when': '2017-12-09'}
2018-04-12 12:33:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A6%E6%B7%AE%E5%A4%A7%E9%81%93399%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.645263048037307,
 'lng': 119.0541065336066,
 'location': '南京项目地址：秦淮大道399号',
 'name': '爱涛天岳城',
 'price': 0,
 'when': '2018-01-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E7%91%B6%E8%B7%AF7%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09198071246321,
 'lng': 118.65432397571688,
 'location': '南京项目地址：七瑶路7号',
 'name': '明发悦庭',
 'price': ' 18500',
 'when': '2017-09-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A5%94%E9%A9%AC%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E9%92%9F%E5%B1%B1 HTTP/1.1" 200 136
2018-04-12 12:33:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08330568277308,
 'lng': 118.91771165983776,
 'location': '南京项目地址：奔马路新城璞樾钟山',
 'name': '新城璞樾钟山',
 'price': ' 900',
 'when': '2017-12-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E6%BA%A7%E6%B0%B4%E5%8E%BF%E4%B8%9C%E5%B1%8F%E9%95%87 HTTP/1.1" 200 138
2018-04-12 12:33:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dphaakno/>
{'lat': 31.722363055816007,
 'lng': 119.03588719018546,
 'location': '南京项目地址：南京溧水县东屏镇',
 'name': '东屏湖9号',
 'price': 0,
 'when': '2013-01-24'}
2018-04-12 12:33:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceug/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcysabltv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qhyzabnwc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A1%B6%E5%B1%B1%E8%A1%97%E9%81%93%E5%AE%9A%E5%90%91%E6%B2%B3%E8%A5%BF%E4%BE%A7 HTTP/1.1" 200 139
2018-04-12 12:33:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gsyaapuz/>
{'lat': 32.12858574755484,
 'lng': 118.69544350619863,
 'location': '南京项目地址：顶山街道定向河西侧',
 'name': '观山悦',
 'price': ' 25500',
 'when': '2017-12-27'}
2018-04-12 12:33:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E6%B3%89%E9%95%87%E5%81%87%E6%97%A5%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_shshyaacka/>
{'lat': 32.09294316228797,
 'lng': 118.52460713295669,
 'location': '南京项目地址：汤泉镇假日路8号',
 'name': '山河水花园',
 'price': ' 25000',
 'when': '2014-04-30'}
2018-04-12 12:33:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfryaaknc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hynhycaakrk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycjydfaauoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djhfscaalag/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rachsaahns/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cfdszgaacay/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg8)
2018-04-12 12:33:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%8B%9C%E5%B2%97%E8%B7%AF%E5%A4%A7%E5%8F%91%E8%9E%8D%E6%82%A6 HTTP/1.1" 200 144
2018-04-12 12:33:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dfryaaknc/>
{'lat': 32.03761727573808,
 'lng': 118.87577728900419,
 'location': '南京项目地址：双拜岗路大发融悦',
 'name': '大发融悦',
 'price': 0,
 'when': '2016-04-26'}
2018-04-12 12:33:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg36> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E9%AB%98%E8%B7%AF50%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hynhycaakrk/>
{'lat': 31.344984216195197,
 'lng': 118.92722832470832,
 'location': '南京项目地址：双高路50号',
 'name': '花样年花样城',
 'price': ' 8500',
 'when': '2017-12-06'}
2018-04-12 12:33:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hsjlwaaqfu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%A5%E5%87%A4%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.78379644297444,
 'lng': 118.86052299785104,
 'location': '南京项目地址：来凤路18号',
 'name': '朗诗青春街区',
 'price': 0,
 'when': '2017-11-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%83%AD%E5%BA%84%E9%95%87%E6%9C%BA%E5%9C%BA%E5%A4%A7%E9%81%93%E5%8D%97%E7%A2%A7%E6%A1%82%E5%9B%AD%E4%B8%96%E7%BA%AA%E5%9F%8E%E9%82%A6 HTTP/1.1" 200 134
2018-04-12 12:33:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgysjcbabisk/>
{'lat': 31.346944453868932,
 'lng': 118.89424983420618,
 'location': '南京项目地址：郭庄镇机场大道南碧桂园世纪城邦',
 'name': '碧桂园世纪城邦',
 'price': ' 12000',
 'when': '2017-08-12'}
2018-04-12 12:33:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdfchtabilb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xlqpcsqabirq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%B1%B1%E5%9B%BD%E5%AE%B6%E6%A3%AE%E6%9E%97%E5%85%AC%E5%9B%AD HTTP/1.1" 200 136
2018-04-12 12:33:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xcysabltv/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华山国家森林公园',
 'name': '新城源山',
 'price': ' 16000',
 'when': '2017-11-11'}
2018-04-12 12:33:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E5%A1%98%E5%8D%97%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_qhyzabnwc/>
{'lat': 31.676904082947466,
 'lng': 119.03333730597843,
 'location': '南京项目地址：双塘南路68号',
 'name': '秦淮源筑',
 'price': ' 12000',
 'when': '2017-11-29'}
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97169%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ycjydfaauoe/>
{'lat': 32.05156767640222,
 'lng': 118.89683388187007,
 'location': '南京项目地址：马群街169号',
 'name': '银城君颐东方',
 'price': ' 43000',
 'when': '2017-12-02'}
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E4%BA%94%E8%B7%AF%E7%94%B5%E5%BB%BA%E6%B5%B7%E8%B5%8B%E5%B0%9A%E5%9F%8E HTTP/1.1" 200 141
2018-04-12 12:33:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djhfscaalag/>
{'lat': 32.137634319277,
 'lng': 118.84295688872218,
 'location': '南京项目地址：经五路电建海赋尚城',
 'name': '电建海赋尚城',
 'price': ' 25800',
 'when': '2018-01-31'}
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%89%9B%E9%A6%96%E5%B1%B1%E5%A4%A7%E9%81%93121%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rachsaahns/>
{'lat': 31.918954454210063,
 'lng': 118.75165574782486,
 'location': '南京项目地址：牛首山大道121号',
 'name': '瑞安翠湖山',
 'price': ' 20000',
 'when': '2018-04-03'}
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E9%9C%9E%E6%96%87%E9%BC%8E%E8%B7%AF1%E5%8F%B7%EF%BC%88%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E4%B8%8E%E5%AD%A6%E6%9E%97%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:33:33 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.11865857092845,
 'lng': 118.91214765162765,
 'location': '南京项目地址：栖霞文鼎路1号（玄武大道与学林路交汇处）',
 'name': '恒基富荟山',
 'price': 0,
 'when': '2014-10-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:33:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E7%83%AD%E6%B2%B3%E5%8D%97%E8%B7%AF%E8%A1%97%E9%81%93 HTTP/1.1" 200 136
2018-04-12 12:33:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hsjlwaaqfu/>
{'lat': 32.08119544876564,
 'lng': 118.74690286637158,
 'location': '南京项目地址：鼓楼区热河南路街道',
 'name': '恒盛金陵湾',
 'price': ' 37500',
 'when': '2017-12-29'}
2018-04-12 12:33:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgydxyxabrtv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:33:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhysabqwl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:33:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hqcfctyabooo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E9%A9%AC%E7%BE%A4%E8%A1%972%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:33 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05578425340213,
 'lng': 118.89966428083703,
 'location': '南京项目地址：马群街道马群街2号',
 'name': '复地御钟山二期',
 'price': 0,
 'when': '2014-07-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%A4%A7%E9%81%938%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgydxyxabrtv/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华大道8号',
 'name': '碧桂园大学印象',
 'price': ' 16000',
 'when': '2017-11-11'}
2018-04-12 12:33:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E6%B9%96%E8%A1%97%E9%81%93%E9%80%9A%E6%B2%B3%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhysabqwl/>
{'lat': 32.45045312201094,
 'lng': 118.94784796098479,
 'location': '南京项目地址：金牛湖街道通河路9号',
 'name': '嘉恒有山',
 'price': ' 13500',
 'when': '2017-12-16'}
2018-04-12 12:33:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxcaabwu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:33:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gxzrtcaabuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:33:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gfdyaadlv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:33:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%AC%E5%AD%90%E6%B1%9F%E5%A4%A7%E9%81%93399%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:34 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.987082829704036,
 'lng': 118.69301154165758,
 'location': '南京项目地址：扬子江大道399号',
 'name': '海峡城',
 'price': 0,
 'when': '时间待定'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jjhtaabzh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:33:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjdhaacak/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:33:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:35 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BB%84%E5%AE%B6%E5%9C%A9%E8%B7%AF%E8%9E%8D%E5%88%9B%E7%B2%BE%E5%BD%A9%E5%A4%A9%E5%9C%B0 HTTP/1.1" 200 134
2018-04-12 12:33:35 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09573605816086,
 'lng': 118.80169499478319,
 'location': '南京项目地址：黄家圩路融创精彩天地',
 'name': '融创精彩天地',
 'price': ' 350',
 'when': '2016-11-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkddhabexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:33:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djzcfycsgcabfky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:33:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tsyjabgtd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:33:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_thnjyzaatgz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:33:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:35 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%AB%99%E4%B8%9C%E4%BA%8C%E8%B7%AF%E4%B8%87%E7%A7%91%E5%A4%A7%E9%83%BD%E4%BC%9A HTTP/1.1" 200 136
2018-04-12 12:33:35 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：站东二路万科大都会',
 'name': '万科大都会',
 'price': 0,
 'when': '2018-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:35 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E5%8D%97%E8%B7%AF5%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cfdszgaacay/>
{'lat': 31.99997241005109,
 'lng': 118.78497177739231,
 'location': '南京项目地址：雨花南路5号',
 'name': '长发都市诸公',
 'price': ' 864',
 'when': '2015-10-24'}
2018-04-12 12:33:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hymdaatgo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B7%A5%E5%86%9C%E8%B7%AF%E5%92%8C%E7%96%8F%E6%B8%AF%E5%A4%A7%E9%81%93%E4%BA%A4%E6%B1%87%E5%A4%84%E5%8D%8E%E4%BE%A8%E5%9F%8E%E7%BF%A1%E7%BF%A0%E5%A4%A9%E5%9F%9F HTTP/1.1" 200 135
2018-04-12 12:33:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hqcfctyabooo/>
{'lat': 32.14946210342667,
 'lng': 118.9979559714333,
 'location': '南京项目地址：工农路和疏港大道交汇处华侨城翡翠天域',
 'name': '华侨城翡翠天域',
 'price': ' 25500',
 'when': '2018-03-31'}
2018-04-12 12:33:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdqsyjabirk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_slhjzxabiuf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E9%87%8C%E6%A1%A5%E5%8C%97%E8%B7%AF%E9%87%91%E5%9C%B0%E6%B5%85%E5%B1%B1%E8%89%BA%E5%A2%83 HTTP/1.1" 200 143
2018-04-12 12:33:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jdqsyjabirk/>
{'lat': 32.094157269152994,
 'lng': 118.65780350461823,
 'location': '南京项目地址：七里桥北路金地浅山艺境',
 'name': '金地浅山艺境',
 'price': ' 40000',
 'when': '2016-06-01'}
2018-04-12 12:33:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E5%A4%A7%E8%A1%97%E5%8D%87%E9%BE%99%E6%B1%87%E9%87%91%E4%B8%AD%E5%BF%83 HTTP/1.1" 200 134
2018-04-12 12:33:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_slhjzxabiuf/>
{'lat': 31.98712298032158,
 'lng': 118.71726900636072,
 'location': '南京项目地址：江山大街升龙汇金中心',
 'name': '升龙汇金中心',
 'price': ' 29000',
 'when': '2015-03-15'}
2018-04-12 12:33:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%B2%BF%E5%B1%B1%E4%B8%9C%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09729036743584,
 'lng': 118.63965590436665,
 'location': '南京项目地址：浦口区江浦街道沿山东路188号',
 'name': '国信自然天城',
 'price': 0,
 'when': '2008-10-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E9%93%9C%E8%B7%AF%E5%9B%BD%E5%BA%9C%E5%A4%A7%E9%99%A2 HTTP/1.1" 200 145
2018-04-12 12:33:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.868615425164933,
 'lng': 118.97393347470582,
 'location': '南京项目地址：汤铜路国府大院',
 'name': '国府大院',
 'price': 0,
 'when': '2016-05-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg13> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:33:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwyhcaadvo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:33:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:33:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xwhjmgcaadxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:33:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smcpabovv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdqsyjaapwt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%93%BA%E5%B2%97%E8%A1%9728%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:37 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.924283790875556,
 'lng': 118.84223111805659,
 'location': '南京项目地址：秣陵街道铺岗街28号',
 'name': '骏景华庭',
 'price': 0,
 'when': '2015-08-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E9%A3%9E%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdfchtabilb/>
{'lat': 32.104949086157944,
 'lng': 118.82824103380696,
 'location': '南京项目地址：华飞路1号',
 'name': '恒大翡翠华庭',
 'price': ' 380',
 'when': '2017-07-05'}
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8F%8C%E8%B7%AF%E4%B8%96%E8%8C%82%E5%9F%8E%E5%93%81 HTTP/1.1" 200 145
2018-04-12 12:33:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smcpabovv/>
{'lat': 31.97666251592093,
 'lng': 118.76671169042649,
 'location': '南京项目地址：宁双路世茂城品',
 'name': '世茂城品',
 'price': ' 37000',
 'when': '2018-02-01'}
2018-04-12 12:33:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcznyyabnqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%8B%E5%AD%90%E6%A5%BC%E8%A5%BF108%E5%8F%B7 HTTP/1.1" 200 133
2018-04-12 12:33:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xlqpcsqabirq/>
{'lat': 32.12560776782336,
 'lng': 118.90211449894603,
 'location': '南京项目地址：王子楼西108号',
 'name': '仙林汽配城',
 'price': 0,
 'when': '2017-08-04'}
2018-04-12 12:33:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg58> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhfcxcaaksy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qxyyaakrh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%8F%E5%B8%82%E8%A1%97%E9%81%93%E7%94%B5%E5%BB%BA%E4%B8%AD%E5%82%A8%E6%B3%9B%E6%82%A6%E5%9F%8E%E5%B8%82%E5%B9%BF%E5%9C%BA HTTP/1.1" 200 134
2018-04-12 12:33:37 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10631834473104,
 'lng': 118.796087672078,
 'location': '南京项目地址：小市街道电建中储泛悦城市广场',
 'name': '电建中储泛悦城市广场',
 'price': ' 35900',
 'when': '2017-12-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E6%BA%AA%E9%95%87%E5%AE%9D%E5%A1%94%E8%B7%AF350%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhfcxcaaksy/>
{'lat': 31.335414317323576,
 'lng': 118.90942190794753,
 'location': '南京项目地址：淳溪镇宝塔路350号',
 'name': '隆豪翡翠星城',
 'price': 0,
 'when': '2017-07-02'}
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9C%88%E5%AE%89%E8%A1%9711%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hymdaatgo/>
{'lat': 32.02460861962323,
 'lng': 118.74210601897207,
 'location': '南京项目地址：月安街11号',
 'name': '海玥名都',
 'price': 0,
 'when': '2017-04-21'}
2018-04-12 12:33:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaazm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zyhfaaxbt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjmyaawmp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsylaatbk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jrcfslaaudc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dhjxhcxymsaavuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mdjyslaadxi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%91%E5%92%8C%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.976571884202652,
 'lng': 118.81231844287983,
 'location': '南京项目地址：民和路1号',
 'name': '万科九都荟',
 'price': 0,
 'when': '2015-11-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E9%87%8C%E6%A1%A5%E5%8C%97%E8%B7%AF%E9%87%91%E5%9C%B0%E6%B5%85%E5%B1%B1%E8%89%BA%E5%A2%83 HTTP/1.1" 200 143
2018-04-12 12:33:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jdqsyjaapwt/>
{'lat': 32.094157269152994,
 'lng': 118.65780350461823,
 'location': '南京项目地址：七里桥北路金地浅山艺境',
 'name': '金地浅山艺境',
 'price': 0,
 'when': '2016-08-14'}
2018-04-12 12:33:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:33:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:33:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:33:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hbypyaakof/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:33:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B4%AA%E8%93%9D%E9%95%87%E5%87%A4%E5%87%B0%E4%BA%95%E8%B7%AF26%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.634768533012924,
 'lng': 119.00443475589523,
 'location': '南京项目地址：洪蓝镇凤凰井路26号',
 'name': '天生御景',
 'price': 0,
 'when': '2014-10-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E5%9B%AD%E6%9E%97%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_qxyyaakrh/>
{'lat': 32.360387136248946,
 'lng': 118.84133678305696,
 'location': '南京项目地址：雄州街道园林西路188号',
 'name': '清香雅苑',
 'price': 0,
 'when': '2016-12-29'}
2018-04-12 12:33:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceve/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:33:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceve/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhjc1haalmu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg59> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%8C%E6%B1%9F%E6%95%85%E5%B1%85%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aaazm/>
{'lat': 31.865264410601366,
 'lng': 118.47517450362449,
 'location': '南京项目地址：乌江故居路8号',
 'name': '江岸景城',
 'price': ' 15000',
 'when': '2015-02-08'}
2018-04-12 12:33:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_zhjc1haalmu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 45, in parse_html
    item["name"] = response.xpath('//h1/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yclxjaarwg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hysglaapty/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xchyzjaakrz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dflyaapvh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9B%A2%E5%B1%B1%E8%A5%BF%E8%B7%AF26%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.69267717506764,
 'lng': 119.0207176406826,
 'location': '南京项目地址：团山西路26号',
 'name': '创维乐活城',
 'price': ' 6800',
 'when': '2017-09-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B4%E9%98%B3%E6%B1%9F%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rcznyyabnqr/>
{'lat': 31.341189718000248,
 'lng': 118.91511603391415,
 'location': '南京项目地址：水阳江路99号',
 'name': '融创中南御园',
 'price': ' 11000',
 'when': '2018-01-02'}
2018-04-12 12:33:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg37> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:33:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8D%97%E8%B7%AF117%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hbypyaakof/>
{'lat': 31.324725434771544,
 'lng': 118.90167334739824,
 'location': '南京项目地址：淳南路117号',
 'name': '湖滨一品苑',
 'price': 0,
 'when': '2011-04-20'}
2018-04-12 12:33:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E5%8D%97%E8%B7%AF501%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.026788843993685,
 'lng': 118.78769049901827,
 'location': '南京项目地址：中山南路501号',
 'name': '泰禾南京院子',
 'price': 0,
 'when': '2017-06-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:33:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg21> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_pthtxsqabgbq/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:33:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%BE%E6%9D%A8%E8%B7%AF%E7%B4%AB%E8%89%BA%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 136
2018-04-12 12:33:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zyhfaaxbt/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：松杨路紫艺华府',
 'name': '紫艺华府',
 'price': 0,
 'when': '2018-01-19'}
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%95%E5%BA%9C%E4%B8%9C%E8%B7%AF228%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjmyaawmp/>
{'lat': 32.12191964138096,
 'lng': 118.81329580556283,
 'location': '南京项目地址：幕府东路228号',
 'name': '紫金铭苑',
 'price': 0,
 'when': '2017-07-24'}
2018-04-12 12:33:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bllswlaamzx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjxtaamsn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:33:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jljqhfaakts/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E5%88%9B%E6%96%B0%E4%B8%9C%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:33:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yclxjaarwg/>
{'lat': 31.8838176413981,
 'lng': 118.88290815941363,
 'location': '南京项目地址：秣陵街道创新东路2号',
 'name': '银城蓝溪郡',
 'price': 0,
 'when': '2015-10-01'}
2018-04-12 12:33:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qdfzaagpr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjaamhi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zyzjgdaaqce/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rjyblsaamir/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%93%9D%E6%B5%B7%E8%B7%AF%E5%BC%98%E9%98%B3%E6%97%B6%E5%85%89%E9%87%8C HTTP/1.1" 200 144
2018-04-12 12:33:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hysglaapty/>
{'lat': 32.18039301137142,
 'lng': 118.7172462747398,
 'location': '南京项目地址：蓝海路弘阳时光里',
 'name': '弘阳时光里',
 'price': 0,
 'when': '2017-06-24'}
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%B9%E9%9C%9E%E8%B7%AF%E6%96%B0%E5%9F%8E%E8%8A%B1%E6%BC%BE%E7%B4%AB%E9%83%A1 HTTP/1.1" 200 143
2018-04-12 12:33:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xchyzjaakrz/>
{'lat': 32.18964133869749,
 'lng': 118.72037139247337,
 'location': '南京项目地址：丹霞路新城花漾紫郡',
 'name': '新城花漾紫郡',
 'price': 0,
 'when': '2016-10-22'}
2018-04-12 12:33:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E9%9C%9E%E7%BB%8F%E4%BA%94%E8%B7%AF%E4%B8%8E%E8%BF%88%E5%8C%96%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 134
2018-04-12 12:33:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dflyaapvh/>
{'lat': 32.1312287642796,
 'lng': 118.84117460118358,
 'location': '南京项目地址：栖霞经五路与迈化路交汇处',
 'name': '东方兰园',
 'price': 0,
 'when': '2016-07-28'}
2018-04-12 12:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceku/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceku/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:33:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%91%A1%E5%9B%AD%E8%B7%AF%E4%BB%81%E6%81%92%E7%BB%BF%E6%B4%B2%E6%96%B0%E5%B2%9B HTTP/1.1" 200 143
2018-04-12 12:33:43 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.03377176667957,
 'lng': 118.70845022618616,
 'location': '南京项目地址：葡园路仁恒绿洲新岛',
 'name': '仁恒绿洲新岛',
 'price': 0,
 'when': '2017-11-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg22> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_pthtxsqabgbq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:33:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E7%9A%8B%E6%A1%A5%E8%A1%97%E9%81%93%E8%BF%88%E5%8C%96%E8%B7%AF376%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bllswlaamzx/>
{'lat': 32.11827229201747,
 'lng': 118.8296499002366,
 'location': '南京项目地址：迈皋桥街道迈化路376号',
 'name': '保利朗诗蔚蓝',
 'price': 0,
 'when': '2017-12-06'}
2018-04-12 12:33:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_atssydaaktt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:33:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceva/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:33:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yydcaaptw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:33:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ytsyhaaksk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:33:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%BD%E6%B3%BD%E8%B7%AF599%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wkjxtaamsn/>
{'lat': 31.91449917688987,
 'lng': 118.89241944689905,
 'location': '南京项目地址：丽泽路599号',
 'name': '五矿九玺台',
 'price': 0,
 'when': '2013-01-20'}
2018-04-12 12:33:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%92%E9%BA%9F%E8%A1%97%E9%81%93%E6%99%BA%E9%80%9A%E8%B7%AF189%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_qdfzaagpr/>
{'lat': 32.03160625464619,
 'lng': 118.9119191637564,
 'location': '南京项目地址：麒麟街道智通路189号',
 'name': '启迪方洲博园',
 'price': 0,
 'when': '2016-07-16'}
2018-04-12 12:33:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%AE%E8%B7%AF201%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:45 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.07904243541421,
 'lng': 118.78987490852688,
 'location': '南京项目地址：中央路201号',
 'name': '玄武湖金茂广场御景华府',
 'price': 0,
 'when': '2009-11-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:45 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.13531269255433,
 'lng': 118.74226588429522,
 'location': '南京项目地址：江山路9号',
 'name': '浦泰和天下三期',
 'price': 0,
 'when': '2017-11-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg14> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:33:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cywxsaacdj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zgtjqxcaaeox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyyjwaacdv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:33:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:46 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcaccii/>: HTTP status code is not handled or not allowed
2018-04-12 12:33:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E4%BF%AE%E6%96%87%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jljqhfaakts/>
{'lat': 31.90070775306782,
 'lng': 118.91608440725392,
 'location': '南京项目地址：江宁区淳化街道修文路3号',
 'name': '金轮津桥华府',
 'price': 0,
 'when': '2016-07-22'}
2018-04-12 12:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djsmyhaakuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:33:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E9%9D%96%E8%B7%AF599%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_atssydaaktt/>
{'lat': 31.966100163341842,
 'lng': 118.85850571579324,
 'location': '南京项目地址：文靖路599号',
 'name': '爱涛尚书云邸',
 'price': 0,
 'when': '2016-03-09'}
2018-04-12 12:33:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceva/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceki/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:33:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceki/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg23> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E7%87%95%E4%B8%9C%E8%B7%AF%E6%8B%9B%E5%95%861872%E5%85%AC%E5%9B%AD%E9%87%8C HTTP/1.1" 200 132
2018-04-12 12:33:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zsylaatbk/>
{'lat': 32.1265750663835,
 'lng': 118.83957790985149,
 'location': '南京项目地址：钟燕东路招商1872公园里',
 'name': '招商1872公园里',
 'price': 0,
 'when': '2017-03-08'}
2018-04-12 12:33:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gkrjaamhi/>
{'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境',
 'price': 0,
 'when': '2012-10-23'}
2018-04-12 12:33:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacene/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacene/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg24> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:33:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceme/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8F%8D%E7%8F%A0%E5%8D%97%E8%B7%AF199%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:33:48 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10124607362065,
 'lng': 118.707219725188,
 'location': '南京项目地址：珍珠南路199号',
 'name': '创源无想墅',
 'price': 0,
 'when': '2016-01-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zssfaaeoa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_slthaaelu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfxsjaaeoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg15> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:33:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkcwjcaaenb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:33:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceme/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E5%B0%A7%E8%B7%AF327%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:48 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12259447503586,
 'lng': 118.84063643989731,
 'location': '南京项目地址：迈尧路327号',
 'name': '中国铁建青秀城',
 'price': 0,
 'when': '2016-06-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:33:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:33:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%92%E9%BA%9F%E8%A1%97%E9%81%93%E9%BA%92%E4%B8%9C%E8%B7%AF777%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yydcaaptw/>
{'lat': 32.058979891669495,
 'lng': 118.95879434272581,
 'location': '南京项目地址：麒麟街道麒东路777号',
 'name': '银亿东城第九街区',
 'price': ' 29000',
 'when': '2018-02-04'}
2018-04-12 12:33:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:33:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceod/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:33:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceod/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%90%89%E5%B1%B1%E5%A4%A7%E9%81%939%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jrcfslaaudc/>
{'lat': 31.861380358744533,
 'lng': 118.77282264452263,
 'location': '南京项目地址：吉山大道9号',
 'name': '景瑞春风十里',
 'price': ' 19000',
 'when': '2017-06-06'}
2018-04-12 12:33:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:33:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E4%B8%AD%E5%9E%A0%E7%B4%AB%E9%87%91%E8%A7%82%E9%82%B8 HTTP/1.1" 200 144
2018-04-12 12:33:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zyzjgdaaqce/>
{'lat': 32.05232823923972,
 'lng': 118.90154611589733,
 'location': '南京项目地址：马群街道中垠紫金观邸',
 'name': '中垠紫金观邸',
 'price': 0,
 'when': '2017-12-20'}
2018-04-12 12:33:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:33:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:33:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg25> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceos/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceos/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E7%9A%8B%E6%A1%A5%E8%A1%97%E9%81%93%E7%BD%91%E6%9D%BF%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:51 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10966291802278,
 'lng': 118.8313789586822,
 'location': '南京项目地址：迈皋桥街道网板路8号',
 'name': '星叶瑜憬湾',
 'price': ' 29500',
 'when': '2018-03-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E5%9B%BA%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ytsyhaaksk/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：永固路3号',
 'name': '亚泰山语湖',
 'price': 0,
 'when': '2017-09-08'}
2018-04-12 12:33:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dhjxhcxymsaavuz/>
{'lat': 32.123523391191696,
 'lng': 118.72947850536069,
 'location': '南京项目地址：浦珠北路59号',
 'name': '大华锦绣华城香鸢美颂',
 'price': ' 24600',
 'when': '2017-11-25'}
2018-04-12 12:33:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E4%B8%B9%E9%98%B3%E5%A4%A7%E9%81%93110%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rjyblsaamir/>
{'lat': 31.849796224068285,
 'lng': 118.77857718961954,
 'location': '南京项目地址：江宁丹阳大道110号',
 'name': '瑞景叶泊蓝山',
 'price': 0,
 'when': '2012-10-02'}
2018-04-12 12:33:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsyyjaaaxe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:33:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhyggaamil/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:33:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BB%84%E5%B1%B1%E5%B2%AD%E8%B7%AF%E4%B9%9D%E6%9C%88%E6%A3%AE%E6%9E%97 HTTP/1.1" 200 143
2018-04-12 12:33:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mdjyslaadxi/>
{'lat': 32.08342667185487,
 'lng': 118.62232126700839,
 'location': '南京项目地址：黄山岭路九月森林',
 'name': '九月森林',
 'price': 0,
 'when': '2018-03-24'}
2018-04-12 12:33:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_smmxjaakrd/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:33:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:33:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_xhycbmlsaakqw/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:33:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_sclfaakub/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:33:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_htygjczgcaakog/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:33:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_znjyaaksn/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:33:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ltxfaawiy/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:33:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg11> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fhhrdxaaclk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wycaakob/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E5%B9%B3%E5%8D%97%E8%B7%AF%E4%B8%8E%E7%99%BD%E4%B8%8B%E8%B7%AF%E4%BA%A4%E7%95%8C%E5%A4%84 HTTP/1.1" 200 136
2018-04-12 12:33:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_fhhrdxaaclk/>
{'lat': 32.03553521855789,
 'lng': 118.79736364858033,
 'location': '南京项目地址：太平南路与白下路交界处',
 'name': '凤凰和睿大厦',
 'price': ' 22000',
 'when': '时间待定'}
2018-04-12 12:33:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfptmhjaaqjj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htygjczgcaakog/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znjyaaksn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:33:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B4%87%E6%96%87%E8%B7%AF68%E5%8F%B7(%E4%BD%93%E8%82%B2%E5%85%AC%E5%9B%AD%E5%8D%97300%E7%B1%B3) HTTP/1.1" 200 138
2018-04-12 12:33:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.636021305521947,
 'lng': 119.04381660119327,
 'location': '南京项目地址：崇文路68号(体育公园南300米)',
 'name': '中山首府',
 'price': 0,
 'when': '2017-07-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:33:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%90%E5%B1%B1%E8%B7%AF208%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djsmyhaakuc/>
{'lat': 31.99841267184827,
 'lng': 118.730251217879,
 'location': '南京项目地址：庐山路208号',
 'name': '德基世贸壹号',
 'price': ' 37000',
 'when': '2014-10-28'}
2018-04-12 12:33:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sjtcaacko/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:33:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceor/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg26> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:33:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A6%84%E5%8F%A3%E8%A1%97%E9%81%93%E4%BF%A1%E8%AF%9A%E5%A4%A7%E9%81%9333%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:33:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zsyyjaaaxe/>
{'lat': 31.7850970443259,
 'lng': 118.83236228130838,
 'location': '南京项目地址：禄口街道信诚大道33号',
 'name': '招商依云郡',
 'price': 0,
 'when': '2016-07-29'}
2018-04-12 12:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg60> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htssyjaaavr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:33:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceor/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_flsyjaaayv/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:33:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_aaayu/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:33:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%9D%E9%BE%99%E5%B1%B1%E8%B7%AF%E4%B8%87%E6%82%A6%E5%9F%8E HTTP/1.1" 200 143
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceri/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:33:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wycaakob/>
{'lat': 31.369820090663627,
 'lng': 118.95197910453356,
 'location': '南京项目地址：九龙山路万悦城',
 'name': '万悦城',
 'price': 0,
 'when': '2017-05-03'}
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltxfaawiy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg9)
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sclfaakub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:33:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceri/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:33:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:55 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:33:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcaceog/>: HTTP status code is not handled or not allowed
2018-04-12 12:33:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9B%A2%E5%B1%B1%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:33:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sjtcaacko/>
{'lat': 31.698645656477684,
 'lng': 119.02620947633312,
 'location': '南京项目地址：团山路1号',
 'name': '世纪天城',
 'price': 0,
 'when': '2016-07-19'}
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flcaapqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jsczgcaakng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gcdtljaacgp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaaws/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cpcaagvp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg27> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:33:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:33:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:33:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:33:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:33:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:33:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%87%A4%E6%B1%87%E5%A4%A7%E9%81%93%E6%98%8E%E5%8F%91%E6%B5%A6%E6%B3%B0%E6%A2%A6%E5%B9%BB%E5%AE%B6 HTTP/1.1" 200 143
2018-04-12 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:33:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfptmhjaaqjj/>
{'lat': 31.92740779796182,
 'lng': 118.64778341958687,
 'location': '南京项目地址：凤汇大道明发浦泰梦幻家',
 'name': '明发浦泰梦幻家',
 'price': 0,
 'when': '2017-09-05'}
2018-04-12 12:33:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E6%B7%B3%E6%BA%AA%E9%95%87%E5%AE%9D%E5%A1%94%E8%B7%AF269%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_htygjczgcaakog/>
{'lat': 31.33618242769404,
 'lng': 118.9089895903361,
 'location': '南京项目地址：高淳淳溪镇宝塔路269号',
 'name': '红太阳国际财智广场',
 'price': 0,
 'when': '2016-04-10'}
2018-04-12 12:33:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BD%AF%E4%BB%B6%E5%A4%A7%E9%81%93%E4%B8%AD%E5%8D%97%E9%94%A6%E8%8B%91 HTTP/1.1" 200 144
2018-04-12 12:33:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_znjyaaksn/>
{'lat': 31.984256699458975,
 'lng': 118.75651496529456,
 'location': '南京项目地址：软件大道中南锦苑',
 'name': '中南锦苑',
 'price': 0,
 'when': '2016-09-03'}
2018-04-12 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xhycbmlsaakqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:33:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:33:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E9%BA%92%E8%B7%AF277%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:33:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_flcaapqv/>
{'lat': 32.01565712729463,
 'lng': 118.88669095266192,
 'location': '南京项目地址：东麒路277号',
 'name': '富力城',
 'price': 0,
 'when': '2012-11-29'}
2018-04-12 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg38> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhxwggaapsi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:33:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:33:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B2%B3%E8%B7%AF%E5%8D%87%E9%BE%99%E5%A4%A9%E6%B1%87 HTTP/1.1" 200 143
2018-04-12 12:33:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.970816439367926,
 'lng': 118.70513179041191,
 'location': '南京项目地址：新河路升龙天汇',
 'name': '升龙天汇',
 'price': 0,
 'when': '2017-11-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%B3%89%E4%B8%9C%E8%B7%AF58%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:33:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhyggaamil/>
{'lat': 31.9539171307712,
 'lng': 118.88896630931528,
 'location': '南京项目地址：淳化街道泉东路58号',
 'name': '中航樾公馆',
 'price': 0,
 'when': '2017-07-03'}
2018-04-12 12:33:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjaapto/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:33:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ygjbszzykpaadii/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:33:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93%E4%B8%8E%E8%B4%A2%E5%85%AB%E8%B7%AF%E4%BA%A4%E5%8F%89%E5%8F%A3%EF%BC%88%E5%A4%A7%E9%A9%AC%E5%B1%B1%E8%B7%AF6%E5%8F%B7%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:33:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：浦口江浦街道沿山大道与财八路交叉口（大马山路6号）',
 'name': '明发香山郡',
 'price': ' 26000',
 'when': '2017-07-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:33:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg28> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:33:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:33:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:33:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:33:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E7%86%9F%E8%A1%97%E9%81%93%E6%B6%A6%E6%B9%96%E5%A4%A7%E9%81%93398%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:33:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ltxfaawiy/>
{'lat': 31.873594814596018,
 'lng': 118.97674222511495,
 'location': '南京项目地址：湖熟街道润湖大道398号',
 'name': '梁台煦府',
 'price': 0,
 'when': '2016-12-10'}
2018-04-12 12:33:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:33:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:33:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:33:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:33:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:34:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E5%AE%81%E8%B7%AF31%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jsczgcaakng/>
{'lat': 32.09653621784545,
 'lng': 118.78217765020526,
 'location': '南京项目地址：建宁路31号',
 'name': '金盛财智广场',
 'price': 0,
 'when': '2012-09-16'}
2018-04-12 12:34:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BA%91%E9%94%A6%E8%B7%AF%E5%AE%8F%E5%9B%BE%E4%B8%8A%E6%B0%B4%E4%BA%91%E9%94%A6 HTTP/1.1" 200 144
2018-04-12 12:34:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_htssyjaaavr/>
{'lat': 32.021247988570856,
 'lng': 118.74727426898808,
 'location': '南京项目地址：云锦路宏图上水云锦',
 'name': '宏图上水云锦一期',
 'price': 0,
 'when': '2016-06-04'}
2018-04-12 12:34:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%90%B4%E4%BE%AF%E8%A1%97158%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:00 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.973438574825735,
 'lng': 118.70282546018457,
 'location': '南京项目地址：吴侯街158号',
 'name': '五矿崇文金城',
 'price': 0,
 'when': '2017-11-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrrjcaaeov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:34:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkcaabgm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:34:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_afgjaabiy/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_pjhfyxaaaze/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:34:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bllsaaazg/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:34:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ckxdyyaabax/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:34:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_xyyshhyaaazr/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:34:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gkrjaapto/>
{'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境',
 'price': 0,
 'when': '2013-11-01'}
2018-04-12 12:34:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:34:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%9C%B0%E9%93%81%E4%BA%8C%E5%8F%B7%E7%BA%BF%E5%A4%A9%E8%BF%88%E5%B9%BF%E5%9C%BA%E6%B2%B9%E5%9D%8A%E6%A1%A5%E7%AB%99 HTTP/1.1" 200 139
2018-04-12 12:34:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sclfaakub/>
{'lat': 31.971841104007034,
 'lng': 118.72764980327469,
 'location': '南京项目地址：建邺地铁二号线天迈广场油坊桥站',
 'name': '首创立方',
 'price': ' 20000',
 'when': '2016-04-01'}
2018-04-12 12:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:34:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E7%99%BD%E9%A9%AC%E8%B7%AF%E4%B8%8E%E7%8B%AE%E5%B1%B1%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:34:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xhycbmlsaakqw/>
{'lat': 32.08258412514195,
 'lng': 118.63632209768683,
 'location': '南京项目地址：浦口区白马路与狮山路交汇处',
 'name': '旭辉银城白马澜山',
 'price': 0,
 'when': '2017-12-25'}
2018-04-12 12:34:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E6%A1%A5%E5%8C%97%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:34:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyyxhtababu/>
{'lat': 32.01816879567414,
 'lng': 118.74715685147487,
 'location': '南京项目地址：大桥北路9号',
 'name': '弘阳印象华庭',
 'price': 0,
 'when': '2017-03-01'}
2018-04-12 12:34:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:34:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacete/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%9B%84%E5%B7%9E%E5%8D%97%E8%B7%AF333%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gcdtljaacgp/>
{'lat': 32.32400440901211,
 'lng': 118.8261801952043,
 'location': '南京项目地址：龙池街道雄州南路333号',
 'name': '冠城大通蓝郡',
 'price': 0,
 'when': '2017-08-20'}
2018-04-12 12:34:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacete/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smmxjaakrd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%BF%E8%A5%BF%E5%9F%82%E5%A4%A7%E8%A1%97100%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aaaws/>
{'lat': 32.09061065715351,
 'lng': 118.67518410377791,
 'location': '南京项目地址：广西埂大街100号',
 'name': '华润国际社区',
 'price': 0,
 'when': '2017-12-28'}
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycyfsaafsp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E7%A6%84%E5%A4%A7%E9%81%931%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cpcaagvp/>
{'lat': 31.79647196501264,
 'lng': 118.86518619158387,
 'location': '南京项目地址：天禄大道1号',
 'name': '翠屏城',
 'price': ' 11900',
 'when': '2017-11-08'}
2018-04-12 12:34:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_klhfaadjw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:34:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_zhygcaaomt/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:34:02 [scrapy.extensions.logstats] INFO: Crawled 353 pages (at 75 pages/min), scraped 189 items (at 31 items/min)
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%81%92%E5%98%89%E8%B7%AF%E4%B8%AD%E6%B5%B7%E7%8E%84%E6%AD%A6%E5%85%AC%E9%A6%86 HTTP/1.1" 200 142
2018-04-12 12:34:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhxwggaapsi/>
{'lat': 32.10309198480382,
 'lng': 118.82802835368933,
 'location': '南京项目地址：恒嘉路中海玄武公馆',
 'name': '中海玄武公馆',
 'price': 0,
 'when': '2017-03-30'}
2018-04-12 12:34:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg29> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%95%87%E5%8D%97%E6%B2%B3%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:02 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.06209076570978,
 'lng': 118.68209046428447,
 'location': '南京项目地址：镇南河路99号',
 'name': '正荣润江城',
 'price': 0,
 'when': '2017-07-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:02 [scrapy.extensions.logstats] INFO: Crawled 132 pages (at 45 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:34:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:02 [scrapy.extensions.logstats] INFO: Crawled 255 pages (at 103 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:34:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceth/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceth/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E7%91%9E%E6%96%87%E8%B7%AF199%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smmxjaakrd/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：淳化街道瑞文路199号',
 'name': '世茂梦享家',
 'price': 0,
 'when': '2016-04-30'}
2018-04-12 12:34:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ssyfhyyxaafss/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:34:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_heshyhggaakok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg10)
2018-04-12 12:34:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hjfhsaahno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:34:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aafrg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:34:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tzyyxaafsh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:34:04 [scrapy.extensions.logstats] INFO: Crawled 107 pages (at 50 pages/min), scraped 89 items (at 39 items/min)
2018-04-12 12:34:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%87%B4%E8%BF%9C%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_klhfaadjw/>
{'lat': 31.64677206867821,
 'lng': 119.04738826030771,
 'location': '南京项目地址：致远路68号',
 'name': '康利华府',
 'price': 0,
 'when': '2018-01-01'}
2018-04-12 12:34:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%9388%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ygjbszzykpaadii/>
{'lat': 32.09998525321101,
 'lng': 118.87119915132855,
 'location': '南京项目地址：玄武大道88号',
 'name': '阳光聚宝山庄臻园',
 'price': 0,
 'when': '2016-09-13'}
2018-04-12 12:34:04 [scrapy.extensions.logstats] INFO: Crawled 547 pages (at 73 pages/min), scraped 262 items (at 23 items/min)
2018-04-12 12:34:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%80%E5%9B%AD%E8%B7%AF6%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.647940595364506,
 'lng': 119.03181041118783,
 'location': '南京项目地址：秀园路6号',
 'name': '万科城',
 'price': 0,
 'when': '2018-03-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg39> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg61> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:34:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjycydaabsv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djhfaabvz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaayu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:34:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_akszsfaaabj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:34:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjgcabbey/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:34:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%89%AA%E5%AD%90%E5%B7%B735%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yjycydaabsv/>
{'lat': 32.019721200388425,
 'lng': 118.79260288216061,
 'location': '南京项目地址：剪子巷35号',
 'name': '雅居乐长乐渡',
 'price': ' 2500',
 'when': '2017-12-20'}
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldzcabbev/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xscaabhf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flsyjaaayv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdxmlyzxaavxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:34:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E6%B5%A6%E5%85%AD%E5%8D%97%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aaayu/>
{'lat': 32.251425749873995,
 'lng': 118.75004994857319,
 'location': '南京项目地址：大厂浦六南路8号',
 'name': '君悦花园',
 'price': 0,
 'when': '2014-08-23'}
2018-04-12 12:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bsxbyaaazh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:34:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E5%90%89%E5%8D%B0%E5%A4%A7%E9%81%934199%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ycyfsaafsp/>
{'lat': 31.878871395291938,
 'lng': 118.78266735426757,
 'location': '南京项目地址：江宁区淳化街道吉印大道4199号',
 'name': '银城一方山',
 'price': 0,
 'when': '2015-11-13'}
2018-04-12 12:34:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aafrw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:34:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:34:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BA%91%E9%94%A6%E8%B7%AF%E6%89%80%E8%A1%97 HTTP/1.1" 200 136
2018-04-12 12:34:07 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04035147114477,
 'lng': 118.75098867333959,
 'location': '南京项目地址：云锦路所街',
 'name': '乐基广场',
 'price': 0,
 'when': '2014-11-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlxlfaawai/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lgwxdhaavvc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:34:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E6%A2%81%E8%A1%97%E9%81%93%E7%91%9E%E6%88%90%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djhfaabvz/>
{'lat': 32.331850449520935,
 'lng': 118.94026095169839,
 'location': '南京项目地址：横梁街道瑞成路9号',
 'name': '东骏华府',
 'price': 0,
 'when': '2013-12-29'}
2018-04-12 12:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjszaabur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:34:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zlhyaabas/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:34:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%85%89%E4%B8%9C%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xscaabhf/>
{'lat': 31.686029241429527,
 'lng': 119.0426089417233,
 'location': '南京项目地址：红光东路8号',
 'name': '橡树城',
 'price': 0,
 'when': '2018-01-23'}
2018-04-12 12:34:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceta/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceta/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg30> (referer: https://nj.fang.lianjia.com/loupan/pg/pg29)
2018-04-12 12:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF126%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ssyfhyyxaafss/>
{'lat': 32.11862130443328,
 'lng': 118.70782125782063,
 'location': '南京项目地址：浦珠北路126号',
 'name': '山水云房花园',
 'price': ' 23000',
 'when': '2017-05-22'}
2018-04-12 12:34:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg31> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E5%8D%97%E7%AB%99%E5%8C%97%E5%B9%BF%E5%9C%BA%E7%BB%BF%E5%9C%B0%E4%B9%8B%E7%AA%97 HTTP/1.1" 200 144
2018-04-12 12:34:09 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.973807633953474,
 'lng': 118.79656951147558,
 'location': '南京项目地址：南京南站北广场绿地之窗',
 'name': '绿地之窗',
 'price': ' 60000',
 'when': '2017-01-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:34:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E6%9E%A2%E8%A5%BF%E8%B7%AF%E5%A5%A5%E5%85%8B%E6%96%AF%E9%92%9F%E5%B1%B1%E5%BA%9C HTTP/1.1" 200 142
2018-04-12 12:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_akszsfaaabj/>
{'lat': 32.09514392116203,
 'lng': 118.91396510333544,
 'location': '南京项目地址：文枢西路奥克斯钟山府',
 'name': '奥克斯钟山府',
 'price': 0,
 'when': '2018-01-29'}
2018-04-12 12:34:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:34:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_heshyhggaakok/>
{'lat': 31.393150940897428,
 'lng': 118.97196008794114,
 'location': '南京项目地址：双湖路1号',
 'name': '海尔双湖壹号公馆',
 'price': ' 8300',
 'when': '2017-09-27'}
2018-04-12 12:34:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceue/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceue/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceul/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%91%E6%99%BA%E8%B7%AF9%E5%8F%B7%E3%80%8110%E5%8F%B7%E3%80%8111%E5%8F%B7%E3%80%8112%E5%8F%B7%E3%80%8113%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97029556775504,
 'lng': 118.81089211249278,
 'location': '南京项目地址：民智路9号、10号、11号、12号、13号',
 'name': '证大喜玛拉雅中心',
 'price': ' 20000',
 'when': '2018-01-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E4%B8%81%E5%AE%B6%E5%B1%B1%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bjszaabur/>
{'lat': 32.24351789402061,
 'lng': 118.78205578787639,
 'location': '南京项目地址：大厂丁家山路2号',
 'name': '碧景山庄',
 'price': 0,
 'when': '2015-02-11'}
2018-04-12 12:34:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceul/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E6%9D%BF%E6%A1%A5%E6%96%B0%E5%9F%8E%E6%96%B0%E6%B9%96%E5%A4%A7%E9%81%93%EF%BC%88%E8%BF%91%E8%8E%B2%E8%8A%B1%E6%B9%96%E5%85%AC%E5%9B%AD%EF%BC%89 HTTP/1.1" 200 143
2018-04-12 12:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_flsyjaaayv/>
{'lat': 31.91023898425397,
 'lng': 118.66805461945387,
 'location': '南京项目地址：雨花板桥新城新湖大道（近莲花湖公园）',
 'name': '富力尚悦居一期',
 'price': 0,
 'when': '2015-10-24'}
2018-04-12 12:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jnhdjzxabgvh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yckqabgrk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:34:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%B0%E6%B3%BD%E8%B7%AF118%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:34:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zlhyaabas/>
{'lat': 31.998126980049786,
 'lng': 118.88957460317951,
 'location': '南京项目地址：丰泽路118号',
 'name': '中粮鸿云',
 'price': 0,
 'when': '2017-09-08'}
2018-04-12 12:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacers/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacers/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hjjlmyaadyi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ylcsjqaadxn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znjyabcmd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E7%86%9F%E8%A1%97%E9%81%93%E7%81%B5%E9%A1%BA%E5%8C%97%E8%B7%AF211%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hjjlmyaadyi/>
{'lat': 31.873002120783894,
 'lng': 118.98550482825115,
 'location': '南京项目地址：湖熟街道灵顺北路211号',
 'name': '恒建金陵美域',
 'price': 0,
 'when': '2015-10-09'}
2018-04-12 12:34:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhygcaaomt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:34:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smwtxcaacap/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:34:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hysyabchh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg32> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%8C%AF%E5%85%B4%E8%B7%AF180%E5%8F%B7%E3%80%81%E8%83%A5%E6%BA%AA%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ylcsjqaadxn/>
{'lat': 31.298993439267697,
 'lng': 119.07494337758881,
 'location': '南京项目地址：振兴路180号、胥溪路9号',
 'name': '垠领城市街区',
 'price': 0,
 'when': '2016-06-01'}
2018-04-12 12:34:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:34:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:34:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8D%97%E8%A1%97%E9%81%93%E9%87%91%E8%BD%AE%E6%98%9F%E7%AB%8B%E6%96%B9 HTTP/1.1" 200 136
2018-04-12 12:34:14 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99799477275822,
 'lng': 118.78177238865749,
 'location': '南京项目地址：宁南街道金轮星立方',
 'name': '金轮星立方',
 'price': ' 60000',
 'when': '2015-12-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceus/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceus/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%BC%E8%87%B4%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bsxbyaaazh/>
{'lat': 31.91310523050222,
 'lng': 118.8974729552743,
 'location': '南京项目地址：格致路9号',
 'name': '伴山香槟园',
 'price': 0,
 'when': '2010-01-16'}
2018-04-12 12:34:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrraaeor/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:34:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceva/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E6%B9%96%E8%A1%97%E9%81%93%E9%87%91%E7%89%9B%E6%B9%96%E7%A4%BE%E5%8C%BA88%E5%8F%B7 HTTP/1.1" 200 142
2018-04-12 12:34:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jnhdjzxabgvh/>
{'lat': 32.47562584733648,
 'lng': 118.97543132009281,
 'location': '南京项目地址：金牛湖街道金牛湖社区88号',
 'name': '金牛湖度假中心',
 'price': 0,
 'when': '2013-12-17'}
2018-04-12 12:34:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceva/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BD%AF%E4%BB%B6%E5%A4%A7%E9%81%93%E4%B8%AD%E5%8D%97%E9%94%A6%E8%8B%91 HTTP/1.1" 200 144
2018-04-12 12:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_znjyabcmd/>
{'lat': 31.984256699458975,
 'lng': 118.75651496529456,
 'location': '南京项目地址：软件大道中南锦苑',
 'name': '中南锦苑',
 'price': 0,
 'when': '2017-03-22'}
2018-04-12 12:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyshsjabcfs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlxlfaayvm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E7%BB%8F%E8%B4%B8%E5%AD%A6%E9%99%A2%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhygcaaomt/>
{'lat': 31.939256003031172,
 'lng': 118.89293055488676,
 'location': '南京项目地址：淳化街道经贸学院路8号',
 'name': '中航樾广场',
 'price': 0,
 'when': '2015-12-12'}
2018-04-12 12:34:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E9%80%9A%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smwtxcaacap/>
{'lat': 32.08452501199852,
 'lng': 118.74076903872225,
 'location': '南京项目地址：南通路89号',
 'name': '世茂外滩新城',
 'price': ' 35900',
 'when': '时间待定'}
2018-04-12 12:34:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceud/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E9%9C%9E%E6%96%87%E9%BC%8E%E8%B7%AF1%E5%8F%B7%EF%BC%88%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E4%B8%8E%E5%AD%A6%E6%9E%97%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84%EF%BC%89 HTTP/1.1" 200 138
2018-04-12 12:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hjfhsaahno/>
{'lat': 32.11865857092845,
 'lng': 118.91214765162765,
 'location': '南京项目地址：栖霞文鼎路1号（玄武大道与学林路交汇处）',
 'name': '恒基富荟山',
 'price': 0,
 'when': '2014-10-30'}
2018-04-12 12:34:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%9C%88%E5%8D%8E%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hysyabchh/>
{'lat': 31.93624759256761,
 'lng': 118.90840306958252,
 'location': '南京项目地址：江宁区淳化街道月华路8号',
 'name': '弘阳上院',
 'price': ' 23000',
 'when': '2015-02-18'}
2018-04-12 12:34:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceud/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E5%B1%B1%E8%A5%BF%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%ADS1%E7%A7%A6%E6%B7%AE%E4%B8%96%E5%AE%B6 HTTP/1.1" 200 137
2018-04-12 12:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyshsjabcfs/>
{'lat': 31.648311742573938,
 'lng': 118.91514343402882,
 'location': '南京项目地址：横山西路碧桂园S1秦淮世家',
 'name': '碧桂园S1秦淮世家',
 'price': 0,
 'when': '2017-11-30'}
2018-04-12 12:34:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E4%B9%90%E8%B7%AF%E6%B4%AA%E5%AE%B6%E5%9B%AD1%E5%8F%B7 HTTP/1.1" 200 143
2018-04-12 12:34:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0053428312632,
 'lng': 118.80204028545512,
 'location': '南京项目地址：永乐路洪家园1号',
 'name': '绿国万象都荟',
 'price': ' 50000',
 'when': '2015-11-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_xyyshhyaaazr/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8D%97%E8%A1%97%E9%81%93%E9%87%91%E8%BD%AE%E6%98%9F%E7%AB%8B%E6%96%B9 HTTP/1.1" 200 136
2018-04-12 12:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlxlfaayvm/>
{'lat': 31.99799477275822,
 'lng': 118.78177238865749,
 'location': '南京项目地址：宁南街道金轮星立方',
 'name': '金轮星立方',
 'price': ' 21000',
 'when': '2015-12-04'}
2018-04-12 12:34:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E9%A9%AC%E8%B7%AF%E9%93%B6%E5%9F%8EKinmaQ+%E7%A4%BE%E5%8C%BA HTTP/1.1" 200 136
2018-04-12 12:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yckqabgrk/>
{'lat': 32.07294880801665,
 'lng': 118.9122779050283,
 'location': '南京项目地址：金马路银城KinmaQ+社区',
 'name': '银城KinmaQ+社区',
 'price': ' 29000',
 'when': '2017-10-01'}
2018-04-12 12:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzscyfaacfh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcmgyaafsc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:34:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jmfaabfl/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:34:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceqj/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:34:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg62> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg40> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg16> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bllsaaazg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhxwggabaxa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:34:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B2%B3%E8%A5%BF%E5%8D%97%E9%83%A8%E5%AD%A6%E5%AD%90%E8%B7%AF HTTP/1.1" 200 136
2018-04-12 12:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zrraaeor/>
{'lat': 32.087391829280385,
 'lng': 118.82174943981876,
 'location': '南京项目地址：河西南部学子路',
 'name': '正荣润峯',
 'price': 0,
 'when': '2017-04-21'}
2018-04-12 12:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxcabbgw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:34:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gcbgyaaejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BB%99%E6%9E%97%E8%A1%97%E9%81%93%E4%BF%9D%E5%88%A9%E7%A4%BC%E5%A2%85 HTTP/1.1" 200 137
2018-04-12 12:34:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.11097695649148,
 'lng': 118.9295337061967,
 'location': '南京项目地址：仙林街道保利礼墅',
 'name': '保利礼墅',
 'price': 0,
 'when': '2015-06-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hycsxjaawkm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxhfabbbc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg15)
2018-04-12 12:34:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacepn/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E5%87%A4%E6%BB%A8%E8%B7%AF18%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aafrg/>
{'lat': 32.207695799701774,
 'lng': 118.74507388427848,
 'location': '南京项目地址：大厂凤滨路18号',
 'name': '福基九龙新城',
 'price': 0,
 'when': '2011-05-06'}
2018-04-12 12:34:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E7%AB%B9%E5%B1%B1%E8%B7%AF588%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tzyyxaafsh/>
{'lat': 31.92671560623449,
 'lng': 118.85742595575786,
 'location': '南京项目地址：江宁区秣陵街道竹山路588号',
 'name': '天泽苑',
 'price': ' 28000',
 'when': '2018-02-03'}
2018-04-12 12:34:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg12> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:34:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hyascaapvm/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_fdyzsyxaampu/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:34:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:34:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg33> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:34:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:34:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E8%8B%8F%E5%AE%81%E9%92%9F%E5%B1%B1%E6%9C%9D%E9%98%B3%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:34:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_snzscyfaacfh/>
{'lat': 32.0913139891331,
 'lng': 118.89802397497581,
 'location': '南京项目地址：玄武大道苏宁钟山朝阳府',
 'name': '苏宁钟山朝阳府',
 'price': 0,
 'when': '2014-03-30'}
2018-04-12 12:34:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E6%BA%AA%E9%95%87%E7%9F%B3%E8%87%BC%E6%B9%96%E5%8C%97%E8%B7%AF76%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gcbgyaaejs/>
{'lat': 31.344123311690005,
 'lng': 118.89682926137152,
 'location': '南京项目地址：淳溪镇石臼湖北路76号',
 'name': '高淳碧桂园',
 'price': 0,
 'when': '2018-03-26'}
2018-04-12 12:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rdxfcaaekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaazn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcaaeok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BD%8D%E5%A4%84%E5%8D%97%E4%BA%AC%E5%94%AF%E4%B8%80%E7%9C%81%E7%BA%A7%E6%97%85%E6%B8%B8%E5%BA%A6%E5%81%87%E5%8C%BA%E2%80%94%E2%80%94%E7%8F%8D%E7%8F%A0%E6%B3%89%E6%97%85%E6%B8%B8%E5%BA%A6%E5%81%87%E5%8C%BA%E5%AF%86%E6%9E%97%E6%B7%B1%E5%A4%84 HTTP/1.1" 200 142
2018-04-12 12:34:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lcmgyaafsc/>
{'lat': 32.1311378986881,
 'lng': 118.66847660834854,
 'location': '南京项目地址：位处南京唯一省级旅游度假区——珍珠泉旅游度假区密林深处',
 'name': '绿城玫瑰园',
 'price': ' 12800',
 'when': '2014-09-27'}
2018-04-12 12:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhxycabgop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:34:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%81%92%E5%98%89%E8%B7%AF%E4%B8%AD%E6%B5%B7%E7%8E%84%E6%AD%A6%E5%85%AC%E9%A6%86 HTTP/1.1" 200 142
2018-04-12 12:34:19 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10309198480382,
 'lng': 118.82802835368933,
 'location': '南京项目地址：恒嘉路中海玄武公馆',
 'name': '中海玄武公馆',
 'price': 0,
 'when': '2017-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%AC%E5%AD%90%E6%B1%9F%E5%A4%A7%E9%81%93399%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:34:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:19 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.987082829704036,
 'lng': 118.69301154165758,
 'location': '南京项目地址：扬子江大道399号',
 'name': '海峡城',
 'price': ' 30000',
 'when': '2016-12-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ckxdyyaabax/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_afgjaabiy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:34:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:34:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceup/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:34:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceup/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:34:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%87%A4%E9%9B%86%E5%A4%A7%E9%81%936%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aafrw/>
{'lat': 31.93439038369555,
 'lng': 118.66586279443327,
 'location': '南京项目地址：凤集大道6号',
 'name': '石林大公园',
 'price': 0,
 'when': '2012-08-08'}
2018-04-12 12:34:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:34:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:34:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyascaapvm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:34:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A6%E5%B1%B1%E8%A1%97%E9%81%93123%E5%9C%B0%E5%9D%97 HTTP/1.1" 200 136
2018-04-12 12:34:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyascaapvm/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：秦山街道123地块',
 'name': '弘阳爱上城',
 'price': 0,
 'when': '2015-11-20'}
2018-04-12 12:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E8%97%8F%E5%A4%A7%E9%81%9312%E5%8F%B7%E5%BC%98%E9%98%B3 HTTP/1.1" 200 137
2018-04-12 12:34:21 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.94682158034673,
 'lng': 118.67416296037928,
 'location': '南京项目地址：龙藏大道12号弘阳',
 'name': '弘阳春上西江',
 'price': 0,
 'when': '2016-11-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:34:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B9%E5%B7%9E%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rdxfcaaekr/>
{'lat': 32.365988858238566,
 'lng': 118.85472132611994,
 'location': '南京项目地址：方州路68号',
 'name': '荣鼎幸福城',
 'price': 0,
 'when': '2018-01-24'}
2018-04-12 12:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg41> (referer: https://nj.fang.lianjia.com/loupan/pg/pg40)
2018-04-12 12:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzhybhlaawbr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg40)
2018-04-12 12:34:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhjlmzaawjd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg40)
2018-04-12 12:34:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg34> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%91%A1%E5%9B%AD%E8%B7%AF%E4%BB%81%E6%81%92%E7%BB%BF%E6%B4%B2%E6%96%B0%E5%B2%9B HTTP/1.1" 200 143
2018-04-12 12:34:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rhlzxdaampx/>
{'lat': 32.03377176667957,
 'lng': 118.70845022618616,
 'location': '南京项目地址：葡园路仁恒绿洲新岛',
 'name': '仁恒绿洲新岛',
 'price': 0,
 'when': '2017-11-19'}
2018-04-12 12:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacews/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacews/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%9F%E8%B7%AF%EF%BC%88%E5%8D%97%E4%BA%AC%E8%A5%BF%E7%AB%99%E8%A5%BF%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 140
2018-04-12 12:34:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10087185564733,
 'lng': 118.74873294286502,
 'location': '南京项目地址：龙江路（南京西站西侧）',
 'name': '锦绣华府',
 'price': ' 420',
 'when': '2016-09-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg17> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:34:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%9C%A0%E5%A4%A7%E9%81%93660%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhxycabgop/>
{'lat': 31.915202403612295,
 'lng': 118.90964727896606,
 'location': '南京项目地址：龙眠大道660号',
 'name': '龙湖新壹城',
 'price': 0,
 'when': '2017-06-25'}
2018-04-12 12:34:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxjshyabdzu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jagwlsabebt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfcfzxabdwh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E7%8E%8B%E6%A1%A5%E8%B7%AF28%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.33955818255956,
 'lng': 118.84800376222998,
 'location': '南京项目地址：雄州街道王桥路28号',
 'name': '城开新都雅苑',
 'price': 0,
 'when': '2017-11-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%BD%E6%99%AF%E8%B7%AF%E8%89%BE%E8%8F%B2%E5%9B%BD%E9%99%85 HTTP/1.1" 200 145
2018-04-12 12:34:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.16648888960027,
 'lng': 118.70877040832077,
 'location': '南京项目地址：丽景路艾菲国际',
 'name': '艾菲国际',
 'price': 0,
 'when': '2015-04-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfbzxcabmjd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwqlnhyabgpx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%95%BF%E6%B1%9F%E8%B7%AF%E8%A5%BF%E4%BE%A7%E6%98%8E%E5%8F%91%E5%8C%97%E7%AB%99%E6%96%B0%E5%9F%8E HTTP/1.1" 200 135
2018-04-12 12:34:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04955537268256,
 'lng': 118.8014603106721,
 'location': '南京项目地址：长江路西侧明发北站新城',
 'name': '明发北站新城',
 'price': 0,
 'when': '2017-11-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjllycabmje/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%8A%E6%B2%B3%E6%96%B0%E5%9F%8E%E9%9B%85%E5%B1%85%E4%B9%90%E6%9E%97%E8%AF%AD%E5%9F%8E HTTP/1.1" 200 136
2018-04-12 12:34:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：汊河新城雅居乐林语城',
 'name': '雅居乐林语城',
 'price': 0,
 'when': '2017-12-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgydxyxabrtv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E9%BA%92%E4%B8%9C%E8%B7%AF588%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aaazn/>
{'lat': 32.05831085966082,
 'lng': 118.94504433960678,
 'location': '南京项目地址：东麒东路588号',
 'name': '麒麟山庄公园境',
 'price': 0,
 'when': '时间待定'}
2018-04-12 12:34:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%A1%94%E6%A1%A5%E8%A5%BF%E8%A1%97155%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jxjshyabdzu/>
{'lat': 32.111578944142316,
 'lng': 118.75557194483122,
 'location': '南京项目地址：宝塔桥西街155号',
 'name': '锦绣江山花园',
 'price': 0,
 'when': '2016-11-25'}
2018-04-12 12:34:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsyfaawlq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:34:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lggyaawox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%99%BA%E6%B1%87%E8%B7%AF92%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jagwlsabebt/>
{'lat': 32.033566135579086,
 'lng': 118.91402647916111,
 'location': '南京项目地址：智汇路92号',
 'name': '京奥港未来墅',
 'price': ' 26000',
 'when': '2017-09-15'}
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%A4%A7%E9%81%936%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:34:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfcfzxabdwh/>
{'lat': 32.063466256710505,
 'lng': 118.67466304975159,
 'location': '南京项目地址：浦口大道6号',
 'name': '明发财富中心',
 'price': ' 17000',
 'when': '2017-10-01'}
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E4%B8%9C%E8%B7%AF301%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zsyfaawlq/>
{'lat': 32.04676420264064,
 'lng': 118.81321034167492,
 'location': '南京项目地址：中山东路301号',
 'name': '钟山颐府',
 'price': 0,
 'when': '2016-06-01'}
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%BE%99%E5%8D%8E%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:34:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.31827364260565,
 'lng': 118.81844075425253,
 'location': '南京项目地址：龙池街道龙华路66号',
 'name': '骋望七里楠花园',
 'price': 0,
 'when': '2015-02-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sswhykpaawjt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:34:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njbjzbjdswqabcno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:34:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_pjhfyxaaaze/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:34:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytabctb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:34:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyzsabdir/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg16)
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%A4%A7%E9%81%938%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华大道8号',
 'name': '碧桂园大学印象',
 'price': ' 16000',
 'when': '2017-11-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg35> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:34:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%8C%BA%E6%80%A1%E5%BA%B7%E8%A1%97%E4%B8%8E%E8%A5%BF%E5%9F%8E%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 137
2018-04-12 12:34:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lcaaeok/>
{'lat': 31.998575159409864,
 'lng': 118.75515428127758,
 'location': '南京项目地址：建邺区怡康街与西城路交汇处',
 'name': '涟城二期',
 'price': 0,
 'when': '2015-03-22'}
2018-04-12 12:34:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_slzxcaawcm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg40)
2018-04-12 12:34:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhysabqwl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:34:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E6%B9%96%E8%A1%97%E9%81%93%E9%80%9A%E6%B2%B3%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.45045312201094,
 'lng': 118.94784796098479,
 'location': '南京项目地址：金牛湖街道通河路9号',
 'name': '嘉恒有山',
 'price': ' 13500',
 'when': '2017-12-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bltyabmqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:34:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%87%E6%99%AF%E5%8C%97%E8%B7%AF%E4%BF%9D%E5%88%A9%E5%A0%82%E6%82%A6 HTTP/1.1" 200 143
2018-04-12 12:34:28 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.987086765521944,
 'lng': 118.81312602132991,
 'location': '南京项目地址：汇景北路保利堂悦',
 'name': '保利堂悦',
 'price': ' 350',
 'when': '2016-04-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ylfablzi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:34:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxlshslaasuo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:34:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E6%96%B0%E8%B7%AF%E8%93%9D%E5%85%89%E5%85%AC%E5%9B%AD1%E5%8F%B7 HTTP/1.1" 200 146
2018-04-12 12:34:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lggyaawox/>
{'lat': 31.92591631683342,
 'lng': 118.67321099728457,
 'location': '南京项目地址：华新路蓝光公园1号',
 'name': '蓝光公园1号',
 'price': 0,
 'when': '2017-06-17'}
2018-04-12 12:34:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jmfaabfl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:34:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cpsjgcabbis/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:34:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gjoydsygcabcyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:34:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A2%85%E5%85%B4%E8%B7%AF%E5%96%84%E6%B0%B4%E6%B9%BE%E8%8A%B1%E5%9B%AD HTTP/1.1" 200 144
2018-04-12 12:34:28 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.958704964869618,
 'lng': 118.73669664435383,
 'location': '南京项目地址：梅兴路善水湾花园',
 'name': '善水湾花园',
 'price': 0,
 'when': '2013-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg18> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:34:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B6%A6%E5%AF%BF%E5%8C%97%E8%B7%AF599%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yzhybhlaawbr/>
{'lat': 31.859401199797308,
 'lng': 118.60077001053546,
 'location': '南京项目地址：润寿北路599号',
 'name': '禹洲弘阳滨湖里',
 'price': 0,
 'when': '2016-12-24'}
2018-04-12 12:34:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%83%9C%E5%A4%AA%E8%B7%AF%E9%87%91%E8%BE%89%E9%87%91%E9%99%B5%E9%93%AD%E8%91%97 HTTP/1.1" 200 135
2018-04-12 12:34:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jhjlmzaawjd/>
{'lat': 31.95061810100132,
 'lng': 118.82058772867562,
 'location': '南京项目地址：胜太路金辉金陵铭著',
 'name': '金辉金陵铭著',
 'price': 0,
 'when': '2016-11-17'}
2018-04-12 12:34:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg12> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fdyzsyxaampu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg11)
2018-04-12 12:34:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E9%A9%AC%E7%BE%A4%E8%A1%972%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_fdyzsyxaampu/>
{'lat': 32.05578425340213,
 'lng': 118.89966428083703,
 'location': '南京项目地址：马群街道马群街2号',
 'name': '复地御钟山二期',
 'price': 0,
 'when': '2014-07-19'}
2018-04-12 12:34:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B3%B0%E5%B1%B1%E8%A5%BF%E8%B7%AF%E5%BE%A1%E6%BE%9C%E5%BA%9C HTTP/1.1" 200 135
2018-04-12 12:34:30 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.15139493848411,
 'lng': 118.71872790211911,
 'location': '南京项目地址：泰山西路御澜府',
 'name': '御澜府',
 'price': ' 25800',
 'when': '2017-11-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcjxthyabmmo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxhfaarwx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E8%B7%AF6%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:30 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.132337610018176,
 'lng': 118.739274526947,
 'location': '南京项目地址：江山路6号',
 'name': '金象朗诗红树林',
 'price': 0,
 'when': '2017-10-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xwhjmgcaadxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:34:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A1%83%E6%BA%AA%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:30 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：桃溪路1号',
 'name': '融创玖溪桃花源',
 'price': ' 395',
 'when': '2018-03-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%9F%E8%B7%AF%EF%BC%88%E5%8D%97%E4%BA%AC%E8%A5%BF%E7%AB%99%E8%A5%BF%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 140
2018-04-12 12:34:30 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10087185564733,
 'lng': 118.74873294286502,
 'location': '南京项目地址：龙江路（南京西站西侧）',
 'name': '锦绣华府',
 'price': 0,
 'when': '2016-05-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smcpabovv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg36> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%AD%E5%90%88%E5%8C%BA%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E7%8E%8B%E6%A1%A5%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 134
2018-04-12 12:34:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_slzxcaawcm/>
{'lat': 32.33244867233251,
 'lng': 118.84063470707173,
 'location': '南京项目地址：六合区雄州街道王桥路99号',
 'name': '石林中心城',
 'price': 0,
 'when': '2017-10-29'}
2018-04-12 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ytwtsjaaeoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlhbskpaaekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hcwjaauyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg40)
2018-04-12 12:34:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%AE%E8%B7%AF201%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xwhjmgcaadxy/>
{'lat': 32.07904243541421,
 'lng': 118.78987490852688,
 'location': '南京项目地址：中央路201号',
 'name': '玄武湖金茂广场御景华府',
 'price': 0,
 'when': '2009-11-01'}
2018-04-12 12:34:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrrjcaaeov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:34:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cwyhcaadvo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:34:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%80%9A%E6%B5%8E%E9%97%A8%E5%A4%96%E5%A4%A7%E8%A1%977%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jmfaabfl/>
{'lat': 32.03040026511993,
 'lng': 118.80856022996521,
 'location': '南京项目地址：通济门外大街7号',
 'name': '京门府',
 'price': 0,
 'when': '2013-11-11'}
2018-04-12 12:34:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg62> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:34:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tchabdhu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:34:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdjbtxaawxd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:34:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B8%AF%E5%A4%A7%E9%81%9388%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cpsjgcabbis/>
{'lat': 32.169791062821595,
 'lng': 118.87681335325735,
 'location': '南京项目地址：新港大道88号',
 'name': '翠屏水晶广场',
 'price': ' 45',
 'when': '2016-01-30'}
2018-04-12 12:34:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E5%B8%82%E6%BA%A7%E6%B0%B4%E5%8C%BA%E7%A7%A6%E6%B7%AE%E8%B7%AF159-21%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gjoydsygcabcyp/>
{'lat': 31.657385165530922,
 'lng': 119.05231070860395,
 'location': '南京项目地址：南京市溧水区秦淮路159-21号',
 'name': '顾家欧亚达商业广场',
 'price': 0,
 'when': '2015-11-12'}
2018-04-12 12:34:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_tyljxssyabfqd/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:34:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B6%A6%E5%AF%8C%E8%B7%AF666%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ytwtsjaaeoo/>
{'lat': 32.269405076580064,
 'lng': 118.74330082207327,
 'location': '南京项目地址：润富路666号',
 'name': '亚泰梧桐世家',
 'price': 0,
 'when': '2017-08-03'}
2018-04-12 12:34:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fctyaawlb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:34:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycdyfaauuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg40)
2018-04-12 12:34:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xzllhwaawji/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:34:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E6%B8%85%E6%B0%B4%E4%BA%AD%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:34:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jlhbskpaaekk/>
{'lat': 31.919765529265728,
 'lng': 118.81406744370776,
 'location': '南京项目地址：秣陵街道清水亭西路188号',
 'name': '九龙湖别墅',
 'price': 0,
 'when': '2016-11-18'}
2018-04-12 12:34:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E7%87%95%E6%B1%9F%E8%B7%AF201%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:34 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.06860445880062,
 'lng': 118.76505691316264,
 'location': '南京项目地址：鼓楼区燕江路201号',
 'name': '江山汇金',
 'price': ' 17100',
 'when': '2014-05-07'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E6%96%B0%E5%8D%8E%E8%A5%BF%E8%B7%AF458%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:34 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.20805330579511,
 'lng': 118.7399702187509,
 'location': '南京项目地址：大厂新华西路458号',
 'name': '盘金华府',
 'price': 0,
 'when': '2014-06-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:35 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%95%87%E5%8D%97%E6%B2%B3%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zrrjcaaeov/>
{'lat': 32.06209076570978,
 'lng': 118.68209046428447,
 'location': '南京项目地址：镇南河路99号',
 'name': '正荣润江城',
 'price': 0,
 'when': '2017-07-05'}
2018-04-12 12:34:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B9%96%E5%A4%A7%E9%81%93%E5%92%8C%E6%98%8C%E6%B9%BE%E6%99%AF HTTP/1.1" 200 142
2018-04-12 12:34:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hcwjaauyp/>
{'lat': 31.9254387597965,
 'lng': 118.67555812585326,
 'location': '南京项目地址：新湖大道和昌湾景',
 'name': '和昌湾景',
 'price': 0,
 'when': '2017-07-03'}
2018-04-12 12:34:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg42> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:34:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hzqlwaawla/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:34:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flsjfaawld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:34:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E5%8C%97%E8%B7%AF369%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_fctyaawlb/>
{'lat': 31.612703497788456,
 'lng': 118.99424929340748,
 'location': '南京项目地址：金牛北路369号',
 'name': '福晟庭院',
 'price': 0,
 'when': '2015-10-30'}
2018-04-12 12:34:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8F%8C%E8%B7%AF%E4%B8%96%E8%8C%82%E5%9F%8E%E5%93%81 HTTP/1.1" 200 145
2018-04-12 12:34:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97666251592093,
 'lng': 118.76671169042649,
 'location': '南京项目地址：宁双路世茂城品',
 'name': '世茂城品',
 'price': ' 37000',
 'when': '2018-02-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xycabkna/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_slhjzxabiuf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9B%A2%E5%B1%B1%E8%A5%BF%E8%B7%AF26%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cwyhcaadvo/>
{'lat': 31.69267717506764,
 'lng': 119.0207176406826,
 'location': '南京项目地址：团山西路26号',
 'name': '创维乐活城',
 'price': ' 6800',
 'when': '2017-09-29'}
2018-04-12 12:34:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E5%B8%82%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B1%A4%E5%B1%B1%E5%9B%BD%E9%99%85%E6%B8%A9%E6%B3%89%E5%9F%8E%E5%9C%A3%E6%B1%A4%E5%A4%A7%E9%81%939%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tchabdhu/>
{'lat': 32.04829213296588,
 'lng': 119.06564056974446,
 'location': '南京项目地址：南京市江宁区汤山国际温泉城圣汤大道9号',
 'name': '汤城汇',
 'price': 0,
 'when': '2015-02-12'}
2018-04-12 12:34:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E6%B9%96%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdjbtxaawxd/>
{'lat': 31.700575027936633,
 'lng': 119.07375409205974,
 'location': '南京项目地址：永湖路188号',
 'name': '恒大金碧天下',
 'price': 0,
 'when': '2018-03-29'}
2018-04-12 12:34:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg13> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:34:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycyfsaaftx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg12)
2018-04-12 12:34:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hblabcnq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:34:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%B7%E7%A6%8F%E5%B7%B771%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ycdyfaauuz/>
{'lat': 32.02535577253019,
 'lng': 118.84839752545017,
 'location': '南京项目地址：海福巷71号',
 'name': '银城东岳府',
 'price': 0,
 'when': '2017-03-30'}
2018-04-12 12:34:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lbzcaavye/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:34:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%9F%E7%81%AB%E8%B7%AF%E6%98%9F%E6%82%A6%E5%9F%8E HTTP/1.1" 200 136
2018-04-12 12:34:38 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.16673496276866,
 'lng': 118.70268689027152,
 'location': '南京项目地址：星火路星悦城',
 'name': '星悦城',
 'price': ' 16000',
 'when': '2018-02-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%89%E4%B8%AD%E9%97%A8%E5%A4%A7%E8%A1%97%E6%B6%B5%E7%A2%A7%E6%A5%BC HTTP/1.1" 200 137
2018-04-12 12:34:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hblabcnq/>
{'lat': 32.04442588871159,
 'lng': 118.75600338659478,
 'location': '南京项目地址：汉中门大街涵碧楼',
 'name': '涵碧楼',
 'price': ' 25000',
 'when': '2015-08-29'}
2018-04-12 12:34:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smjwsabcny/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:34:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjhbshyabctn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:34:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E5%90%89%E5%8D%B0%E5%A4%A7%E9%81%934199%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ycyfsaaftx/>
{'lat': 31.878871395291938,
 'lng': 118.78266735426757,
 'location': '南京项目地址：江宁区淳化街道吉印大道4199号',
 'name': '银城一方山',
 'price': 0,
 'when': '2016-01-01'}
2018-04-12 12:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg14> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxcaabwu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cywxsaacdj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jjhtaabzh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zgtjqxcaaeox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyyjwaacdv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjdhaacak/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:34:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8F%8D%E7%8F%A0%E5%8C%97%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xzllhwaawji/>
{'lat': 31.684557220584292,
 'lng': 119.03736365769795,
 'location': '南京项目地址：珍珠北路88号',
 'name': '喜之郎丽湖湾',
 'price': 0,
 'when': '2015-12-25'}
2018-04-12 12:34:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E7%94%9F%E6%A1%A5%E5%A4%A7%E9%81%93218%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hzqlwaawla/>
{'lat': 31.648004371136633,
 'lng': 119.0089268568526,
 'location': '南京项目地址：天生桥大道218号',
 'name': '华洲青林湾',
 'price': 0,
 'when': '2017-09-01'}
2018-04-12 12:34:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E5%A4%A7%E8%A1%97%E5%8D%87%E9%BE%99%E6%B1%87%E9%87%91%E4%B8%AD%E5%BF%83 HTTP/1.1" 200 134
2018-04-12 12:34:40 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.98712298032158,
 'lng': 118.71726900636072,
 'location': '南京项目地址：江山大街升龙汇金中心',
 'name': '升龙汇金中心',
 'price': ' 29000',
 'when': '2015-03-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdqsyjabirk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sjxnfabhsz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:34:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E9%87%8C%E6%A1%A5%E5%8C%97%E8%B7%AF%E9%87%91%E5%9C%B0%E6%B5%85%E5%B1%B1%E8%89%BA%E5%A2%83 HTTP/1.1" 200 143
2018-04-12 12:34:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.094157269152994,
 'lng': 118.65780350461823,
 'location': '南京项目地址：七里桥北路金地浅山艺境',
 'name': '金地浅山艺境',
 'price': ' 40000',
 'when': '2016-06-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg37> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:34:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%B0%E5%8D%97%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lbzcaavye/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：台南路10号',
 'name': '力标赞城',
 'price': 0,
 'when': '2018-01-01'}
2018-04-12 12:34:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wjjyabgxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:34:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldbfgcaavjz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:34:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhmsabhag/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:34:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%89%AC%E5%AD%90%E6%B1%9F%E5%A4%A7%E9%81%93399%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:34:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hxcaabwu/>
{'lat': 31.987082829704036,
 'lng': 118.69301154165758,
 'location': '南京项目地址：扬子江大道399号',
 'name': '海峡城',
 'price': 0,
 'when': '时间待定'}
2018-04-12 12:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gxzrtcaabuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg13)
2018-04-12 12:34:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9A%82%E6%97%A0 HTTP/1.1" 200 136
2018-04-12 12:34:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_flsjfaawld/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：暂无',
 'name': '富力水街坊',
 'price': 0,
 'when': '2017-12-11'}
2018-04-12 12:34:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxcjyaawif/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:34:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8F%A0%E6%B3%89%E8%A5%BF%E8%B7%AF%E4%B8%89%E9%87%91%E9%91%AB%E5%AE%81%E5%BA%9C HTTP/1.1" 200 142
2018-04-12 12:34:43 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05495625325235,
 'lng': 118.63701904801674,
 'location': '南京项目地址：珠泉西路三金鑫宁府',
 'name': '三金鑫宁府',
 'price': ' 25600',
 'when': '2017-12-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bllswlaamzx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:34:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhygcaaomt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:34:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smrlaarsf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcznyyabnqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yydcaaptw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:34:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hqcfctyabooo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:34:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E7%9A%8B%E6%A1%A5%E8%A1%97%E9%81%93%E8%BF%88%E5%8C%96%E8%B7%AF376%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:43 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.11827229201747,
 'lng': 118.8296499002366,
 'location': '南京项目地址：迈皋桥街道迈化路376号',
 'name': '保利朗诗蔚蓝',
 'price': 0,
 'when': '2017-12-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%9F%B3%E6%9D%A8%E8%B7%AF107%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_smjwsabcny/>
{'lat': 32.01039784610178,
 'lng': 118.87256973377394,
 'location': '南京项目地址：石杨路107号',
 'name': '世茂君望墅',
 'price': 0,
 'when': '2015-09-26'}
2018-04-12 12:34:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E6%BB%A8%E8%B7%AF58%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bjhbshyabctn/>
{'lat': 31.9483738255737,
 'lng': 118.82015885337091,
 'location': '南京项目地址：湖滨路58号',
 'name': '百家湖别墅花园',
 'price': ' 43000',
 'when': '2017-04-12'}
2018-04-12 12:34:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8F%8D%E7%8F%A0%E5%8D%97%E8%B7%AF199%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:34:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cywxsaacdj/>
{'lat': 32.10124607362065,
 'lng': 118.707219725188,
 'location': '南京项目地址：珍珠南路199号',
 'name': '创源无想墅',
 'price': 0,
 'when': '2016-01-12'}
2018-04-12 12:34:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%93%BA%E5%B2%97%E8%A1%9728%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jjhtaabzh/>
{'lat': 31.924283790875556,
 'lng': 118.84223111805659,
 'location': '南京项目地址：秣陵街道铺岗街28号',
 'name': '骏景华庭',
 'price': 0,
 'when': '2015-08-12'}
2018-04-12 12:34:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E5%B0%A7%E8%B7%AF327%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%8C%BA%E5%B7%B4%E5%B1%B1%E8%B7%AF38%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zgtjqxcaaeox/>
{'lat': 32.12259447503586,
 'lng': 118.84063643989731,
 'location': '南京项目地址：迈尧路327号',
 'name': '中国铁建青秀城',
 'price': 0,
 'when': '2016-06-04'}
2018-04-12 12:34:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hxcjyaawif/>
{'lat': 32.008675496084074,
 'lng': 118.73063170639526,
 'location': '南京项目地址：建邺区巴山路38号',
 'name': '华新城璟园',
 'price': 0,
 'when': '2016-05-15'}
2018-04-12 12:34:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E7%BB%8F%E8%B4%B8%E5%AD%A6%E9%99%A2%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:45 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.939256003031172,
 'lng': 118.89293055488676,
 'location': '南京项目地址：淳化街道经贸学院路8号',
 'name': '中航樾广场',
 'price': 0,
 'when': '2015-12-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_heshyhggabgfc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:34:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcthyabgvb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:34:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jsfaawlc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:34:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ydhczxabgkt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:34:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E8%B7%AF%E8%8D%A3%E9%87%8C HTTP/1.1" 200 135
2018-04-12 12:34:46 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.13159618531885,
 'lng': 118.73518389787502,
 'location': '南京项目地址：浦珠路荣里',
 'name': '世茂荣里',
 'price': 0,
 'when': '2018-03-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%85%89%E8%B7%AF19%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wjjyabgxy/>
{'lat': 31.688295449939762,
 'lng': 119.03969542075559,
 'location': '南京项目地址：红光路19号',
 'name': '万景佳苑',
 'price': 0,
 'when': '2016-10-10'}
2018-04-12 12:34:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_heshyhggabgfc/>
{'lat': 31.393150940897428,
 'lng': 118.97196008794114,
 'location': '南京项目地址：双湖路1号',
 'name': '海尔双湖壹号公馆',
 'price': 0,
 'when': '2017-06-26'}
2018-04-12 12:34:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B4%E9%98%B3%E6%B1%9F%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:49 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.341189718000248,
 'lng': 118.91511603391415,
 'location': '南京项目地址：水阳江路99号',
 'name': '融创中南御园',
 'price': ' 11000',
 'when': '2018-01-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E5%B1%B1%E8%A1%97%E9%81%93%E9%BA%92%E9%BA%9F%E9%97%A8%E5%A4%A7%E9%81%936699%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lcthyabgvb/>
{'lat': 32.04571553461317,
 'lng': 119.02176299880456,
 'location': '南京项目地址：汤山街道麒麟门大道6699号',
 'name': '绿城桃花源',
 'price': 0,
 'when': '2018-03-31'}
2018-04-12 12:34:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jrgjgcabeuu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:34:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%95%E5%BA%9C%E4%B8%9C%E8%B7%AF%E7%BB%BF%E5%9C%B0%E7%BC%A4%E7%BA%B7%E5%B9%BF%E5%9C%BA HTTP/1.1" 200 134
2018-04-12 12:34:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ldbfgcaavjz/>
{'lat': 32.1181890588941,
 'lng': 118.78596874649138,
 'location': '南京项目地址：幕府东路绿地缤纷广场',
 'name': '绿地缤纷广场',
 'price': ' 158',
 'when': '2017-09-16'}
2018-04-12 12:34:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E8%83%A1%E6%A1%A5%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:51 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：江浦街道胡桥路9号',
 'name': '明发云庭',
 'price': ' 35000',
 'when': '2017-03-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%92%E9%BA%9F%E8%A1%97%E9%81%93%E9%BA%92%E4%B8%9C%E8%B7%AF777%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:34:51 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.058979891669495,
 'lng': 118.95879434272581,
 'location': '南京项目地址：麒麟街道麒东路777号',
 'name': '银亿东城第九街区',
 'price': ' 29000',
 'when': '2018-02-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E5%B1%B1%E8%B7%AF95%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jsfaawlc/>
{'lat': 31.94158984043159,
 'lng': 118.84824359301572,
 'location': '南京项目地址：金山路95号',
 'name': '金山府',
 'price': 0,
 'when': '2015-05-15'}
2018-04-12 12:34:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A5%94%E9%A9%AC%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E9%92%9F%E5%B1%B1 HTTP/1.1" 200 136
2018-04-12 12:34:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08330568277308,
 'lng': 118.91771165983776,
 'location': '南京项目地址：奔马路新城璞樾钟山',
 'name': '新城璞樾钟山',
 'price': ' 900',
 'when': '2017-12-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xyyshhyaaazr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg14)
2018-04-12 12:34:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_tyljxyabgtm/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:34:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hyyjfabhht/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_2jbjhabhfk/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jdwryabhfp/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bgybasjabgyc/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:34:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_blsdgcabdzt/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:34:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_zgtjqxcabefw/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:34:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B7%A5%E5%86%9C%E8%B7%AF%E5%92%8C%E7%96%8F%E6%B8%AF%E5%A4%A7%E9%81%93%E4%BA%A4%E6%B1%87%E5%A4%84%E5%8D%8E%E4%BE%A8%E5%9F%8E%E7%BF%A1%E7%BF%A0%E5%A4%A9%E5%9F%9F HTTP/1.1" 200 135
2018-04-12 12:34:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.14946210342667,
 'lng': 118.9979559714333,
 'location': '南京项目地址：工农路和疏港大道交汇处华侨城翡翠天域',
 'name': '华侨城翡翠天域',
 'price': ' 25500',
 'when': '2018-03-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jljqhfaakts/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:34:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ytsyhaaksk/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_atssydaaktt/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hbypyaakof/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%80%BB%E9%83%A8%E5%A4%A7%E9%81%93%E6%AF%85%E8%BE%BE%E6%B1%87%E5%88%9B%E4%B8%AD%E5%BF%83 HTTP/1.1" 200 136
2018-04-12 12:34:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ydhczxabgkt/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：总部大道毅达汇创中心',
 'name': '毅达汇创中心',
 'price': ' 24500',
 'when': '2017-06-05'}
2018-04-12 12:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njjazxabhgr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:34:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E9%9E%8D%E8%A1%97%E9%81%93%E5%BC%98%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhmsabhag/>
{'lat': 32.5387256198191,
 'lng': 118.81897438994582,
 'location': '南京项目地址：马鞍街道弘湖路1号',
 'name': '郦湖美墅',
 'price': ' 18500',
 'when': '2017-07-09'}
2018-04-12 12:34:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg63> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg63> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:34:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg64> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:34:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BE%8A%E5%B1%B1%E5%8C%97%E8%B7%AF%E6%98%9F%E5%8F%B6%E7%BE%8A%E5%B1%B1%E6%B9%96%E8%8A%B1%E5%9B%AD HTTP/1.1" 200 136
2018-04-12 12:34:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12228406250346,
 'lng': 118.9464675340093,
 'location': '南京项目地址：羊山北路星叶羊山湖花园',
 'name': '星叶羊山湖花园',
 'price': 0,
 'when': '2014-10-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E4%BF%AE%E6%96%87%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.90070775306782,
 'lng': 118.91608440725392,
 'location': '南京项目地址：江宁区淳化街道修文路3号',
 'name': '金轮津桥华府',
 'price': 0,
 'when': '2016-07-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djyfaaynn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hhqhwaayej/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:34:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E8%8E%89%E6%B9%96%E8%A5%BF%E8%B7%AF31%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:34:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djyfaaynn/>
{'lat': 32.33177772895079,
 'lng': 118.81890481887899,
 'location': '南京项目地址：龙池街道莉湖西路31号',
 'name': '东骏悦府',
 'price': ' 11000',
 'when': '2016-11-03'}
2018-04-12 12:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ljlaaynh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:34:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg19> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg38> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tsyjabgtd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:34:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_klhfaadjw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djsmyhaakuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:34:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A5%A0%E6%BA%AA%E6%B1%9F%E4%B8%9C%E8%A1%97%E4%B8%8E%E6%81%92%E5%B1%B1%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 136
2018-04-12 12:34:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jrgjgcabeuu/>
{'lat': 31.996202612883714,
 'lng': 118.74177240914636,
 'location': '南京项目地址：楠溪江东街与恒山路交汇处',
 'name': '金润国际广场',
 'price': ' 31000',
 'when': '2012-11-09'}
2018-04-12 12:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flcaapqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:34:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wyqcwjblzxabgnj/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_shxgabgvr/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg43> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:34:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E4%B8%9C%E4%B8%AD%E8%B7%AF333%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_njjazxabhgr/>
{'lat': 32.00432202883629,
 'lng': 118.73176864542782,
 'location': '南京项目地址：江东中路333号',
 'name': '南京金奥中心',
 'price': 0,
 'when': '2013-12-17'}
2018-04-12 12:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wnsscdsjjqabelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wyqcwjblzxabgnj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:34:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_shxgabgvr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:34:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E6%B4%B2%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wnsscdsjjqabelo/>
{'lat': 32.16240412601025,
 'lng': 118.75041249708227,
 'location': '南京项目地址：浦洲路66号',
 'name': '威尼斯水城第十九街区',
 'price': ' 20600',
 'when': '2017-11-11'}
2018-04-12 12:34:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E9%BE%99%E5%87%A4%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:34:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wyqcwjblzxabgnj/>
{'lat': 31.943934853497655,
 'lng': 118.94156811107989,
 'location': '南京项目地址：淳化街道龙凤路2号',
 'name': '万宇汽车五金博览中心',
 'price': 0,
 'when': '2016-05-25'}
2018-04-12 12:34:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%82%85%E5%AE%B6%E8%BE%B9%E7%8E%B0%E4%BB%A3%E5%86%9C%E4%B8%9A%E5%9B%AD%E5%8C%BA%E5%86%85 HTTP/1.1" 200 133
2018-04-12 12:34:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_shxgabgvr/>
{'lat': 31.577965439645308,
 'lng': 119.01108803019201,
 'location': '南京项目地址：傅家边现代农业园区内',
 'name': '森湖溪谷',
 'price': 0,
 'when': '2009-07-17'}
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%A1%94%E8%B7%AF98%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:34:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hhqhwaayej/>
{'lat': 31.328638162523443,
 'lng': 118.88087325668766,
 'location': '南京项目地址：宝塔路98号',
 'name': '华辉秦淮湾',
 'price': 0,
 'when': '2017-06-05'}
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyozcabgyt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dyqsablea/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sclfablcb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzjjyaayda/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hlgjablxd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldhqchpbjabmmc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rssfablye/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%81%E5%AE%81%E5%A4%A7%E9%81%931998%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyozcabgyt/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滁宁大道1998号',
 'name': '碧桂园欧洲城',
 'price': 0,
 'when': '2017-07-25'}
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B4%AA%E8%93%9D%E9%95%87%E5%87%A4%E5%87%B0%E4%BA%95%E8%B7%AF26%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:34:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.634768533012924,
 'lng': 119.00443475589523,
 'location': '南京项目地址：洪蓝镇凤凰井路26号',
 'name': '天生御景',
 'price': 0,
 'when': '2014-10-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjgxtabgdk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njcfgcabgvg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tyljxyabgtm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyzsgyxabgwq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bltyabgvd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zgtjqxcabefw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%87%B4%E8%BF%9C%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:34:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.64677206867821,
 'lng': 119.04738826030771,
 'location': '南京项目地址：致远路68号',
 'name': '康利华府',
 'price': 0,
 'when': '2018-01-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhxwggaapsi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jsczgcaakng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sjtcaacko/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaaws/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E4%B8%AD%E5%BB%BA%E5%9B%BD%E7%86%99%E5%8F%B0 HTTP/1.1" 200 142
2018-04-12 12:34:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.06590199137902,
 'lng': 118.65369290890968,
 'location': '南京项目地址：新浦路中建国熙台',
 'name': '中建国熙台',
 'price': 0,
 'when': '2017-06-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:34:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg43> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:35:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E4%B8%9C%E5%8C%97%E8%B7%AF%E9%BE%99%E6%B1%9F%E9%87%8C HTTP/1.1" 200 137
2018-04-12 12:35:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ljlaaynh/>
{'lat': 32.05770706730537,
 'lng': 118.74598750383659,
 'location': '南京项目地址：江东北路龙江里',
 'name': '龙江里',
 'price': ' 34000',
 'when': '2016-12-30'}
2018-04-12 12:35:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_tyljxssyabfqd/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%B1%B1%E5%9B%BD%E5%AE%B6%E6%A3%AE%E6%9E%97%E5%85%AC%E5%9B%AD%E5%8D%97%E9%97%A8 HTTP/1.1" 200 136
2018-04-12 12:35:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dyqsablea/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华山国家森林公园南门',
 'name': '东原亲山',
 'price': ' 20000',
 'when': '2017-12-22'}
2018-04-12 12:35:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg44> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:35:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%90%E5%B1%B1%E8%B7%AF208%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99841267184827,
 'lng': 118.730251217879,
 'location': '南京项目地址：庐山路208号',
 'name': '德基世贸壹号',
 'price': ' 37000',
 'when': '2014-10-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%B1%B1%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09260114030094,
 'lng': 118.81803364578863,
 'location': '南京项目地址：红山路88号',
 'name': '南京常发广场',
 'price': ' 25000',
 'when': '2015-08-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dsszyjhfaawli/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcslabfij/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:35:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%9C%B0%E9%93%81%E4%BA%8C%E5%8F%B7%E7%BA%BF%E5%A4%A9%E8%BF%88%E5%B9%BF%E5%9C%BA%E6%B2%B9%E5%9D%8A%E6%A1%A5%E7%AB%99 HTTP/1.1" 200 139
2018-04-12 12:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sclfablcb/>
{'lat': 31.971841104007034,
 'lng': 118.72764980327469,
 'location': '南京项目地址：建邺地铁二号线天迈广场油坊桥站',
 'name': '首创立方',
 'price': ' 30000',
 'when': '2017-10-13'}
2018-04-12 12:35:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E9%BA%92%E8%B7%AF277%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:03 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.01565712729463,
 'lng': 118.88669095266192,
 'location': '南京项目地址：东麒路277号',
 'name': '富力城',
 'price': 0,
 'when': '2012-11-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gcdtljaacgp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:35:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wkjxtaamsn/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:03 [scrapy.extensions.logstats] INFO: Crawled 347 pages (at 92 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:35:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E4%B8%83%E9%87%8C%E8%B7%AF%E4%B8%8E%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:35:03 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0913457771416,
 'lng': 118.65014507465395,
 'location': '南京项目地址：江浦街道七里路与沿山大道交汇处',
 'name': '通宇林景熙园',
 'price': 0,
 'when': '2017-08-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%81%B5%E5%B1%B1%E5%8C%97%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dsszyjhfaawli/>
{'lat': 32.098719710952,
 'lng': 118.93614446759723,
 'location': '南京项目地址：灵山北路9号',
 'name': '东墅山庄英郡华府',
 'price': ' 2480',
 'when': '2014-05-03'}
2018-04-12 12:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dcjmyaatpv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg45> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flshabfza/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyshsjabryn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:03 [scrapy.extensions.logstats] INFO: Crawled 404 pages (at 51 pages/min), scraped 230 items (at 41 items/min)
2018-04-12 12:35:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E5%AF%8C%E5%A1%98%E8%A1%978%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lcslabfij/>
{'lat': 31.97168171605523,
 'lng': 118.86003408519586,
 'location': '南京项目地址：东山街道富塘街8号',
 'name': '绿城深蓝',
 'price': 0,
 'when': '2018-02-11'}
2018-04-12 12:35:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E5%87%A4%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.652751200874587,
 'lng': 119.0233543470155,
 'location': '南京项目地址：栖凤路68号',
 'name': '弘阳禹洲时光印象',
 'price': 0,
 'when': '2017-12-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%94%E5%A4%A9%E5%A4%A7%E8%A1%97%E4%BF%9D%E5%88%A9%E5%A4%A9%E6%82%A6 HTTP/1.1" 200 145
2018-04-12 12:35:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.03108091466837,
 'lng': 118.73254774489833,
 'location': '南京项目地址：应天大街保利天悦',
 'name': '保利天悦',
 'price': 0,
 'when': '2017-11-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BF%88%E5%B0%A7%E8%B7%AF327%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:35:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12259447503586,
 'lng': 118.84063643989731,
 'location': '南京项目地址：迈尧路327号',
 'name': '中国铁建青秀城',
 'price': 0,
 'when': '2014-12-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_pthtxsqabgbq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg18)
2018-04-12 12:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_blsdgcabdzt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:35:05 [scrapy.extensions.logstats] INFO: Crawled 164 pages (at 32 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E9%9D%96%E4%B8%9C%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dcjmyaatpv/>
{'lat': 31.96985873235598,
 'lng': 118.87182639943344,
 'location': '南京项目地址：文靖东路88号',
 'name': '东城金茂悦',
 'price': 0,
 'when': '2017-07-03'}
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.13531269255433,
 'lng': 118.74226588429522,
 'location': '南京项目地址：江山路9号',
 'name': '浦泰和天下三期',
 'price': 0,
 'when': '2017-11-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E9%BA%92%E8%B7%AF277%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_flshabfza/>
{'lat': 32.01565712729463,
 'lng': 118.88669095266192,
 'location': '南京项目地址：东麒路277号',
 'name': '富力十号',
 'price': ' 900',
 'when': '2015-06-02'}
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E5%B1%B1%E8%A5%BF%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%ADS1%E7%A7%A6%E6%B7%AE%E4%B8%96%E5%AE%B6 HTTP/1.1" 200 137
2018-04-12 12:35:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyshsjabryn/>
{'lat': 31.648311742573938,
 'lng': 118.91514343402882,
 'location': '南京项目地址：横山西路碧桂园S1秦淮世家',
 'name': '碧桂园S1秦淮世家',
 'price': ' 60000',
 'when': '2018-03-17'}
2018-04-12 12:35:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_undefinedaatan/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:35:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxlshslaasuo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:35:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BE%90%E5%BA%84%E8%BD%AF%E4%BB%B6%E5%9B%AD HTTP/1.1" 200 143
2018-04-12 12:35:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_snzjjyaayda/>
{'lat': 32.097126504668104,
 'lng': 118.89223524935424,
 'location': '南京项目地址：徐庄软件园',
 'name': '苏宁紫金嘉悦',
 'price': ' 20000',
 'when': '2016-09-24'}
2018-04-12 12:35:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%81%92%E5%98%89%E8%B7%AF%E4%B8%AD%E6%B5%B7%E7%8E%84%E6%AD%A6%E5%85%AC%E9%A6%86 HTTP/1.1" 200 142
2018-04-12 12:35:08 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10309198480382,
 'lng': 118.82802835368933,
 'location': '南京项目地址：恒嘉路中海玄武公馆',
 'name': '中海玄武公馆',
 'price': 0,
 'when': '2017-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E9%AB%98%E5%BA%99%E8%B7%AF%E6%9C%97%E8%AF%97%E7%86%99%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 141
2018-04-12 12:35:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_undefinedaatan/>
{'lat': 31.9752553808195,
 'lng': 118.69895635055644,
 'location': '南京项目地址：南高庙路朗诗熙华府',
 'name': '朗诗熙华府',
 'price': 0,
 'when': '2017-11-20'}
2018-04-12 12:35:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacela/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:35:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%A7%E8%A1%9781%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:35:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hlgjablxd/>
{'lat': 32.0574390450143,
 'lng': 118.78971204573793,
 'location': '南京项目地址：中大街81号',
 'name': '海伦国际',
 'price': 0,
 'when': '2017-10-31'}
2018-04-12 12:35:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E5%AE%81%E8%B7%AF31%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09653621784545,
 'lng': 118.78217765020526,
 'location': '南京项目地址：建宁路31号',
 'name': '金盛财智广场',
 'price': 0,
 'when': '2012-09-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%9B%A2%E5%B1%B1%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:35:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.698645656477684,
 'lng': 119.02620947633312,
 'location': '南京项目地址：团山路1号',
 'name': '世纪天城',
 'price': 0,
 'when': '2016-07-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%BF%E8%A5%BF%E5%9F%82%E5%A4%A7%E8%A1%97100%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09061065715351,
 'lng': 118.67518410377791,
 'location': '南京项目地址：广西埂大街100号',
 'name': '华润国际社区',
 'price': 0,
 'when': '2017-12-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hbypyaakof/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:35:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ytsyhaaksk/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:35:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ylcsjqaadxn/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:35:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_cpcaagvp/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:35:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E9%9B%84%E5%B7%9E%E5%8D%97%E8%B7%AF333%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.32400440901211,
 'lng': 118.8261801952043,
 'location': '南京项目地址：龙池街道雄州南路333号',
 'name': '冠城大通蓝郡',
 'price': 0,
 'when': '2017-08-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%96%B0%E6%B5%A6%E8%B7%AF128%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.07216834555913,
 'lng': 118.65572949722356,
 'location': '南京项目地址：江浦街道新浦路128号',
 'name': '宝隆时代广场',
 'price': ' 16500',
 'when': '2017-11-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdzxfhaatqu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_2jbjhabhfk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:35:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyyjfabhht/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:35:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg20> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdwryabhfp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:35:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfytaaycz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgybasjabgyc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
2018-04-12 12:35:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E4%B8%9C%E5%8D%97%E8%B7%AF%E9%87%91%E5%9C%B0%E4%B8%AD%E5%BF%83%E9%A3%8E%E5%8D%8E HTTP/1.1" 200 136
2018-04-12 12:35:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.981980257155737,
 'lng': 118.70237986022788,
 'location': '南京项目地址：江东南路金地中心风华',
 'name': '金地中心风华',
 'price': 0,
 'when': '2017-11-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_2jbjhabhfk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg17)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 45, in parse_html
    item["name"] = response.xpath('//h1/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E8%B7%AF6%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jxlshslaasuo/>
{'lat': 32.132337610018176,
 'lng': 118.739274526947,
 'location': '南京项目地址：江山路6号',
 'name': '金象朗诗红树林',
 'price': 0,
 'when': '2017-10-28'}
2018-04-12 12:35:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg46> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacela/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacell/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacell/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8D%97%E8%B7%AF117%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.324725434771544,
 'lng': 118.90167334739824,
 'location': '南京项目地址：淳南路117号',
 'name': '湖滨一品苑',
 'price': 0,
 'when': '2011-04-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_atssydaaktt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:35:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg39> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:35:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%AA%E6%96%B0%E8%B7%AF%E5%BC%98%E9%98%B3%E7%87%95%E6%B1%9F%E5%BA%9C HTTP/1.1" 200 144
2018-04-12 12:35:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.14416255725624,
 'lng': 118.83407420848347,
 'location': '南京项目地址：太新路弘阳燕江府',
 'name': '弘阳燕江府',
 'price': 0,
 'when': '2017-06-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E5%8C%97%E8%B7%AF279%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:35:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08261037776124,
 'lng': 118.76973175941542,
 'location': '南京项目地址：中山北路279号',
 'name': '金鼎湾如院',
 'price': 0,
 'when': '2015-10-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdfchtabilb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:35:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E9%A3%9E%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdfchtabilb/>
{'lat': 32.104949086157944,
 'lng': 118.82824103380696,
 'location': '南京项目地址：华飞路1号',
 'name': '恒大翡翠华庭',
 'price': ' 380',
 'when': '2017-07-05'}
2018-04-12 12:35:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjlhjqabkjx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:35:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%8E%8B%E5%A4%A7%E8%A1%97%E7%BB%BF%E5%9C%B0%E5%8D%8E%E4%BE%A8%E5%9F%8E%E6%B5%B7%E7%8F%80%E6%BB%A8%E6%B1%9F HTTP/1.1" 200 137
2018-04-12 12:35:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ldhqchpbjabmmc/>
{'lat': 31.981396621207637,
 'lng': 118.69564997992349,
 'location': '南京项目地址：龙王大街绿地华侨城海珀滨江',
 'name': '绿地华侨城海珀滨江',
 'price': 0,
 'when': '2017-11-20'}
2018-04-12 12:35:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E9%9D%96%E8%B7%AF599%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:15 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.966100163341842,
 'lng': 118.85850571579324,
 'location': '南京项目地址：文靖路599号',
 'name': '爱涛尚书云邸',
 'price': 0,
 'when': '2016-03-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hjjlmyaadyi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:35:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_akszsfaaabj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:35:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djhfaabvz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:35:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjszaabur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:35:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smwtxcaacap/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:35:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zlhyaabas/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:35:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E7%91%B6%E8%B7%AF7%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:15 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09198071246321,
 'lng': 118.65432397571688,
 'location': '南京项目地址：七瑶路7号',
 'name': '明发悦庭',
 'price': ' 18500',
 'when': '2017-09-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%81%E9%98%B3%E4%B8%9C%E8%B7%AF901%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:35:15 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滁阳东路901号',
 'name': '碧桂园北岸世家',
 'price': 0,
 'when': '2017-07-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E5%BE%B7%E8%B7%AF65%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:35:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjlhjqabkjx/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：金德路65号',
 'name': '中骏六号街区',
 'price': ' 14000',
 'when': '2018-03-26'}
2018-04-12 12:35:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceks/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qhyzabnwc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:35:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyfhcabjte/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:35:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tyljzyabnpz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:35:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceks/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E5%A1%98%E5%8D%97%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:35:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_qhyzabnwc/>
{'lat': 31.676904082947466,
 'lng': 119.03333730597843,
 'location': '南京项目地址：双塘南路68号',
 'name': '秦淮源筑',
 'price': ' 12000',
 'when': '2017-11-29'}
2018-04-12 12:35:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkddhabexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zgtjyxsaatpp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xhbyqhaathi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E6%B5%8E%E5%BC%80%E5%8F%91%E5%8C%BAS122%E4%B8%9C%E5%8C%97%E4%BE%A7%E7%A2%A7%E6%A1%82%E5%9B%AD%E5%87%A4%E5%87%B0%E5%9F%8E HTTP/1.1" 200 144
2018-04-12 12:35:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyfhcabjte/>
{'lat': 32.032188608864764,
 'lng': 119.09968634138617,
 'location': '南京项目地址：经济开发区S122东北侧碧桂园凤凰城',
 'name': '碧桂园凤凰城',
 'price': ' 12000',
 'when': '2018-04-07'}
2018-04-12 12:35:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E7%86%9F%E8%A1%97%E9%81%93%E7%81%B5%E9%A1%BA%E5%8C%97%E8%B7%AF211%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:35:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.873002120783894,
 'lng': 118.98550482825115,
 'location': '南京项目地址：湖熟街道灵顺北路211号',
 'name': '恒建金陵美域',
 'price': 0,
 'when': '2015-10-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cpcaagvp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%91%9B%E5%A1%98%E8%A1%97%E9%81%93%E5%92%8C%E6%97%AD%E8%B7%AF500%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:35:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rssfablye/>
{'lat': 32.249438029473545,
 'lng': 118.74243099284794,
 'location': '南京项目地址：葛塘街道和旭路500号',
 'name': '荣盛首府',
 'price': 0,
 'when': '2017-11-29'}
2018-04-12 12:35:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_lhxycabktp/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:17 [scrapy.extensions.logstats] INFO: Crawled 588 pages (at 41 pages/min), scraped 299 items (at 37 items/min)
2018-04-12 12:35:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_zdmygcabmqi/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:35:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg65> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:35:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_dhjxhcyabmqu/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:35:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_zhtylabxle/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:35:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_zdmygcabmqh/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E6%9E%A2%E8%A5%BF%E8%B7%AF%E5%A5%A5%E5%85%8B%E6%96%AF%E9%92%9F%E5%B1%B1%E5%BA%9C HTTP/1.1" 200 142
2018-04-12 12:35:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09514392116203,
 'lng': 118.91396510333544,
 'location': '南京项目地址：文枢西路奥克斯钟山府',
 'name': '奥克斯钟山府',
 'price': 0,
 'when': '2018-01-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E6%A2%81%E8%A1%97%E9%81%93%E7%91%9E%E6%88%90%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:35:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.331850449520935,
 'lng': 118.94026095169839,
 'location': '南京项目地址：横梁街道瑞成路9号',
 'name': '东骏华府',
 'price': 0,
 'when': '2013-12-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E4%B8%81%E5%AE%B6%E5%B1%B1%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.24351789402061,
 'lng': 118.78205578787639,
 'location': '南京项目地址：大厂丁家山路2号',
 'name': '碧景山庄',
 'price': 0,
 'when': '2015-02-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E9%80%9A%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08452501199852,
 'lng': 118.74076903872225,
 'location': '南京项目地址：南通路89号',
 'name': '世茂外滩新城',
 'price': ' 35900',
 'when': '时间待定'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg65> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:35:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdmygcabmqh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:35:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E9%80%9A%E5%AE%87%E6%9E%97%E6%99%AF%E5%B0%8A%E5%9B%AD HTTP/1.1" 200 136
2018-04-12 12:35:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tyljzyabnpz/>
{'lat': 32.075130364489524,
 'lng': 118.65787254029496,
 'location': '南京项目地址：新浦路通宇林景尊园',
 'name': '通宇林景尊园',
 'price': ' 27300',
 'when': '2017-12-20'}
2018-04-12 12:35:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%AB%99%E4%B8%9C%E4%BA%8C%E8%B7%AF%E4%B8%87%E7%A7%91%E5%A4%A7%E9%83%BD%E4%BC%9A HTTP/1.1" 200 136
2018-04-12 12:35:18 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：站东二路万科大都会',
 'name': '万科大都会',
 'price': 0,
 'when': '2018-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgysjcbabisk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:35:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xlqpcsqabirq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:35:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:35:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_thnjyzaatgz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcpyhsabezj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djzcfycsgcabfky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:35:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E6%A1%A5%E5%8D%97%E8%B7%AF108%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:18 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.865478012062233,
 'lng': 118.61613434356234,
 'location': '南京项目地址：宁桥南路108号',
 'name': '中国铁建原香颂',
 'price': 0,
 'when': '2017-09-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%B0%E6%B3%BD%E8%B7%AF118%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:35:19 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.998126980049786,
 'lng': 118.88957460317951,
 'location': '南京项目地址：丰泽路118号',
 'name': '中粮鸿云',
 'price': 0,
 'when': '2017-09-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ylcsjqaadxn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:35:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E7%A6%84%E5%A4%A7%E9%81%931%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:19 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.79647196501264,
 'lng': 118.86518619158387,
 'location': '南京项目地址：天禄大道1号',
 'name': '翠屏城',
 'price': ' 11900',
 'when': '2017-11-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%83%AD%E5%BA%84%E9%95%87%E6%9C%BA%E5%9C%BA%E5%A4%A7%E9%81%93%E5%8D%97%E7%A2%A7%E6%A1%82%E5%9B%AD%E4%B8%96%E7%BA%AA%E5%9F%8E%E9%82%A6 HTTP/1.1" 200 134
2018-04-12 12:35:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgysjcbabisk/>
{'lat': 31.346944453868932,
 'lng': 118.89424983420618,
 'location': '南京项目地址：郭庄镇机场大道南碧桂园世纪城邦',
 'name': '碧桂园世纪城邦',
 'price': ' 12000',
 'when': '2017-08-12'}
2018-04-12 12:35:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg47> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:35:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyshsjabnav/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:35:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E5%86%9C%E8%8A%B1%E8%B7%AF102%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.974841301133058,
 'lng': 118.79538062299754,
 'location': '南京项目地址：东山街道农花路102号',
 'name': '旭辉铂悦秦淮',
 'price': 0,
 'when': '2017-07-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:35:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%8B%E5%AD%90%E6%A5%BC%E8%A5%BF108%E5%8F%B7 HTTP/1.1" 200 133
2018-04-12 12:35:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xlqpcsqabirq/>
{'lat': 32.12560776782336,
 'lng': 118.90211449894603,
 'location': '南京项目地址：王子楼西108号',
 'name': '仙林汽配城',
 'price': 0,
 'when': '2017-08-04'}
2018-04-12 12:35:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E5%B1%B1%E8%A5%BF%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%ADS1%E7%A7%A6%E6%B7%AE%E4%B8%96%E5%AE%B6 HTTP/1.1" 200 137
2018-04-12 12:35:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyshsjabnav/>
{'lat': 31.648311742573938,
 'lng': 118.91514343402882,
 'location': '南京项目地址：横山西路碧桂园S1秦淮世家',
 'name': '碧桂园S1秦淮世家',
 'price': 0,
 'when': '2017-11-30'}
2018-04-12 12:35:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:35:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%8C%AF%E5%85%B4%E8%B7%AF180%E5%8F%B7%E3%80%81%E8%83%A5%E6%BA%AA%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:22 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.298993439267697,
 'lng': 119.07494337758881,
 'location': '南京项目地址：振兴路180号、胥溪路9号',
 'name': '垠领城市街区',
 'price': 0,
 'when': '2016-06-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg40> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:35:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzhybhlaawbr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:35:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhjlmzaawjd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:35:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_slzxcaawcm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:35:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E5%8D%97%E8%B7%AF501%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:22 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.026788843993685,
 'lng': 118.78769049901827,
 'location': '南京项目地址：中山南路501号',
 'name': '泰禾南京院子',
 'price': 0,
 'when': '2017-06-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E9%97%A8%E5%A4%A7%E8%A1%97297%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdmygcabmqh/>
{'lat': 32.043648320833704,
 'lng': 118.86848048488551,
 'location': '南京项目地址：中山门大街297号',
 'name': '钟鼎名悦广场',
 'price': 0,
 'when': '2017-09-16'}
2018-04-12 12:35:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhtylabxle/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:35:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdmygcabmqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:35:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dhjxhcyabmqu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:35:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B6%A6%E5%AF%BF%E5%8C%97%E8%B7%AF599%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.859401199797308,
 'lng': 118.60077001053546,
 'location': '南京项目地址：润寿北路599号',
 'name': '禹洲弘阳滨湖里',
 'price': 0,
 'when': '2016-12-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkjxtaamsn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:35:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycdyfaauuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:35:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hcwjaauyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:35:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%92%9F%E5%B1%B1%E8%B7%AF%E6%96%B0%E5%9F%8E%E7%92%9E%E6%A8%BE%E5%92%8C%E5%B1%B1 HTTP/1.1" 200 135
2018-04-12 12:35:25 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04095857741548,
 'lng': 118.85225558502222,
 'location': '南京项目地址：钟山路新城璞樾和山',
 'name': '新城璞樾和山',
 'price': ' 30000',
 'when': '2018-02-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%83%AD%E6%B2%B3%E5%8D%97%E8%B7%AF%E6%9E%9C%E5%93%81%E5%B8%82%E5%9C%BA%E5%9C%B0%E5%9D%97%E4%B8%AD%E6%B5%B7%E6%A1%83%E5%9B%AD%E9%87%8C HTTP/1.1" 200 136
2018-04-12 12:35:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhtylabxle/>
{'lat': 32.083859111765705,
 'lng': 118.7477835049071,
 'location': '南京项目地址：热河南路果品市场地块中海桃园里',
 'name': '中海桃源里',
 'price': 0,
 'when': '2018-03-31'}
2018-04-12 12:35:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg66> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tyljxssyabfqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:35:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhxycabktp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:35:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E9%97%A8%E5%A4%A7%E8%A1%97297%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdmygcabmqi/>
{'lat': 32.043648320833704,
 'lng': 118.86848048488551,
 'location': '南京项目地址：中山门大街297号',
 'name': '钟鼎名悦广场',
 'price': ' 50000',
 'when': '2018-03-19'}
2018-04-12 12:35:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%83%9C%E5%A4%AA%E8%B7%AF%E9%87%91%E8%BE%89%E9%87%91%E9%99%B5%E9%93%AD%E8%91%97 HTTP/1.1" 200 135
2018-04-12 12:35:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.95061810100132,
 'lng': 118.82058772867562,
 'location': '南京项目地址：胜太路金辉金陵铭著',
 'name': '金辉金陵铭著',
 'price': 0,
 'when': '2016-11-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%AD%E5%90%88%E5%8C%BA%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E7%8E%8B%E6%A1%A5%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 134
2018-04-12 12:35:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.33244867233251,
 'lng': 118.84063470707173,
 'location': '南京项目地址：六合区雄州街道王桥路99号',
 'name': '石林中心城',
 'price': 0,
 'when': '2017-10-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gcbgyaaejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:35:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlhbskpaaekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:35:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B0%8F%E5%B8%82%E8%A1%97%E9%81%93%E7%94%B5%E5%BB%BA%E4%B8%AD%E5%82%A8%E6%B3%9B%E6%82%A6%E5%9F%8E%E5%B8%82%E5%B9%BF%E5%9C%BA HTTP/1.1" 200 134
2018-04-12 12:35:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10631834473104,
 'lng': 118.796087672078,
 'location': '南京项目地址：小市街道电建中储泛悦城市广场',
 'name': '电建中储泛悦城市广场',
 'price': ' 35900',
 'when': '2017-12-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacelb/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:35:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:35:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg21> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:35:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjjzaatbs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%BD%E6%B3%BD%E8%B7%AF599%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:28 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.91449917688987,
 'lng': 118.89241944689905,
 'location': '南京项目地址：丽泽路599号',
 'name': '五矿九玺台',
 'price': 0,
 'when': '2013-01-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:35:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dhjxhcyabmqu/>
{'lat': 32.123523391191696,
 'lng': 118.72947850536069,
 'location': '南京项目地址：浦口区浦珠北路59号',
 'name': '大华锦绣华城商业',
 'price': ' 45000',
 'when': '2017-07-18'}
2018-04-12 12:35:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%8E%E5%9F%8E%E5%A4%A7%E9%81%93%E4%BB%A5%E8%A5%BF%E4%B8%AD%E4%BA%A4%E9%94%A6%E8%87%B4 HTTP/1.1" 200 136
2018-04-12 12:35:30 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97475979445248,
 'lng': 118.81085768852734,
 'location': '南京项目地址：明城大道以西中交锦致',
 'name': '中交锦致',
 'price': 0,
 'when': '2017-07-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:35:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:35:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:35:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceku/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:35:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:35:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceku/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:35:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg48> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg22> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%B7%E7%A6%8F%E5%B7%B771%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.02535577253019,
 'lng': 118.84839752545017,
 'location': '南京项目地址：海福巷71号',
 'name': '银城东岳府',
 'price': 0,
 'when': '2017-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg49> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wkapysaatgt/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:35:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg20)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacels/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacels/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceki/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceki/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B9%96%E5%A4%A7%E9%81%93%E5%92%8C%E6%98%8C%E6%B9%BE%E6%99%AF HTTP/1.1" 200 142
2018-04-12 12:35:33 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.9254387597965,
 'lng': 118.67555812585326,
 'location': '南京项目地址：新湖大道和昌湾景',
 'name': '和昌湾景',
 'price': 0,
 'when': '2017-07-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceme/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:35:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceme/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E7%99%BD%E9%A9%AC%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:35:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tyljxssyabfqd/>
{'lat': 32.08732150414787,
 'lng': 118.63490312801513,
 'location': '南京项目地址：江浦街道白马路89号',
 'name': '通宇林景象山墅院',
 'price': ' 38000',
 'when': '2016-03-26'}
2018-04-12 12:35:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:35:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%9C%A0%E5%A4%A7%E9%81%93660%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhxycabktp/>
{'lat': 31.915202403612295,
 'lng': 118.90964727896606,
 'location': '南京项目地址：龙眠大道660号',
 'name': '龙湖新壹城',
 'price': 0,
 'when': '2017-10-25'}
2018-04-12 12:35:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg67> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceju/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceju/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:35:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkapysaatgt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg19)
2018-04-12 12:35:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:35:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyslcfabkak/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:35:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg50> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BB%93%E5%AE%B6%E5%B7%B7%E4%B8%87%E7%A7%91%E5%AE%89%E5%93%81%E5%9B%AD%E8%88%8D HTTP/1.1" 200 131
2018-04-12 12:35:37 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.9649933148731,
 'lng': 118.76593279846456,
 'location': '南京项目地址：仓家巷万科安品园舍',
 'name': '万科安品园舍',
 'price': 0,
 'when': '2016-06-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg23> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:35:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:35:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E6%BA%AA%E9%95%87%E7%9F%B3%E8%87%BC%E6%B9%96%E5%8C%97%E8%B7%AF76%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:38 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.344123311690005,
 'lng': 118.89682926137152,
 'location': '南京项目地址：淳溪镇石臼湖北路76号',
 'name': '高淳碧桂园',
 'price': 0,
 'when': '2018-03-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg51> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg24> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceow/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceow/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceot/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:35:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceot/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
2018-04-12 12:35:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceod/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg22)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceod/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:35:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:35:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg25> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:35:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacene/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E6%B8%85%E6%B0%B4%E4%BA%AD%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:35:40 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.919765529265728,
 'lng': 118.81406744370776,
 'location': '南京项目地址：秣陵街道清水亭西路188号',
 'name': '九龙湖别墅',
 'price': 0,
 'when': '2016-11-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:40 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_ytsyhaaksk/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_rdxfcaaekr/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:35:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg41> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:35:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacene/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://nj.fang.lianjia.com/loupan/p_ytsyhaaksk/>: Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:35:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceql/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:35:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceql/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E7%90%8A%E5%B1%B1%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%AD%E5%8D%81%E9%87%8C%E6%98%A5%E9%A3%8E HTTP/1.1" 200 134
2018-04-12 12:35:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyslcfabkak/>
{'lat': 31.346944453868932,
 'lng': 118.89424983420618,
 'location': '南京项目地址：红琊山路碧桂园十里春风',
 'name': '碧桂园十里春风',
 'price': ' 7500',
 'when': '2018-03-07'}
2018-04-12 12:35:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:35:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceln/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rdxfcaaekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:35:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:35:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg68> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:35:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:35:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:35:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:35:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:35:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceli/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:35:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceli/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:35:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:35:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacept/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacems/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacept/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceps/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceps/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B9%E5%B7%9E%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:43 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.365988858238566,
 'lng': 118.85472132611994,
 'location': '南京项目地址：方州路68号',
 'name': '荣鼎幸福城',
 'price': 0,
 'when': '2018-01-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg41> (referer: https://nj.fang.lianjia.com/loupan/pg/pg40)
2018-04-12 12:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceon/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceon/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flsjfaawld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:35:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hzqlwaawla/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:35:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:35:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceln/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacens/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:35:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceln/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacens/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceou/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceou/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:45 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:35:45 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:35:46 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:35:46 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:35:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacekv/>: HTTP status code is not handled or not allowed
2018-04-12 12:35:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceph/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:35:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacele/>: HTTP status code is not handled or not allowed
2018-04-12 12:35:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:35:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceph/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9A%82%E6%97%A0 HTTP/1.1" 200 136
2018-04-12 12:35:46 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：暂无',
 'name': '富力水街坊',
 'price': 0,
 'when': '2017-12-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxcjyaawif/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:35:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E7%94%9F%E6%A1%A5%E5%A4%A7%E9%81%93218%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:49 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.648004371136633,
 'lng': 119.0089268568526,
 'location': '南京项目地址：天生桥大道218号',
 'name': '华洲青林湾',
 'price': 0,
 'when': '2017-09-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:35:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg26> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:35:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:35:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:35:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg69> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%8C%BA%E5%B7%B4%E5%B1%B1%E8%B7%AF38%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:51 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.008675496084074,
 'lng': 118.73063170639526,
 'location': '南京项目地址：建邺区巴山路38号',
 'name': '华新城璟园',
 'price': 0,
 'when': '2016-05-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacemq/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:35:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xzllhwaawji/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:35:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fctyaawlb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:35:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8F%8D%E7%8F%A0%E5%8C%97%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:35:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.684557220584292,
 'lng': 119.03736365769795,
 'location': '南京项目地址：珍珠北路88号',
 'name': '喜之郎丽湖湾',
 'price': 0,
 'when': '2015-12-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:35:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E5%8C%97%E8%B7%AF369%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:35:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.612703497788456,
 'lng': 118.99424929340748,
 'location': '南京项目地址：金牛北路369号',
 'name': '福晟庭院',
 'price': 0,
 'when': '2015-10-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:35:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:35:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:35:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:53 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacems/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:35:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://nj.fang.lianjia.com/loupan/p_bcaccii/>: Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacems/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:35:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacequ/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:35:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg42> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:35:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacema/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:53 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:35:53 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcaceog/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg23)
2018-04-12 12:35:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacequ/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:35:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcaceog/>: HTTP status code is not handled or not allowed
2018-04-12 12:35:53 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:35:53 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:35:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacelq/>: HTTP status code is not handled or not allowed
2018-04-12 12:35:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:35:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg70> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:35:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg43> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceom/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfysyfaayds/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:35:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceom/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:35:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93%E5%92%8C%E8%8A%B1%E5%8D%89%E5%A4%A7%E9%81%93%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 135
2018-04-12 12:35:54 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08114358586541,
 'lng': 118.64442572426861,
 'location': '南京项目地址：沿山大道和花卉大道交汇处',
 'name': '明发阅山悦府',
 'price': 0,
 'when': '2018-02-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlxlfaayvm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znsjyyaaynl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceol/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:35:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceol/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg27> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:35:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg71> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:35:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:35:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg72> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:35:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:35:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:35:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:35:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:35:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg73> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacera/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:35:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacera/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:35:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:35:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceui/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacero/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceti/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceui/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacero/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceti/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacema/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:35:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacema/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8D%97%E8%A1%97%E9%81%93%E9%87%91%E8%BD%AE%E6%98%9F%E7%AB%8B%E6%96%B9 HTTP/1.1" 200 136
2018-04-12 12:35:57 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99799477275822,
 'lng': 118.78177238865749,
 'location': '南京项目地址：宁南街道金轮星立方',
 'name': '金轮星立方',
 'price': ' 21000',
 'when': '2015-12-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcthyabgvb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wyqcwjblzxabgnj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacern/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:35:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacern/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacess/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:35:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacess/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacest/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:35:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacest/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:35:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:35:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
2018-04-12 12:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacery/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg21)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacery/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:35:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceqf/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:35:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg28> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:35:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceri/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:35:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceri/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:35:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:35:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%8E%E5%9F%8E%E5%A4%A7%E9%81%93%E4%B8%87%E7%A7%91%E9%83%BD%E8%8D%9F%E5%8D%97%E8%8B%91 HTTP/1.1" 200 136
2018-04-12 12:35:59 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97475979445248,
 'lng': 118.81085768852734,
 'location': '南京项目地址：明城大道万科都荟南苑',
 'name': '万科星荟',
 'price': 0,
 'when': '2017-10-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:35:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:36:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:36:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacenp/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacepc/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
2018-04-12 12:36:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg74> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:36:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:36:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:36:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg25)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:01 [scrapy.extensions.logstats] INFO: Crawled 256 pages (at 92 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:36:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E4%B8%AD%E5%8D%97%E4%B8%96%E7%BA%AA%E9%9B%85%E8%8B%91 HTTP/1.1" 200 143
2018-04-12 12:36:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04313070524712,
 'lng': 118.91670898739703,
 'location': '南京项目地址：马群街道中南世纪雅苑',
 'name': '中南世纪雅苑',
 'price': 0,
 'when': '2017-05-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ydhczxabgkt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:36:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:02 [scrapy.extensions.logstats] INFO: Crawled 658 pages (at 70 pages/min), scraped 306 items (at 7 items/min)
2018-04-12 12:36:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:36:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:02 [scrapy.extensions.logstats] INFO: Crawled 477 pages (at 73 pages/min), scraped 244 items (at 14 items/min)
2018-04-12 12:36:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:36:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg52> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacets/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacety/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacets/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacety/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceto/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceto/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacete/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
2018-04-12 12:36:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacete/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg75> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg27)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E5%B1%B1%E8%A1%97%E9%81%93%E9%BA%92%E9%BA%9F%E9%97%A8%E5%A4%A7%E9%81%936699%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:36:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04571553461317,
 'lng': 119.02176299880456,
 'location': '南京项目地址：汤山街道麒麟门大道6699号',
 'name': '绿城桃花源',
 'price': 0,
 'when': '2018-03-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E9%BE%99%E5%87%A4%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:36:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.943934853497655,
 'lng': 118.94156811107989,
 'location': '南京项目地址：淳化街道龙凤路2号',
 'name': '万宇汽车五金博览中心',
 'price': 0,
 'when': '2016-05-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:04 [scrapy.extensions.logstats] INFO: Crawled 383 pages (at 36 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:36:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%80%BB%E9%83%A8%E5%A4%A7%E9%81%93%E6%AF%85%E8%BE%BE%E6%B1%87%E5%88%9B%E4%B8%AD%E5%BF%83 HTTP/1.1" 200 136
2018-04-12 12:36:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：总部大道毅达汇创中心',
 'name': '毅达汇创中心',
 'price': ' 24500',
 'when': '2017-06-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg44> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:36:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_heshyhggabgfc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:36:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcslabfij/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:36:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flshabfza/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:36:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jngcabbex/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:36:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhcjzcabbrp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:36:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:36:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.393150940897428,
 'lng': 118.97196008794114,
 'location': '南京项目地址：双湖路1号',
 'name': '海尔双湖壹号公馆',
 'price': 0,
 'when': '2017-06-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znjyabaye/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:36:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:36:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:36:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceth/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceth/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
2018-04-12 12:36:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg26)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
2018-04-12 12:36:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg24)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E5%AF%8C%E5%A1%98%E8%A1%978%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:07 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97168171605523,
 'lng': 118.86003408519586,
 'location': '南京项目地址：东山街道富塘街8号',
 'name': '绿城深蓝',
 'price': 0,
 'when': '2018-02-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceta/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceta/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:36:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E9%BA%92%E8%B7%AF277%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:09 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.01565712729463,
 'lng': 118.88669095266192,
 'location': '南京项目地址：东麒路277号',
 'name': '富力十号',
 'price': ' 900',
 'when': '2015-06-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%AD%E5%90%88%E9%95%BF%E6%B1%9F%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.347517586163555,
 'lng': 118.84876979582978,
 'location': '南京项目地址：六合长江路1号',
 'name': '金宁广场',
 'price': ' 13000',
 'when': '2010-11-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E8%BE%B9%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:36:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.095733750047245,
 'lng': 118.74065486319363,
 'location': '南京项目地址：江边路1号',
 'name': '龙湖春江紫宸',
 'price': 0,
 'when': '2017-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlxgmzabfmg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hlgjabatq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:36:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BD%AF%E4%BB%B6%E5%A4%A7%E9%81%93%E4%B8%AD%E5%8D%97%E9%94%A6%E8%8B%91 HTTP/1.1" 200 144
2018-04-12 12:36:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.984256699458975,
 'lng': 118.75651496529456,
 'location': '南京项目地址：软件大道中南锦苑',
 'name': '中南锦苑',
 'price': ' 150',
 'when': '2017-03-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%AF%9A%E4%BF%A1%E5%A4%A7%E9%81%93998%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:36:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.91463660152268,
 'lng': 118.84551268108456,
 'location': '南京项目地址：诚信大道998号',
 'name': '金轮星光名座',
 'price': 0,
 'when': '2013-01-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%A7%E8%A1%9781%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:36:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0574390450143,
 'lng': 118.78971204573793,
 'location': '南京项目地址：中大街81号',
 'name': '海伦国际',
 'price': ' 12730',
 'when': '2017-10-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:36:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg52> (referer: https://nj.fang.lianjia.com/loupan/pg/pg51)
2018-04-12 12:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_undefinedaatan/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg45> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceqg/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E9%AB%98%E5%BA%99%E8%B7%AF%E6%9C%97%E8%AF%97%E7%86%99%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 141
2018-04-12 12:36:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.9752553808195,
 'lng': 118.69895635055644,
 'location': '南京项目地址：南高庙路朗诗熙华府',
 'name': '朗诗熙华府',
 'price': 0,
 'when': '2017-11-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceks/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg53> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceks/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacert/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacese/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacert/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacese/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceya/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:36:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceya/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:36:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htssyjabatw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceug/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceug/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:36:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceve/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg76> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:36:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceve/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacesz/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:36:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacett/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacett/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jshysfabnqz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:36:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltxghyabnqx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:36:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BA%91%E9%94%A6%E8%B7%AF%E5%AE%8F%E5%9B%BE%E4%B8%8A%E6%B0%B4%E4%BA%91%E9%94%A6 HTTP/1.1" 200 144
2018-04-12 12:36:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.021247988570856,
 'lng': 118.74727426898808,
 'location': '南京项目地址：云锦路宏图上水云锦',
 'name': '宏图上水云锦一期',
 'price': ' 55000',
 'when': '2017-01-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg54> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacesz/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:36:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceum/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceum/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacela/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacela/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg55> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg46> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%A1%94%E6%A1%A5%E6%B1%9F%E5%B1%B1%E6%B1%87%E6%82%A6%E5%B1%B1%E5%BA%9C HTTP/1.1" 200 136
2018-04-12 12:36:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jshysfabnqz/>
{'lat': 32.11252831954423,
 'lng': 118.75754400569694,
 'location': '南京项目地址：宝塔桥江山汇悦山府',
 'name': '江山汇悦山府',
 'price': ' 33500',
 'when': '2017-12-24'}
2018-04-12 12:36:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:19 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%A5%E5%87%A4%E8%B7%AF5%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ltxghyabnqx/>
{'lat': 31.78563307820375,
 'lng': 118.86158025941931,
 'location': '南京项目地址：来凤路5号',
 'name': '蓝天星港花园',
 'price': ' 17000',
 'when': '2017-12-23'}
2018-04-12 12:36:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceww/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hnldxsyjabiji/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:36:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceww/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:20 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacesz/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:36:20 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacesz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E5%8D%97%E8%B7%AF%E5%9C%B0%E4%B8%8B%E5%95%86%E4%B8%9A%E8%A1%97 HTTP/1.1" 200 137
2018-04-12 12:36:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hnldxsyjabiji/>
{'lat': 32.074991410650846,
 'lng': 118.78115603429792,
 'location': '南京项目地址：湖南路地下商业街',
 'name': '湖南路地下商业街',
 'price': ' 300',
 'when': '2017-06-03'}
2018-04-12 12:36:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacesz/>: HTTP status code is not handled or not allowed
2018-04-12 12:36:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:36:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg56> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:36:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg57> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:36:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceux/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceux/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfryabmqc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:36:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyshsjabryn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceko/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:36:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:36:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:36:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg29> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacerp/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetp/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg29> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%8B%9C%E5%B2%97%E8%B7%AF%E5%A4%A7%E5%8F%91%E8%9E%8D%E6%82%A6 HTTP/1.1" 200 144
2018-04-12 12:36:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dfryabmqc/>
{'lat': 32.03761727573808,
 'lng': 118.87577728900419,
 'location': '南京项目地址：双拜岗路大发融悦',
 'name': '大发融悦',
 'price': ' 36000',
 'when': '2016-04-26'}
2018-04-12 12:36:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E5%B1%B1%E8%A5%BF%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%ADS1%E7%A7%A6%E6%B7%AE%E4%B8%96%E5%AE%B6 HTTP/1.1" 200 137
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:36:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.648311742573938,
 'lng': 118.91514343402882,
 'location': '南京项目地址：横山西路碧桂园S1秦淮世家',
 'name': '碧桂园S1秦淮世家',
 'price': ' 60000',
 'when': '2018-03-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcysabltv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg58> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rtscablnx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qxyyaakrh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
2018-04-12 12:36:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xlqpcsqabirq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdfchtabilb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacell/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:36:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceko/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg28)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg30> (referer: https://nj.fang.lianjia.com/loupan/pg/pg29)
2018-04-12 12:36:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceuf/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:36:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceso/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg29)
2018-04-12 12:36:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg29)
2018-04-12 12:36:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceso/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg29)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg29)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:36:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E5%9B%AD%E6%9E%97%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_qxyyaakrh/>
{'lat': 32.360387136248946,
 'lng': 118.84133678305696,
 'location': '南京项目地址：雄州街道园林西路188号',
 'name': '清香雅苑',
 'price': 0,
 'when': '2016-12-29'}
2018-04-12 12:36:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dphaakno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:36:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjjlhaaksm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:36:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhfcxcaaksy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:36:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%B1%B1%E5%9B%BD%E5%AE%B6%E6%A3%AE%E6%9E%97%E5%85%AC%E5%9B%AD HTTP/1.1" 200 136
2018-04-12 12:36:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华山国家森林公园',
 'name': '新城源山',
 'price': ' 16000',
 'when': '2017-11-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_dcjmyaatpv/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceue/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceue/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceul/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceul/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg31> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacers/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacers/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%89%E5%B1%B1%E7%9F%B6%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:36:28 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.918461028206096,
 'lng': 118.63790417448658,
 'location': '南京项目地址：三山矶路9号',
 'name': '润泰市场',
 'price': ' 11000',
 'when': '2017-10-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%8B%E5%AD%90%E6%A5%BC%E8%A5%BF108%E5%8F%B7 HTTP/1.1" 200 133
2018-04-12 12:36:28 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12560776782336,
 'lng': 118.90211449894603,
 'location': '南京项目地址：王子楼西108号',
 'name': '仙林汽配城',
 'price': 0,
 'when': '2017-08-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg32> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E9%A3%9E%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:28 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.104949086157944,
 'lng': 118.82824103380696,
 'location': '南京项目地址：华飞路1号',
 'name': '恒大翡翠华庭',
 'price': ' 380',
 'when': '2017-07-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacell/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg47> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qhyzabnwc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njjazxabhgr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E6%BA%A7%E6%B0%B4%E5%8E%BF%E4%B8%9C%E5%B1%8F%E9%95%87 HTTP/1.1" 200 138
2018-04-12 12:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dphaakno/>
{'lat': 31.722363055816007,
 'lng': 119.03588719018546,
 'location': '南京项目地址：南京溧水县东屏镇',
 'name': '东屏湖9号',
 'price': 0,
 'when': '2013-01-24'}
2018-04-12 12:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhjc1haalmu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hysglaapty/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dflyaapvh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E5%A1%98%E5%8D%97%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:36:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.676904082947466,
 'lng': 119.03333730597843,
 'location': '南京项目地址：双塘南路68号',
 'name': '秦淮源筑',
 'price': ' 12000',
 'when': '2017-11-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgysjcbabisk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tyljzyabnpz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjlhjqabkjx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyfhcabjte/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyshsjabnav/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%93%E6%BA%AA%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:36:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zjjlhaaksm/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：卓溪路10号',
 'name': '中交锦兰荟',
 'price': 0,
 'when': '2016-07-07'}
2018-04-12 12:36:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyozcabgyt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:36:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E4%B8%9C%E4%B8%AD%E8%B7%AF333%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.00432202883629,
 'lng': 118.73176864542782,
 'location': '南京项目地址：江东中路333号',
 'name': '南京金奥中心',
 'price': 0,
 'when': '2013-12-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E6%BA%AA%E9%95%87%E5%AE%9D%E5%A1%94%E8%B7%AF350%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhfcxcaaksy/>
{'lat': 31.335414317323576,
 'lng': 118.90942190794753,
 'location': '南京项目地址：淳溪镇宝塔路350号',
 'name': '隆豪翡翠星城',
 'price': 0,
 'when': '2017-07-02'}
2018-04-12 12:36:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_zhjc1haalmu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 45, in parse_html
    item["name"] = response.xpath('//h1/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg29)
2018-04-12 12:36:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceus/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg29)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:33 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:36:33 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:36:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%83%AD%E5%BA%84%E9%95%87%E6%9C%BA%E5%9C%BA%E5%A4%A7%E9%81%93%E5%8D%97%E7%A2%A7%E6%A1%82%E5%9B%AD%E4%B8%96%E7%BA%AA%E5%9F%8E%E9%82%A6 HTTP/1.1" 200 134
2018-04-12 12:36:33 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.346944453868932,
 'lng': 118.89424983420618,
 'location': '南京项目地址：郭庄镇机场大道南碧桂园世纪城邦',
 'name': '碧桂园世纪城邦',
 'price': ' 12000',
 'when': '2017-08-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceus/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacetv/>: HTTP status code is not handled or not allowed
2018-04-12 12:36:33 [scrapy.core.engine] INFO: Closing spider (finished)
2018-04-12 12:36:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 43,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 11,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 32,
 'downloader/request_bytes': 542849,
 'downloader/request_count': 737,
 'downloader/request_method_count/GET': 737,
 'downloader/response_bytes': 15464365,
 'downloader/response_count': 694,
 'downloader/response_status_count/200': 676,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/500': 17,
 'dupefilter/filtered': 914,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 4, 12, 4, 36, 33, 843696),
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/500': 6,
 'item_scraped_count': 309,
 'log_count/DEBUG': 1672,
 'log_count/ERROR': 291,
 'log_count/INFO': 21,
 'memusage/max': 144662528,
 'memusage/startup': 59211776,
 'request_depth_max': 76,
 'response_received_count': 683,
 'retry/count': 54,
 'retry/max_reached': 6,
 'retry/reason_count/500 Internal Server Error': 11,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 11,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 32,
 'scheduler/dequeued': 736,
 'scheduler/dequeued/memory': 736,
 'scheduler/enqueued': 736,
 'scheduler/enqueued/memory': 736,
 'spider_exceptions/IndexError': 291,
 'start_time': datetime.datetime(2018, 4, 12, 4, 28, 2, 46094)}
2018-04-12 12:36:33 [scrapy.core.engine] INFO: Spider closed (finished)
2018-04-12 12:36:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%93%9D%E6%B5%B7%E8%B7%AF%E5%BC%98%E9%98%B3%E6%97%B6%E5%85%89%E9%87%8C HTTP/1.1" 200 144
2018-04-12 12:36:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hysglaapty/>
{'lat': 32.18039301137142,
 'lng': 118.7172462747398,
 'location': '南京项目地址：蓝海路弘阳时光里',
 'name': '弘阳时光里',
 'price': 0,
 'when': '2017-06-24'}
2018-04-12 12:36:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B5%A6%E8%B7%AF%E9%80%9A%E5%AE%87%E6%9E%97%E6%99%AF%E5%B0%8A%E5%9B%AD HTTP/1.1" 200 136
2018-04-12 12:36:33 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.075130364489524,
 'lng': 118.65787254029496,
 'location': '南京项目地址：新浦路通宇林景尊园',
 'name': '通宇林景尊园',
 'price': ' 27300',
 'when': '2017-12-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E9%9C%9E%E7%BB%8F%E4%BA%94%E8%B7%AF%E4%B8%8E%E8%BF%88%E5%8C%96%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 134
2018-04-12 12:36:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dflyaapvh/>
{'lat': 32.1312287642796,
 'lng': 118.84117460118358,
 'location': '南京项目地址：栖霞经五路与迈化路交汇处',
 'name': '东方兰园',
 'price': 0,
 'when': '2016-07-28'}
2018-04-12 12:36:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E5%BE%B7%E8%B7%AF65%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:36:34 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：金德路65号',
 'name': '中骏六号街区',
 'price': ' 14000',
 'when': '2018-03-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xchyzjaakrz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjaamhi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rjyblsaamir/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BB%8F%E6%B5%8E%E5%BC%80%E5%8F%91%E5%8C%BAS122%E4%B8%9C%E5%8C%97%E4%BE%A7%E7%A2%A7%E6%A1%82%E5%9B%AD%E5%87%A4%E5%87%B0%E5%9F%8E HTTP/1.1" 200 144
2018-04-12 12:36:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.032188608864764,
 'lng': 119.09968634138617,
 'location': '南京项目地址：经济开发区S122东北侧碧桂园凤凰城',
 'name': '碧桂园凤凰城',
 'price': ' 12000',
 'when': '2018-04-07'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%B9%E9%9C%9E%E8%B7%AF%E6%96%B0%E5%9F%8E%E8%8A%B1%E6%BC%BE%E7%B4%AB%E9%83%A1 HTTP/1.1" 200 143
2018-04-12 12:36:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xchyzjaakrz/>
{'lat': 32.18964133869749,
 'lng': 118.72037139247337,
 'location': '南京项目地址：丹霞路新城花漾紫郡',
 'name': '新城花漾紫郡',
 'price': 0,
 'when': '2016-10-22'}
2018-04-12 12:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qdfzaagpr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhyggaamil/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E5%B1%B1%E8%A5%BF%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%ADS1%E7%A7%A6%E6%B7%AE%E4%B8%96%E5%AE%B6 HTTP/1.1" 200 137
2018-04-12 12:36:38 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.648311742573938,
 'lng': 118.91514343402882,
 'location': '南京项目地址：横山西路碧桂园S1秦淮世家',
 'name': '碧桂园S1秦淮世家',
 'price': 0,
 'when': '2017-11-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%81%E5%AE%81%E5%A4%A7%E9%81%931998%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:36:38 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滁宁大道1998号',
 'name': '碧桂园欧洲城',
 'price': 0,
 'when': '2017-07-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dcjmyaatpv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:36:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E9%9D%96%E4%B8%9C%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:36:38 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.96985873235598,
 'lng': 118.87182639943344,
 'location': '南京项目地址：文靖东路88号',
 'name': '东城金茂悦',
 'price': 0,
 'when': '2017-07-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg48> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:36:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gkrjaamhi/>
{'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境',
 'price': 0,
 'when': '2012-10-23'}
2018-04-12 12:36:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacels/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacels/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacema/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacema/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg49> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:36:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg50> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg33> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:36:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E4%B8%B9%E9%98%B3%E5%A4%A7%E9%81%93110%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rjyblsaamir/>
{'lat': 31.849796224068285,
 'lng': 118.77857718961954,
 'location': '南京项目地址：江宁丹阳大道110号',
 'name': '瑞景叶泊蓝山',
 'price': 0,
 'when': '2012-10-02'}
2018-04-12 12:36:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yclxjaarwg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacent/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%92%E9%BA%9F%E8%A1%97%E9%81%93%E6%99%BA%E9%80%9A%E8%B7%AF189%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:36:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_qdfzaagpr/>
{'lat': 32.03160625464619,
 'lng': 118.9119191637564,
 'location': '南京项目地址：麒麟街道智通路189号',
 'name': '启迪方洲博园',
 'price': 0,
 'when': '2016-07-16'}
2018-04-12 12:36:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacent/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceof/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceof/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:36:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceob/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceob/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceot/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceot/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:36:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:36:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%B3%89%E4%B8%9C%E8%B7%AF58%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:36:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhyggaamil/>
{'lat': 31.9539171307712,
 'lng': 118.88896630931528,
 'location': '南京项目地址：淳化街道泉东路58号',
 'name': '中航樾公馆',
 'price': 0,
 'when': '2017-07-03'}
2018-04-12 12:36:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E5%88%9B%E6%96%B0%E4%B8%9C%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:36:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yclxjaarwg/>
{'lat': 31.8838176413981,
 'lng': 118.88290815941363,
 'location': '南京项目地址：秣陵街道创新东路2号',
 'name': '银城蓝溪郡',
 'price': 0,
 'when': '2015-10-01'}
2018-04-12 12:36:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceva/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceva/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacena/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zyzjgdaaqce/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacena/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:36:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceru/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceub/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:36:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetx/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:36:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg34> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:36:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg51> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceup/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:36:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceup/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E4%B8%AD%E5%9E%A0%E7%B4%AB%E9%87%91%E8%A7%82%E9%82%B8 HTTP/1.1" 200 144
2018-04-12 12:36:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zyzjgdaaqce/>
{'lat': 32.05232823923972,
 'lng': 118.90154611589733,
 'location': '南京项目地址：马群街道中垠紫金观邸',
 'name': '中垠紫金观邸',
 'price': 0,
 'when': '2017-12-20'}
2018-04-12 12:36:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wymsyaakoe/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg52> (referer: https://nj.fang.lianjia.com/loupan/pg/pg51)
2018-04-12 12:36:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacext/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacext/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg59> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceow/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceow/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg59> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:36:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacesz/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:36:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacese/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacese/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bsxbyaaazh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg53> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacesz/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:36:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htssyjaaavr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jmfaabfl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:36:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceud/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:36:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:48 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacesz/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacesz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacesz/>: HTTP status code is not handled or not allowed
2018-04-12 12:36:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacert/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:36:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacert/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg35> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:36:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceub/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bltyabmqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:36:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%87%E6%99%AF%E5%8C%97%E8%B7%AF%E4%BF%9D%E5%88%A9%E5%A0%82%E6%82%A6 HTTP/1.1" 200 143
2018-04-12 12:36:49 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.987086765521944,
 'lng': 118.81312602132991,
 'location': '南京项目地址：汇景北路保利堂悦',
 'name': '保利堂悦',
 'price': ' 350',
 'when': '2016-04-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjllycabmje/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:36:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfbzxcabmjd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:36:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacett/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacett/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%BC%E8%87%B4%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:36:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bsxbyaaazh/>
{'lat': 31.91310523050222,
 'lng': 118.8974729552743,
 'location': '南京项目地址：格致路9号',
 'name': '伴山香槟园',
 'price': 0,
 'when': '2010-01-16'}
2018-04-12 12:36:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsyyjaaaxe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:36:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaayu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:36:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flsyjaaayv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:36:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceug/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceug/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceve/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceve/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%8A%E6%B2%B3%E6%96%B0%E5%9F%8E%E9%9B%85%E5%B1%85%E4%B9%90%E6%9E%97%E8%AF%AD%E5%9F%8E HTTP/1.1" 200 136
2018-04-12 12:36:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：汊河新城雅居乐林语城',
 'name': '雅居乐林语城',
 'price': 0,
 'when': '2017-12-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ylfablzi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:36:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcjxthyabmmo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:36:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgydxyxabrtv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:36:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BA%91%E9%94%A6%E8%B7%AF%E5%AE%8F%E5%9B%BE%E4%B8%8A%E6%B0%B4%E4%BA%91%E9%94%A6 HTTP/1.1" 200 144
2018-04-12 12:36:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_htssyjaaavr/>
{'lat': 32.021247988570856,
 'lng': 118.74727426898808,
 'location': '南京项目地址：云锦路宏图上水云锦',
 'name': '宏图上水云锦一期',
 'price': 0,
 'when': '2016-06-04'}
2018-04-12 12:36:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:36:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg54> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:36:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg55> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:36:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%95%BF%E6%B1%9F%E8%B7%AF%E8%A5%BF%E4%BE%A7%E6%98%8E%E5%8F%91%E5%8C%97%E7%AB%99%E6%96%B0%E5%9F%8E HTTP/1.1" 200 135
2018-04-12 12:36:54 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04955537268256,
 'lng': 118.8014603106721,
 'location': '南京项目地址：长江路西侧明发北站新城',
 'name': '明发北站新城',
 'price': 0,
 'when': '2017-11-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%80%9A%E6%B5%8E%E9%97%A8%E5%A4%96%E5%A4%A7%E8%A1%977%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jmfaabfl/>
{'lat': 32.03040026511993,
 'lng': 118.80856022996521,
 'location': '南京项目地址：通济门外大街7号',
 'name': '京门府',
 'price': 0,
 'when': '2013-11-11'}
2018-04-12 12:36:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjaapto/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:36:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:36:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:36:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:36:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:36:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B3%B0%E5%B1%B1%E8%A5%BF%E8%B7%AF%E5%BE%A1%E6%BE%9C%E5%BA%9C HTTP/1.1" 200 135
2018-04-12 12:36:56 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.15139493848411,
 'lng': 118.71872790211911,
 'location': '南京项目地址：泰山西路御澜府',
 'name': '御澜府',
 'price': ' 25800',
 'when': '2017-11-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:36:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A1%83%E6%BA%AA%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:36:56 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：桃溪路1号',
 'name': '融创玖溪桃花源',
 'price': ' 395',
 'when': '2018-03-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:36:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%A4%A7%E9%81%938%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:36:56 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华大道8号',
 'name': '碧桂园大学印象',
 'price': ' 16000',
 'when': '2017-11-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:36:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhysabqwl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
2018-04-12 12:36:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg34)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E6%B9%96%E8%A1%97%E9%81%93%E9%80%9A%E6%B2%B3%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:57 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.45045312201094,
 'lng': 118.94784796098479,
 'location': '南京项目地址：金牛湖街道通河路9号',
 'name': '嘉恒有山',
 'price': ' 13500',
 'when': '2017-12-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:36:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A6%84%E5%8F%A3%E8%A1%97%E9%81%93%E4%BF%A1%E8%AF%9A%E5%A4%A7%E9%81%9333%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zsyyjaaaxe/>
{'lat': 31.7850970443259,
 'lng': 118.83236228130838,
 'location': '南京项目地址：禄口街道信诚大道33号',
 'name': '招商依云郡',
 'price': 0,
 'when': '2016-07-29'}
2018-04-12 12:36:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg36> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:36:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E6%B5%A6%E5%85%AD%E5%8D%97%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_aaayu/>
{'lat': 32.251425749873995,
 'lng': 118.75004994857319,
 'location': '南京项目地址：大厂浦六南路8号',
 'name': '君悦花园',
 'price': 0,
 'when': '2014-08-23'}
2018-04-12 12:36:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:36:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceud/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
2018-04-12 12:36:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sjxnfabhsz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:36:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
2018-04-12 12:36:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
2018-04-12 12:36:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceud/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg31)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:36:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:36:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E6%9D%BF%E6%A1%A5%E6%96%B0%E5%9F%8E%E6%96%B0%E6%B9%96%E5%A4%A7%E9%81%93%EF%BC%88%E8%BF%91%E8%8E%B2%E8%8A%B1%E6%B9%96%E5%85%AC%E5%9B%AD%EF%BC%89 HTTP/1.1" 200 143
2018-04-12 12:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_flsyjaaayv/>
{'lat': 31.91023898425397,
 'lng': 118.66805461945387,
 'location': '南京项目地址：雨花板桥新城新湖大道（近莲花湖公园）',
 'name': '富力尚悦居一期',
 'price': 0,
 'when': '2015-10-24'}
2018-04-12 12:36:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ygjbszzykpaadii/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:36:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:36:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:36:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8F%A0%E6%B3%89%E8%A5%BF%E8%B7%AF%E4%B8%89%E9%87%91%E9%91%AB%E5%AE%81%E5%BA%9C HTTP/1.1" 200 142
2018-04-12 12:37:00 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05495625325235,
 'lng': 118.63701904801674,
 'location': '南京项目地址：珠泉西路三金鑫宁府',
 'name': '三金鑫宁府',
 'price': ' 25600',
 'when': '2017-12-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg33)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceru/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg30)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rcznyyabnqr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:37:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B4%E9%98%B3%E6%B1%9F%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.341189718000248,
 'lng': 118.91511603391415,
 'location': '南京项目地址：水阳江路99号',
 'name': '融创中南御园',
 'price': ' 11000',
 'when': '2018-01-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smrlaarsf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:37:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E7%8F%A0%E8%B7%AF%E8%8D%A3%E9%87%8C HTTP/1.1" 200 135
2018-04-12 12:37:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gkrjaapto/>
{'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境',
 'price': 0,
 'when': '2013-11-01'}
2018-04-12 12:37:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.13159618531885,
 'lng': 118.73518389787502,
 'location': '南京项目地址：浦珠路荣里',
 'name': '世茂荣里',
 'price': 0,
 'when': '2018-03-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wymsyaakoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_xscaabhf/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xycabkna/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:37:01 [scrapy.extensions.logstats] INFO: Crawled 332 pages (at 76 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:37:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%9F%E7%81%AB%E8%B7%AF%E6%98%9F%E6%82%A6%E5%9F%8E HTTP/1.1" 200 136
2018-04-12 12:37:02 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.16673496276866,
 'lng': 118.70268689027152,
 'location': '南京项目地址：星火路星悦城',
 'name': '星悦城',
 'price': ' 16000',
 'when': '2018-02-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hqcfctyabooo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:37:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdqsyjabirk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:37:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B7%A5%E5%86%9C%E8%B7%AF%E5%92%8C%E7%96%8F%E6%B8%AF%E5%A4%A7%E9%81%93%E4%BA%A4%E6%B1%87%E5%A4%84%E5%8D%8E%E4%BE%A8%E5%9F%8E%E7%BF%A1%E7%BF%A0%E5%A4%A9%E5%9F%9F HTTP/1.1" 200 135
2018-04-12 12:37:02 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.14946210342667,
 'lng': 118.9979559714333,
 'location': '南京项目地址：工农路和疏港大道交汇处华侨城翡翠天域',
 'name': '华侨城翡翠天域',
 'price': ' 25500',
 'when': '2018-03-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E9%87%8C%E6%A1%A5%E5%8C%97%E8%B7%AF%E9%87%91%E5%9C%B0%E6%B5%85%E5%B1%B1%E8%89%BA%E5%A2%83 HTTP/1.1" 200 143
2018-04-12 12:37:02 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.094157269152994,
 'lng': 118.65780350461823,
 'location': '南京项目地址：七里桥北路金地浅山艺境',
 'name': '金地浅山艺境',
 'price': ' 40000',
 'when': '2016-06-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djsmyhaakuc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:37:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:02 [scrapy.extensions.logstats] INFO: Crawled 493 pages (at 110 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:37:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E5%B9%B3%E5%92%8C%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:37:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wymsyaakoe/>
{'lat': 31.943934853497655,
 'lng': 118.94156811107989,
 'location': '南京项目地址：淳化街道平和路8号',
 'name': '武夷名仕园',
 'price': 0,
 'when': '2015-10-21'}
2018-04-12 12:37:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg60> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjycydaabsv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:03 [scrapy.extensions.logstats] INFO: Crawled 545 pages (at 68 pages/min), scraped 266 items (at 22 items/min)
2018-04-12 12:37:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:37:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BA%90%E5%B1%B1%E8%B7%AF208%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99841267184827,
 'lng': 118.730251217879,
 'location': '南京项目地址：庐山路208号',
 'name': '德基世贸壹号',
 'price': ' 37000',
 'when': '2014-10-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jljqhfaakts/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:37:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacexa/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:37:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E4%BF%AE%E6%96%87%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:05 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.90070775306782,
 'lng': 118.91608440725392,
 'location': '南京项目地址：江宁区淳化街道修文路3号',
 'name': '金轮津桥华府',
 'price': 0,
 'when': '2016-07-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg37> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:37:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_slhjzxabiuf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:37:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:05 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%89%AA%E5%AD%90%E5%B7%B735%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yjycydaabsv/>
{'lat': 32.019721200388425,
 'lng': 118.79260288216061,
 'location': '南京项目地址：剪子巷35号',
 'name': '雅居乐长乐渡',
 'price': ' 2500',
 'when': '2017-12-20'}
2018-04-12 12:37:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xscaabhf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E5%A4%A7%E8%A1%97%E5%8D%87%E9%BE%99%E6%B1%87%E9%87%91%E4%B8%AD%E5%BF%83 HTTP/1.1" 200 134
2018-04-12 12:37:07 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.98712298032158,
 'lng': 118.71726900636072,
 'location': '南京项目地址：江山大街升龙汇金中心',
 'name': '升龙汇金中心',
 'price': ' 29000',
 'when': '2015-03-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jsczgcaakng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:37:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%85%89%E4%B8%9C%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xscaabhf/>
{'lat': 31.686029241429527,
 'lng': 119.0426089417233,
 'location': '南京项目地址：红光东路8号',
 'name': '橡树城',
 'price': 0,
 'when': '2018-01-23'}
2018-04-12 12:37:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg61> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzscyfaacfh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jnhdjzxabgvh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrraaeor/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcmgyaafsc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhxycabgop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yckqabgrk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacesy/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:37:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E5%AE%81%E8%B7%AF31%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09653621784545,
 'lng': 118.78217765020526,
 'location': '南京项目地址：建宁路31号',
 'name': '金盛财智广场',
 'price': 0,
 'when': '2012-09-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dfmyaaknx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:37:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smcpabovv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:37:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceum/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:37:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ytsyhaaksk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:37:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxhfaarwx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:37:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_atssydaaktt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:37:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_undefinedaaqhr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:37:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceum/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:37:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceum/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E6%B7%B3%E6%B7%B3%E6%BA%AA%E9%95%87%E6%85%A2%E5%9F%8E%E5%A4%A7%E9%81%9368%E5%8F%B7%EF%BC%88%E9%AB%98%E6%B7%B3%E6%96%B0%E4%BD%93%E8%82%B2%E4%B8%AD%E5%BF%83%E5%8C%97%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 136
2018-04-12 12:37:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.33915369585837,
 'lng': 118.89224328829025,
 'location': '南京项目地址：高淳淳溪镇慢城大道68号（高淳新体育中心北侧）',
 'name': '东方曼园',
 'price': 0,
 'when': '2016-01-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:37:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E8%8B%8F%E5%AE%81%E9%92%9F%E5%B1%B1%E6%9C%9D%E9%98%B3%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_snzscyfaacfh/>
{'lat': 32.0913139891331,
 'lng': 118.89802397497581,
 'location': '南京项目地址：玄武大道苏宁钟山朝阳府',
 'name': '苏宁钟山朝阳府',
 'price': 0,
 'when': '2014-03-30'}
2018-04-12 12:37:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8F%8C%E8%B7%AF%E4%B8%96%E8%8C%82%E5%9F%8E%E5%93%81 HTTP/1.1" 200 145
2018-04-12 12:37:14 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97666251592093,
 'lng': 118.76671169042649,
 'location': '南京项目地址：宁双路世茂城品',
 'name': '世茂城品',
 'price': ' 37000',
 'when': '2018-02-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E5%9B%BA%E8%B7%AF3%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:14 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：永固路3号',
 'name': '亚泰山语湖',
 'price': 0,
 'when': '2017-09-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E6%B9%96%E8%A1%97%E9%81%93%E9%87%91%E7%89%9B%E6%B9%96%E7%A4%BE%E5%8C%BA88%E5%8F%B7 HTTP/1.1" 200 142
2018-04-12 12:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jnhdjzxabgvh/>
{'lat': 32.47562584733648,
 'lng': 118.97543132009281,
 'location': '南京项目地址：金牛湖街道金牛湖社区88号',
 'name': '金牛湖度假中心',
 'price': 0,
 'when': '2013-12-17'}
2018-04-12 12:37:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B2%B3%E8%A5%BF%E5%8D%97%E9%83%A8%E5%AD%A6%E5%AD%90%E8%B7%AF HTTP/1.1" 200 136
2018-04-12 12:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zrraaeor/>
{'lat': 32.087391829280385,
 'lng': 118.82174943981876,
 'location': '南京项目地址：河西南部学子路',
 'name': '正荣润峯',
 'price': 0,
 'when': '2017-04-21'}
2018-04-12 12:37:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BD%8D%E5%A4%84%E5%8D%97%E4%BA%AC%E5%94%AF%E4%B8%80%E7%9C%81%E7%BA%A7%E6%97%85%E6%B8%B8%E5%BA%A6%E5%81%87%E5%8C%BA%E2%80%94%E2%80%94%E7%8F%8D%E7%8F%A0%E6%B3%89%E6%97%85%E6%B8%B8%E5%BA%A6%E5%81%87%E5%8C%BA%E5%AF%86%E6%9E%97%E6%B7%B1%E5%A4%84 HTTP/1.1" 200 142
2018-04-12 12:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lcmgyaafsc/>
{'lat': 32.1311378986881,
 'lng': 118.66847660834854,
 'location': '南京项目地址：位处南京唯一省级旅游度假区——珍珠泉旅游度假区密林深处',
 'name': '绿城玫瑰园',
 'price': ' 12800',
 'when': '2014-09-27'}
2018-04-12 12:37:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%9C%A0%E5%A4%A7%E9%81%93660%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhxycabgop/>
{'lat': 31.915202403612295,
 'lng': 118.90964727896606,
 'location': '南京项目地址：龙眠大道660号',
 'name': '龙湖新壹城',
 'price': 0,
 'when': '2017-06-25'}
2018-04-12 12:37:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg56> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:37:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%9F%E8%B7%AF%EF%BC%88%E5%8D%97%E4%BA%AC%E8%A5%BF%E7%AB%99%E8%A5%BF%E4%BE%A7%EF%BC%89 HTTP/1.1" 200 140
2018-04-12 12:37:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.10087185564733,
 'lng': 118.74873294286502,
 'location': '南京项目地址：龙江路（南京西站西侧）',
 'name': '锦绣华府',
 'price': 0,
 'when': '2016-05-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg56> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:37:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg57> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:37:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg58> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E9%A9%AC%E8%B7%AF%E9%93%B6%E5%9F%8EKinmaQ+%E7%A4%BE%E5%8C%BA HTTP/1.1" 200 136
2018-04-12 12:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yckqabgrk/>
{'lat': 32.07294880801665,
 'lng': 118.9122779050283,
 'location': '南京项目地址：金马路银城KinmaQ+社区',
 'name': '银城KinmaQ+社区',
 'price': ' 29000',
 'when': '2017-10-01'}
2018-04-12 12:37:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhfcxcaaksy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg62> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E6%BA%AA%E9%95%87%E5%AE%9D%E5%A1%94%E8%B7%AF350%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:18 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.335414317323576,
 'lng': 118.90942190794753,
 'location': '南京项目地址：淳溪镇宝塔路350号',
 'name': '隆豪翡翠星城',
 'price': 0,
 'when': '2017-07-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gjoydsygcabcyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ygjbszzykpaadii/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tchabdhu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E9%9D%96%E8%B7%AF599%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:18 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.966100163341842,
 'lng': 118.85850571579324,
 'location': '南京项目地址：文靖路599号',
 'name': '爱涛尚书云邸',
 'price': 0,
 'when': '2016-03-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:18 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E5%B8%82%E6%BA%A7%E6%B0%B4%E5%8C%BA%E7%A7%A6%E6%B7%AE%E8%B7%AF159-21%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_gjoydsygcabcyp/>
{'lat': 31.657385165530922,
 'lng': 119.05231070860395,
 'location': '南京项目地址：南京市溧水区秦淮路159-21号',
 'name': '顾家欧亚达商业广场',
 'price': 0,
 'when': '2015-11-12'}
2018-04-12 12:37:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxjshyabdzu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg59> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dflyaapvh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hysglaapty/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%A6%E5%8C%96%E8%B7%AF611%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：麦化路611号',
 'name': '电建洺悦府',
 'price': ' 22000',
 'when': '2017-12-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hbypyaakof/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg36)
2018-04-12 12:37:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jxlshslaasuo/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:37:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_yzjqlaaqji/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_wkpysaafgz/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%9388%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ygjbszzykpaadii/>
{'lat': 32.09998525321101,
 'lng': 118.87119915132855,
 'location': '南京项目地址：玄武大道88号',
 'name': '阳光聚宝山庄臻园',
 'price': 0,
 'when': '2016-09-13'}
2018-04-12 12:37:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacexa/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_gsyaapuz/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jdqsyjaapwt/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hsjlwaaqfu/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8D%97%E8%B7%AF117%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:21 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.324725434771544,
 'lng': 118.90167334739824,
 'location': '南京项目地址：淳南路117号',
 'name': '湖滨一品苑',
 'price': 0,
 'when': '2011-04-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jdqsyjaapwt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:37:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sfjyaaftm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:37:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flcaapqv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:37:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_klhfaadjw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:37:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E9%9C%9E%E7%BB%8F%E4%BA%94%E8%B7%AF%E4%B8%8E%E8%BF%88%E5%8C%96%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 134
2018-04-12 12:37:22 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1312287642796,
 'lng': 118.84117460118358,
 'location': '南京项目地址：栖霞经五路与迈化路交汇处',
 'name': '东方兰园',
 'price': 0,
 'when': '2016-07-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjaapto/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E5%B8%82%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B1%A4%E5%B1%B1%E5%9B%BD%E9%99%85%E6%B8%A9%E6%B3%89%E5%9F%8E%E5%9C%A3%E6%B1%A4%E5%A4%A7%E9%81%939%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tchabdhu/>
{'lat': 32.04829213296588,
 'lng': 119.06564056974446,
 'location': '南京项目地址：南京市江宁区汤山国际温泉城圣汤大道9号',
 'name': '汤城汇',
 'price': 0,
 'when': '2015-02-12'}
2018-04-12 12:37:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsyfaawlq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfcfzxabdwh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lggyaawox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%83%E9%87%8C%E6%A1%A5%E5%8C%97%E8%B7%AF%E9%87%91%E5%9C%B0%E6%B5%85%E5%B1%B1%E8%89%BA%E5%A2%83 HTTP/1.1" 200 143
2018-04-12 12:37:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.094157269152994,
 'lng': 118.65780350461823,
 'location': '南京项目地址：七里桥北路金地浅山艺境',
 'name': '金地浅山艺境',
 'price': 0,
 'when': '2016-08-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hsjlwaaqfu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:37:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cpcaagvp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:37:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E7%89%8C%E7%9F%B3%E5%A4%A7%E8%A1%97288%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.391466237256026,
 'lng': 119.00002643556175,
 'location': '南京项目地址：双牌石大街288号',
 'name': '双富嘉园',
 'price': 0,
 'when': '2017-01-07'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E9%BA%92%E8%B7%AF277%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.01565712729463,
 'lng': 118.88669095266192,
 'location': '南京项目地址：东麒路277号',
 'name': '富力城',
 'price': 0,
 'when': '2012-11-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%93%9D%E6%B5%B7%E8%B7%AF%E5%BC%98%E9%98%B3%E6%97%B6%E5%85%89%E9%87%8C HTTP/1.1" 200 144
2018-04-12 12:37:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.18039301137142,
 'lng': 118.7172462747398,
 'location': '南京项目地址：蓝海路弘阳时光里',
 'name': '弘阳时光里',
 'price': 0,
 'when': '2017-06-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境',
 'price': 0,
 'when': '2013-11-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qxyyaakrh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yclxjaarwg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcxhbyjlaatbh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E5%9B%AD%E6%9E%97%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.360387136248946,
 'lng': 118.84133678305696,
 'location': '南京项目地址：雄州街道园林西路188号',
 'name': '清香雅苑',
 'price': 0,
 'when': '2016-12-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjjlhaaksm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wymsyaakoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dphaakno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%A1%94%E6%A1%A5%E8%A5%BF%E8%A1%97155%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jxjshyabdzu/>
{'lat': 32.111578944142316,
 'lng': 118.75557194483122,
 'location': '南京项目地址：宝塔桥西街155号',
 'name': '锦绣江山花园',
 'price': 0,
 'when': '2016-11-25'}
2018-04-12 12:37:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%87%B4%E8%BF%9C%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.64677206867821,
 'lng': 119.04738826030771,
 'location': '南京项目地址：致远路68号',
 'name': '康利华府',
 'price': 0,
 'when': '2018-01-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BC%93%E6%A5%BC%E5%8C%BA%E7%83%AD%E6%B2%B3%E5%8D%97%E8%B7%AF%E8%A1%97%E9%81%93 HTTP/1.1" 200 136
2018-04-12 12:37:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08119544876564,
 'lng': 118.74690286637158,
 'location': '南京项目地址：鼓楼区热河南路街道',
 'name': '恒盛金陵湾',
 'price': ' 37500',
 'when': '2017-12-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E5%88%9B%E6%96%B0%E4%B8%9C%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:37:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.8838176413981,
 'lng': 118.88290815941363,
 'location': '南京项目地址：秣陵街道创新东路2号',
 'name': '银城蓝溪郡',
 'price': 0,
 'when': '2015-10-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%90%E5%B1%B1%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0303034041956,
 'lng': 118.7330601392595,
 'location': '南京项目地址：乐山路99号',
 'name': '北辰旭辉铂悦金陵',
 'price': 0,
 'when': '2017-03-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjaamhi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E4%B8%9C%E8%B7%AF301%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zsyfaawlq/>
{'lat': 32.04676420264064,
 'lng': 118.81321034167492,
 'location': '南京项目地址：中山东路301号',
 'name': '钟山颐府',
 'price': 0,
 'when': '2016-06-01'}
2018-04-12 12:37:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E7%A6%84%E5%A4%A7%E9%81%931%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.79647196501264,
 'lng': 118.86518619158387,
 'location': '南京项目地址：天禄大道1号',
 'name': '翠屏城',
 'price': ' 11900',
 'when': '2017-11-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg38> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:37:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%93%E6%BA%AA%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：卓溪路10号',
 'name': '中交锦兰荟',
 'price': 0,
 'when': '2016-07-07'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E5%B9%B3%E5%92%8C%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:37:32 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.943934853497655,
 'lng': 118.94156811107989,
 'location': '南京项目地址：淳化街道平和路8号',
 'name': '武夷名仕园',
 'price': 0,
 'when': '2015-10-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzjqlaaqji/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:37:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%A4%A7%E9%81%936%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_mfcfzxabdwh/>
{'lat': 32.063466256710505,
 'lng': 118.67466304975159,
 'location': '南京项目地址：浦口大道6号',
 'name': '明发财富中心',
 'price': ' 17000',
 'when': '2017-10-01'}
2018-04-12 12:37:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E6%96%B0%E8%B7%AF%E8%93%9D%E5%85%89%E5%85%AC%E5%9B%AD1%E5%8F%B7 HTTP/1.1" 200 146
2018-04-12 12:37:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lggyaawox/>
{'lat': 31.92591631683342,
 'lng': 118.67321099728457,
 'location': '南京项目地址：华新路蓝光公园1号',
 'name': '蓝光公园1号',
 'price': 0,
 'when': '2017-06-17'}
2018-04-12 12:37:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_tyljxssyabfqd/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_jagwlsabebt/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hdjbtxaawxd/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_cpsjgcabbis/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg63> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:37:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdjbtxaawxd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jagwlsabebt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E6%BA%A7%E6%B0%B4%E5%8E%BF%E4%B8%9C%E5%B1%8F%E9%95%87 HTTP/1.1" 200 138
2018-04-12 12:37:34 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.722363055816007,
 'lng': 119.03588719018546,
 'location': '南京项目地址：南京溧水县东屏镇',
 'name': '东屏湖9号',
 'price': 0,
 'when': '2013-01-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:35 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E6%B9%96%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hdjbtxaawxd/>
{'lat': 31.700575027936633,
 'lng': 119.07375409205974,
 'location': '南京项目地址：永湖路188号',
 'name': '恒大金碧天下',
 'price': 0,
 'when': '2018-03-29'}
2018-04-12 12:37:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境',
 'price': 0,
 'when': '2012-10-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhyggaamil/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%B3%89%E4%B8%9C%E8%B7%AF58%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.9539171307712,
 'lng': 118.88896630931528,
 'location': '南京项目地址：淳化街道泉东路58号',
 'name': '中航樾公馆',
 'price': 0,
 'when': '2017-07-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg60> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhjc1haalmu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_zhjc1haalmu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 45, in parse_html
    item["name"] = response.xpath('//h1/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xchyzjaakrz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%B5%9B%E8%99%B9%E6%A1%A5%E8%A1%97%E9%81%93%E7%A6%B9%E6%B4%B2%E5%90%89%E5%BA%86%E9%87%8C HTTP/1.1" 200 142
2018-04-12 12:37:37 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.01411065563163,
 'lng': 118.76650360603985,
 'location': '南京项目地址：赛虹桥街道禹洲吉庆里',
 'name': '禹洲吉庆里',
 'price': 0,
 'when': '2016-05-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxlshslaasuo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg35)
2018-04-12 12:37:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkpysaafgz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:37:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gsyaapuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg37)
2018-04-12 12:37:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg39> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:37:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
2018-04-12 12:37:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ytwtsjaaeoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:37:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%B1%B1%E8%B7%AF6%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:37 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.132337610018176,
 'lng': 118.739274526947,
 'location': '南京项目地址：江山路6号',
 'name': '金象朗诗红树林',
 'price': 0,
 'when': '2017-10-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%99%BA%E6%B1%87%E8%B7%AF92%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_jagwlsabebt/>
{'lat': 32.033566135579086,
 'lng': 118.91402647916111,
 'location': '南京项目地址：智汇路92号',
 'name': '京奥港未来墅',
 'price': ' 26000',
 'when': '2017-09-15'}
2018-04-12 12:37:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tyljxssyabfqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%B9%E9%9C%9E%E8%B7%AF%E6%96%B0%E5%9F%8E%E8%8A%B1%E6%BC%BE%E7%B4%AB%E9%83%A1 HTTP/1.1" 200 143
2018-04-12 12:37:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.18964133869749,
 'lng': 118.72037139247337,
 'location': '南京项目地址：丹霞路新城花漾紫郡',
 'name': '新城花漾紫郡',
 'price': 0,
 'when': '2016-10-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flsyjaaayv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rjyblsaamir/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:37:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacexy/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:37:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E6%B2%BF%E5%B1%B1%E5%A4%A7%E9%81%93231%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.11764716703607,
 'lng': 118.67514525451335,
 'location': '南京项目地址：江浦街道沿山大道231号',
 'name': '万科璞悦山',
 'price': 0,
 'when': '2017-04-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E7%99%BD%E9%A9%AC%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_tyljxssyabfqd/>
{'lat': 32.08732150414787,
 'lng': 118.63490312801513,
 'location': '南京项目地址：江浦街道白马路89号',
 'name': '通宇林景象山墅院',
 'price': ' 38000',
 'when': '2016-03-26'}
2018-04-12 12:37:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cpsjgcabbis/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:37:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B8%AF%E5%A4%A7%E9%81%9388%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_cpsjgcabbis/>
{'lat': 32.169791062821595,
 'lng': 118.87681335325735,
 'location': '南京项目地址：新港大道88号',
 'name': '翠屏水晶广场',
 'price': ' 45',
 'when': '2016-01-30'}
2018-04-12 12:37:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A1%B6%E5%B1%B1%E8%A1%97%E9%81%93%E5%AE%9A%E5%90%91%E6%B2%B3%E8%A5%BF%E4%BE%A7 HTTP/1.1" 200 139
2018-04-12 12:37:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12858574755484,
 'lng': 118.69544350619863,
 'location': '南京项目地址：顶山街道定向河西侧',
 'name': '观山悦',
 'price': ' 25500',
 'when': '2017-12-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg32)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:37:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B6%A6%E5%AF%8C%E8%B7%AF666%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:42 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.269405076580064,
 'lng': 118.74330082207327,
 'location': '南京项目地址：润富路666号',
 'name': '亚泰梧桐世家',
 'price': 0,
 'when': '2017-08-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaazn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:37:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjszaabur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:37:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aabcc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:37:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg63> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:37:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg64> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:37:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djyfaaynn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:37:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E8%8E%89%E6%B9%96%E8%A5%BF%E8%B7%AF31%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:37:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_djyfaaynn/>
{'lat': 32.33177772895079,
 'lng': 118.81890481887899,
 'location': '南京项目地址：龙池街道莉湖西路31号',
 'name': '东骏悦府',
 'price': ' 11000',
 'when': '2016-11-03'}
2018-04-12 12:37:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ljlaaynh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:37:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E6%9D%BF%E6%A1%A5%E6%96%B0%E5%9F%8E%E6%96%B0%E6%B9%96%E5%A4%A7%E9%81%93%EF%BC%88%E8%BF%91%E8%8E%B2%E8%8A%B1%E6%B9%96%E5%85%AC%E5%9B%AD%EF%BC%89 HTTP/1.1" 200 143
2018-04-12 12:37:43 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.91023898425397,
 'lng': 118.66805461945387,
 'location': '南京项目地址：雨花板桥新城新湖大道（近莲花湖公园）',
 'name': '富力尚悦居一期',
 'price': 0,
 'when': '2015-10-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsyyjaaaxe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E4%B8%9C%E5%8C%97%E8%B7%AF%E9%BE%99%E6%B1%9F%E9%87%8C HTTP/1.1" 200 137
2018-04-12 12:37:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ljlaaynh/>
{'lat': 32.05770706730537,
 'lng': 118.74598750383659,
 'location': '南京项目地址：江东北路龙江里',
 'name': '龙江里',
 'price': ' 34000',
 'when': '2016-12-30'}
2018-04-12 12:37:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg65> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzjjyaayda/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:37:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdmygcabmqh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E9%BA%92%E4%B8%9C%E8%B7%AF588%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05831085966082,
 'lng': 118.94504433960678,
 'location': '南京项目地址：东麒东路588号',
 'name': '麒麟山庄公园境',
 'price': 0,
 'when': '时间待定'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E4%B8%B9%E9%98%B3%E5%A4%A7%E9%81%93110%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:45 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.849796224068285,
 'lng': 118.77857718961954,
 'location': '南京项目地址：江宁丹阳大道110号',
 'name': '瑞景叶泊蓝山',
 'price': 0,
 'when': '2012-10-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldgyaadmw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_clgszaadsb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ydtcyjaadpy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BE%90%E5%BA%84%E8%BD%AF%E4%BB%B6%E5%9B%AD HTTP/1.1" 200 143
2018-04-12 12:37:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_snzjjyaayda/>
{'lat': 32.097126504668104,
 'lng': 118.89223524935424,
 'location': '南京项目地址：徐庄软件园',
 'name': '苏宁紫金嘉悦',
 'price': ' 20000',
 'when': '2016-09-24'}
2018-04-12 12:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dhjxhcyabmqu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdmygcabmqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhtylabxle/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldhqchpbjabmmc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E9%97%A8%E5%A4%A7%E8%A1%97297%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdmygcabmqh/>
{'lat': 32.043648320833704,
 'lng': 118.86848048488551,
 'location': '南京项目地址：中山门大街297号',
 'name': '钟鼎名悦广场',
 'price': 0,
 'when': '2017-09-16'}
2018-04-12 12:37:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:37:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dhjxhcyabmqu/>
{'lat': 32.123523391191696,
 'lng': 118.72947850536069,
 'location': '南京项目地址：浦口区浦珠北路59号',
 'name': '大华锦绣华城商业',
 'price': ' 45000',
 'when': '2017-07-18'}
2018-04-12 12:37:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:46 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E4%B8%81%E5%AE%B6%E5%B1%B1%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:46 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.24351789402061,
 'lng': 118.78205578787639,
 'location': '南京项目地址：大厂丁家山路2号',
 'name': '碧景山庄',
 'price': 0,
 'when': '2015-02-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A6%84%E5%8F%A3%E8%A1%97%E9%81%93%E4%BF%A1%E8%AF%9A%E5%A4%A7%E9%81%9333%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:37:47 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.7850970443259,
 'lng': 118.83236228130838,
 'location': '南京项目地址：禄口街道信诚大道33号',
 'name': '招商依云郡',
 'price': 0,
 'when': '2016-07-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E9%97%A8%E5%A4%A7%E8%A1%97297%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zdmygcabmqi/>
{'lat': 32.043648320833704,
 'lng': 118.86848048488551,
 'location': '南京项目地址：中山门大街297号',
 'name': '钟鼎名悦广场',
 'price': ' 50000',
 'when': '2018-03-19'}
2018-04-12 12:37:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E9%BE%99%E6%A3%A0%E8%B7%AF233%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:37:48 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.31046576638648,
 'lng': 118.87725817797637,
 'location': '南京项目地址：雄州街道龙棠路233号',
 'name': '御珑湾',
 'price': 0,
 'when': '2014-06-08'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cpcyaadyw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:37:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djhfaabvz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:37:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smwtxcaacap/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:37:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcaaeok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg38)
2018-04-12 12:37:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BA%A7%E6%B0%B4%E9%87%91%E7%89%9B%E5%8C%97%E8%B7%AF666%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:49 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.625957518863856,
 'lng': 119.00961238373077,
 'location': '南京项目地址：溧水金牛北路666号',
 'name': '溧都桂苑',
 'price': 0,
 'when': '2011-11-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%8C%E5%A4%8F%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:49 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.74074774208822,
 'lng': 119.01363948733201,
 'location': '南京项目地址：乌夏路88号',
 'name': '藏珑谷山庄',
 'price': ' 12800',
 'when': '2016-06-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E5%8F%8C%E9%BE%99%E5%A4%A7%E9%81%933000%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:50 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.92002953414327,
 'lng': 118.83467340342527,
 'location': '南京项目地址：秣陵街道双龙大道3000号',
 'name': '翠屏诚园',
 'price': 0,
 'when': '2017-06-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg40> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:37:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znjyabcmd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:37:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlxlfaayvm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:37:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyshsjabcfs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:37:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A6%E6%B7%AE%E5%A4%A7%E9%81%93168%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:37:51 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.660021743699502,
 'lng': 119.05091071375787,
 'location': '南京项目地址：秦淮大道168号',
 'name': '亚东同城逸境',
 'price': 0,
 'when': '2016-03-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaayu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htssyjaaavr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcjlhaaeaz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jstjsaadxq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%83%AD%E6%B2%B3%E5%8D%97%E8%B7%AF%E6%9E%9C%E5%93%81%E5%B8%82%E5%9C%BA%E5%9C%B0%E5%9D%97%E4%B8%AD%E6%B5%B7%E6%A1%83%E5%9B%AD%E9%87%8C HTTP/1.1" 200 136
2018-04-12 12:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_zhtylabxle/>
{'lat': 32.083859111765705,
 'lng': 118.7477835049071,
 'location': '南京项目地址：热河南路果品市场地块中海桃园里',
 'name': '中海桃源里',
 'price': 0,
 'when': '2018-03-31'}
2018-04-12 12:37:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E6%B5%A6%E5%85%AD%E5%8D%97%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.251425749873995,
 'lng': 118.75004994857319,
 'location': '南京项目地址：大厂浦六南路8号',
 'name': '君悦花园',
 'price': 0,
 'when': '2014-08-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E6%A2%81%E8%A1%97%E9%81%93%E7%91%9E%E6%88%90%E8%B7%AF9%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.331850449520935,
 'lng': 118.94026095169839,
 'location': '南京项目地址：横梁街道瑞成路9号',
 'name': '东骏华府',
 'price': 0,
 'when': '2013-12-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E9%80%9A%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08452501199852,
 'lng': 118.74076903872225,
 'location': '南京项目地址：南通路89号',
 'name': '世茂外滩新城',
 'price': ' 35900',
 'when': '时间待定'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%8C%BA%E6%80%A1%E5%BA%B7%E8%A1%97%E4%B8%8E%E8%A5%BF%E5%9F%8E%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 137
2018-04-12 12:37:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.998575159409864,
 'lng': 118.75515428127758,
 'location': '南京项目地址：建邺区怡康街与西城路交汇处',
 'name': '涟城二期',
 'price': 0,
 'when': '2015-03-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rdxfcaaekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:37:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hysyabchh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:37:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gcbgyaaejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:37:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jlhbskpaaekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg39)
2018-04-12 12:37:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BD%AF%E4%BB%B6%E5%A4%A7%E9%81%93%E4%B8%AD%E5%8D%97%E9%94%A6%E8%8B%91 HTTP/1.1" 200 144
2018-04-12 12:37:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.984256699458975,
 'lng': 118.75651496529456,
 'location': '南京项目地址：软件大道中南锦苑',
 'name': '中南锦苑',
 'price': 0,
 'when': '2017-03-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%81%E5%8D%97%E8%A1%97%E9%81%93%E9%87%91%E8%BD%AE%E6%98%9F%E7%AB%8B%E6%96%B9 HTTP/1.1" 200 136
2018-04-12 12:37:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.99799477275822,
 'lng': 118.78177238865749,
 'location': '南京项目地址：宁南街道金轮星立方',
 'name': '金轮星立方',
 'price': ' 21000',
 'when': '2015-12-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BA%91%E9%94%A6%E8%B7%AF%E5%AE%8F%E5%9B%BE%E4%B8%8A%E6%B0%B4%E4%BA%91%E9%94%A6 HTTP/1.1" 200 144
2018-04-12 12:37:54 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.021247988570856,
 'lng': 118.74727426898808,
 'location': '南京项目地址：云锦路宏图上水云锦',
 'name': '宏图上水云锦一期',
 'price': 0,
 'when': '2016-06-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%95%BF%E4%BA%AD%E8%A1%9755%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:54 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.914770739009395,
 'lng': 118.83304208150336,
 'location': '南京项目地址：秣陵街道长亭街55号',
 'name': '新城玖珑湖二期',
 'price': 0,
 'when': '2015-10-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:54 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%8E%8B%E5%A4%A7%E8%A1%97%E7%BB%BF%E5%9C%B0%E5%8D%8E%E4%BE%A8%E5%9F%8E%E6%B5%B7%E7%8F%80%E6%BB%A8%E6%B1%9F HTTP/1.1" 200 137
2018-04-12 12:37:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ldhqchpbjabmmc/>
{'lat': 31.981396621207637,
 'lng': 118.69564997992349,
 'location': '南京项目地址：龙王大街绿地华侨城海珀滨江',
 'name': '绿地华侨城海珀滨江',
 'price': 0,
 'when': '2017-11-20'}
2018-04-12 12:37:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyylqjabjif/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:37:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhxycabktp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hlgjablxd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B2%BF%E6%B1%9F%E8%A1%97%E9%81%93%E9%AB%98%E6%96%B0%E6%8A%80%E6%9C%AF%E4%BA%A7%E4%B8%9A%E5%BC%80%E5%8F%91%E5%8C%BA HTTP/1.1" 200 137
2018-04-12 12:37:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hyylqjabjif/>
{'lat': 32.16709029296466,
 'lng': 118.74179198502003,
 'location': '南京项目地址：沿江街道高新技术产业开发区',
 'name': '弘阳燕澜七缙',
 'price': ' 42000',
 'when': '2017-08-17'}
2018-04-12 12:37:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rssfablye/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sclfablcb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%9C%A0%E5%A4%A7%E9%81%93660%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhxycabktp/>
{'lat': 31.915202403612295,
 'lng': 118.90964727896606,
 'location': '南京项目地址：龙眠大道660号',
 'name': '龙湖新壹城',
 'price': 0,
 'when': '2017-10-25'}
2018-04-12 12:37:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E5%B1%B1%E8%A5%BF%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%ADS1%E7%A7%A6%E6%B7%AE%E4%B8%96%E5%AE%B6 HTTP/1.1" 200 137
2018-04-12 12:37:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.648311742573938,
 'lng': 118.91514343402882,
 'location': '南京项目地址：横山西路碧桂园S1秦淮世家',
 'name': '碧桂园S1秦淮世家',
 'price': 0,
 'when': '2017-11-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E9%94%A6%E4%B8%8A%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:37:56 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：江浦街道锦上路1号',
 'name': '金盛田锦上',
 'price': 0,
 'when': '2014-08-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lbzcaavye/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrraaeor/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcmgyaafsc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldbfgcaavjz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ygjbszzykpaadii/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:37:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smjwsabcny/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:37:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:57 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%A7%E8%A1%9781%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:37:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hlgjablxd/>
{'lat': 32.0574390450143,
 'lng': 118.78971204573793,
 'location': '南京项目地址：中大街81号',
 'name': '海伦国际',
 'price': 0,
 'when': '2017-10-31'}
2018-04-12 12:37:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xlqpcsqabirr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:37:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgywtyxabilr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:37:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldlxcabjex/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:37:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dyqsablea/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:37:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yyssabjdy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:37:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B9%E5%B7%9E%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:37:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.365988858238566,
 'lng': 118.85472132611994,
 'location': '南京项目地址：方州路68号',
 'name': '荣鼎幸福城',
 'price': 0,
 'when': '2018-01-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%B0%E5%8D%97%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：台南路10号',
 'name': '力标赞城',
 'price': 0,
 'when': '2018-01-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B2%B3%E8%A5%BF%E5%8D%97%E9%83%A8%E5%AD%A6%E5%AD%90%E8%B7%AF HTTP/1.1" 200 136
2018-04-12 12:37:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.087391829280385,
 'lng': 118.82174943981876,
 'location': '南京项目地址：河西南部学子路',
 'name': '正荣润峯',
 'price': 0,
 'when': '2017-04-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:37:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%91%9B%E5%A1%98%E8%A1%97%E9%81%93%E5%92%8C%E6%97%AD%E8%B7%AF500%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:37:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_rssfablye/>
{'lat': 32.249438029473545,
 'lng': 118.74243099284794,
 'location': '南京项目地址：葛塘街道和旭路500号',
 'name': '荣盛首府',
 'price': 0,
 'when': '2017-11-29'}
2018-04-12 12:37:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%9C%B0%E9%93%81%E4%BA%8C%E5%8F%B7%E7%BA%BF%E5%A4%A9%E8%BF%88%E5%B9%BF%E5%9C%BA%E6%B2%B9%E5%9D%8A%E6%A1%A5%E7%AB%99 HTTP/1.1" 200 139
2018-04-12 12:37:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_sclfablcb/>
{'lat': 31.971841104007034,
 'lng': 118.72764980327469,
 'location': '南京项目地址：建邺地铁二号线天迈广场油坊桥站',
 'name': '首创立方',
 'price': ' 30000',
 'when': '2017-10-13'}
2018-04-12 12:37:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:37:59 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%8B%E5%AD%90%E6%A5%BC%E8%A5%BF108%E5%8F%B7 HTTP/1.1" 200 133
2018-04-12 12:37:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_xlqpcsqabirr/>
{'lat': 32.12560776782336,
 'lng': 118.90211449894603,
 'location': '南京项目地址：王子楼西108号',
 'name': '仙林汽配城',
 'price': ' 32000',
 'when': '2017-08-04'}
2018-04-12 12:37:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%9C%88%E5%8D%8E%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:00 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.93624759256761,
 'lng': 118.90840306958252,
 'location': '南京项目地址：江宁区淳化街道月华路8号',
 'name': '弘阳上院',
 'price': ' 23000',
 'when': '2015-02-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BD%8D%E5%A4%84%E5%8D%97%E4%BA%AC%E5%94%AF%E4%B8%80%E7%9C%81%E7%BA%A7%E6%97%85%E6%B8%B8%E5%BA%A6%E5%81%87%E5%8C%BA%E2%80%94%E2%80%94%E7%8F%8D%E7%8F%A0%E6%B3%89%E6%97%85%E6%B8%B8%E5%BA%A6%E5%81%87%E5%8C%BA%E5%AF%86%E6%9E%97%E6%B7%B1%E5%A4%84 HTTP/1.1" 200 142
2018-04-12 12:38:00 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1311378986881,
 'lng': 118.66847660834854,
 'location': '南京项目地址：位处南京唯一省级旅游度假区——珍珠泉旅游度假区密林深处',
 'name': '绿城玫瑰园',
 'price': ' 12800',
 'when': '2014-09-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%95%E5%BA%9C%E4%B8%9C%E8%B7%AF%E7%BB%BF%E5%9C%B0%E7%BC%A4%E7%BA%B7%E5%B9%BF%E5%9C%BA HTTP/1.1" 200 134
2018-04-12 12:38:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1181890588941,
 'lng': 118.78596874649138,
 'location': '南京项目地址：幕府东路绿地缤纷广场',
 'name': '绿地缤纷广场',
 'price': ' 158',
 'when': '2017-09-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%9388%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:38:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09998525321101,
 'lng': 118.87119915132855,
 'location': '南京项目地址：玄武大道88号',
 'name': '阳光聚宝山庄臻园',
 'price': 0,
 'when': '2016-09-13'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%81%E9%98%B3%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%AD%E6%99%9A%E4%BA%AD%E5%8D%B0%E8%B1%A1 HTTP/1.1" 200 134
2018-04-12 12:38:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgywtyxabilr/>
{'lat': 31.346944453868932,
 'lng': 118.89424983420618,
 'location': '南京项目地址：滁阳路碧桂园晚亭印象',
 'name': '碧桂园晚亭印象',
 'price': ' 6900',
 'when': '2017-11-19'}
2018-04-12 12:38:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E6%BA%AA%E9%95%87%E7%9F%B3%E8%87%BC%E6%B9%96%E5%8C%97%E8%B7%AF76%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:02 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.344123311690005,
 'lng': 118.89682926137152,
 'location': '南京项目地址：淳溪镇石臼湖北路76号',
 'name': '高淳碧桂园',
 'price': 0,
 'when': '2018-03-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E5%A1%98%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ldlxcabjex/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：高塘路99号',
 'name': '绿地理想城',
 'price': ' 35',
 'when': '2018-01-06'}
2018-04-12 12:38:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E6%B8%85%E6%B0%B4%E4%BA%AD%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:38:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.919765529265728,
 'lng': 118.81406744370776,
 'location': '南京项目地址：秣陵街道清水亭西路188号',
 'name': '九龙湖别墅',
 'price': 0,
 'when': '2016-11-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:04 [scrapy.extensions.logstats] INFO: Crawled 375 pages (at 43 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:38:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%B1%B1%E5%9B%BD%E5%AE%B6%E6%A3%AE%E6%9E%97%E5%85%AC%E5%9B%AD%E5%8D%97%E9%97%A8 HTTP/1.1" 200 136
2018-04-12 12:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_dyqsablea/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华山国家森林公园南门',
 'name': '东原亲山',
 'price': ' 20000',
 'when': '2017-12-22'}
2018-04-12 12:38:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%9F%B3%E6%9D%A8%E8%B7%AF107%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:06 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.01039784610178,
 'lng': 118.87256973377394,
 'location': '南京项目地址：石杨路107号',
 'name': '世茂君望墅',
 'price': 0,
 'when': '2015-09-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:38:06 [scrapy.extensions.logstats] INFO: Crawled 536 pages (at 43 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:38:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg61> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:38:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hblabcnq/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:38:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg61> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:38:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hblabcnq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:38:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%89%E4%B8%AD%E9%97%A8%E5%A4%A7%E8%A1%97%E6%B6%B5%E7%A2%A7%E6%A5%BC HTTP/1.1" 200 137
2018-04-12 12:38:07 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04442588871159,
 'lng': 118.75600338659478,
 'location': '南京项目地址：汉中门大街涵碧楼',
 'name': '涵碧楼',
 'price': ' 25000',
 'when': '2015-08-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg62> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:38:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tchabdhu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:38:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxjshyabdzu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:38:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:08 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E5%91%A8%E8%A5%BF%E8%B7%AF33%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:38:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_yyssabjdy/>
{'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：秣周西路33号',
 'name': '远洋山水',
 'price': ' 18000',
 'when': '2018-04-09'}
2018-04-12 12:38:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hhqhwaayej/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:38:08 [scrapy.extensions.logstats] INFO: Crawled 586 pages (at 41 pages/min), scraped 303 items (at 37 items/min)
2018-04-12 12:38:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg66> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:38:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hnldxsyjabiji/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:38:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_lhmsabhag/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:38:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ltxghyabnqx/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:38:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hysdzxeqabgxt/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:38:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg66> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wjjyabgxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hhqhwaayej/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:38:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E5%B8%82%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B1%A4%E5%B1%B1%E5%9B%BD%E9%99%85%E6%B8%A9%E6%B3%89%E5%9F%8E%E5%9C%A3%E6%B1%A4%E5%A4%A7%E9%81%939%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:38:09 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04829213296588,
 'lng': 119.06564056974446,
 'location': '南京项目地址：南京市江宁区汤山国际温泉城圣汤大道9号',
 'name': '汤城汇',
 'price': 0,
 'when': '2015-02-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jagwlsabebt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:38:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tyljxssyabfqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:38:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdjbtxaawxd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:38:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfcfzxabdwh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:38:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsyfaawlq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:38:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:10 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%A1%94%E6%A1%A5%E8%A5%BF%E8%A1%97155%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:38:10 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.111578944142316,
 'lng': 118.75557194483122,
 'location': '南京项目地址：宝塔桥西街155号',
 'name': '锦绣江山花园',
 'price': 0,
 'when': '2016-11-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%85%89%E8%B7%AF19%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_wjjyabgxy/>
{'lat': 31.688295449939762,
 'lng': 119.03969542075559,
 'location': '南京项目地址：红光路19号',
 'name': '万景佳苑',
 'price': 0,
 'when': '2016-10-10'}
2018-04-12 12:38:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltxghyabnqx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hnldxsyjabiji/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hysdzxeqabgxt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%A1%94%E8%B7%AF98%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hhqhwaayej/>
{'lat': 31.328638162523443,
 'lng': 118.88087325668766,
 'location': '南京项目地址：宝塔路98号',
 'name': '华辉秦淮湾',
 'price': 0,
 'when': '2017-06-05'}
2018-04-12 12:38:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%99%BA%E6%B1%87%E8%B7%AF92%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:38:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.033566135579086,
 'lng': 118.91402647916111,
 'location': '南京项目地址：智汇路92号',
 'name': '京奥港未来墅',
 'price': ' 26000',
 'when': '2017-09-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E7%99%BD%E9%A9%AC%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:38:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08732150414787,
 'lng': 118.63490312801513,
 'location': '南京项目地址：江浦街道白马路89号',
 'name': '通宇林景象山墅院',
 'price': ' 38000',
 'when': '2016-03-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%A5%E5%87%A4%E8%B7%AF5%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_ltxghyabnqx/>
{'lat': 31.78563307820375,
 'lng': 118.86158025941931,
 'location': '南京项目地址：来凤路5号',
 'name': '蓝天星港花园',
 'price': ' 17000',
 'when': '2017-12-23'}
2018-04-12 12:38:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg41> (referer: https://nj.fang.lianjia.com/loupan/pg/pg40)
2018-04-12 12:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hzqlwaawla/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flsjfaawld/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yzhybhlaawbr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_fctyaawlb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ycdyfaauuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E5%8D%97%E8%B7%AF%E5%9C%B0%E4%B8%8B%E5%95%86%E4%B8%9A%E8%A1%97 HTTP/1.1" 200 137
2018-04-12 12:38:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hnldxsyjabiji/>
{'lat': 32.074991410650846,
 'lng': 118.78115603429792,
 'location': '南京项目地址：湖南路地下商业街',
 'name': '湖南路地下商业街',
 'price': ' 300',
 'when': '2017-06-03'}
2018-04-12 12:38:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E6%A1%A5%E5%8C%97%E8%B7%AF%E5%BC%98%E9%98%B3%E6%97%B6%E4%BB%A3%E4%B8%AD%E5%BF%83 HTTP/1.1" 200 135
2018-04-12 12:38:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_hysdzxeqabgxt/>
{'lat': 32.145114679194116,
 'lng': 118.72727783203082,
 'location': '南京项目地址：大桥北路弘阳时代中心',
 'name': '弘阳时代中心二期',
 'price': ' 15000',
 'when': '2017-10-29'}
2018-04-12 12:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg67> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyslcfabkak/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E7%90%8A%E5%B1%B1%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%AD%E5%8D%81%E9%87%8C%E6%98%A5%E9%A3%8E HTTP/1.1" 200 134
2018-04-12 12:38:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_bgyslcfabkak/>
{'lat': 31.346944453868932,
 'lng': 118.89424983420618,
 'location': '南京项目地址：红琊山路碧桂园十里春风',
 'name': '碧桂园十里春风',
 'price': ' 7500',
 'when': '2018-03-07'}
2018-04-12 12:38:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:38:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:38:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A9%E7%94%9F%E6%A1%A5%E5%A4%A7%E9%81%93218%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.648004371136633,
 'lng': 119.0089268568526,
 'location': '南京项目地址：天生桥大道218号',
 'name': '华洲青林湾',
 'price': 0,
 'when': '2017-09-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hcwjaauyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9A%82%E6%97%A0 HTTP/1.1" 200 136
2018-04-12 12:38:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：暂无',
 'name': '富力水街坊',
 'price': 0,
 'when': '2017-12-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B6%A6%E5%AF%BF%E5%8C%97%E8%B7%AF599%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.859401199797308,
 'lng': 118.60077001053546,
 'location': '南京项目地址：润寿北路599号',
 'name': '禹洲弘阳滨湖里',
 'price': 0,
 'when': '2016-12-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E5%8C%97%E8%B7%AF369%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:38:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.612703497788456,
 'lng': 118.99424929340748,
 'location': '南京项目地址：金牛北路369号',
 'name': '福晟庭院',
 'price': 0,
 'when': '2015-10-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%B7%E7%A6%8F%E5%B7%B771%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:17 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.02535577253019,
 'lng': 118.84839752545017,
 'location': '南京项目地址：海福巷71号',
 'name': '银城东岳府',
 'price': 0,
 'when': '2017-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xzllhwaawji/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhmsabhag/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B9%96%E5%A4%A7%E9%81%93%E5%92%8C%E6%98%8C%E6%B9%BE%E6%99%AF HTTP/1.1" 200 142
2018-04-12 12:38:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.9254387597965,
 'lng': 118.67555812585326,
 'location': '南京项目地址：新湖大道和昌湾景',
 'name': '和昌湾景',
 'price': 0,
 'when': '2017-07-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jhjlmzaawjd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hxcjyaawif/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E9%9E%8D%E8%A1%97%E9%81%93%E5%BC%98%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://nj.fang.lianjia.com/loupan/p_lhmsabhag/>
{'lat': 32.5387256198191,
 'lng': 118.81897438994582,
 'location': '南京项目地址：马鞍街道弘湖路1号',
 'name': '郦湖美墅',
 'price': ' 18500',
 'when': '2017-07-09'}
2018-04-12 12:38:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceln/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceln/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E6%B9%96%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:21 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.700575027936633,
 'lng': 119.07375409205974,
 'location': '南京项目地址：永湖路188号',
 'name': '恒大金碧天下',
 'price': 0,
 'when': '2018-03-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:21 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%A4%A7%E9%81%936%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:38:21 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.063466256710505,
 'lng': 118.67466304975159,
 'location': '南京项目地址：浦口大道6号',
 'name': '明发财富中心',
 'price': ' 17000',
 'when': '2017-10-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg68> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceju/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceju/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8F%8D%E7%8F%A0%E5%8C%97%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:22 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.684557220584292,
 'lng': 119.03736365769795,
 'location': '南京项目地址：珍珠北路88号',
 'name': '喜之郎丽湖湾',
 'price': 0,
 'when': '2015-12-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:38:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:23 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E4%B8%9C%E8%B7%AF301%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:23 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04676420264064,
 'lng': 118.81321034167492,
 'location': '南京项目地址：中山东路301号',
 'name': '钟山颐府',
 'price': 0,
 'when': '2016-06-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_lggyaawox/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:38:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg63> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:38:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gjoydsygcabcyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:38:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%83%9C%E5%A4%AA%E8%B7%AF%E9%87%91%E8%BE%89%E9%87%91%E9%99%B5%E9%93%AD%E8%91%97 HTTP/1.1" 200 135
2018-04-12 12:38:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.95061810100132,
 'lng': 118.82058772867562,
 'location': '南京项目地址：胜太路金辉金陵铭著',
 'name': '金辉金陵铭著',
 'price': 0,
 'when': '2016-11-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E5%B8%82%E6%BA%A7%E6%B0%B4%E5%8C%BA%E7%A7%A6%E6%B7%AE%E8%B7%AF159-21%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.657385165530922,
 'lng': 119.05231070860395,
 'location': '南京项目地址：南京市溧水区秦淮路159-21号',
 'name': '顾家欧亚达商业广场',
 'price': 0,
 'when': '2015-11-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lggyaawox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:38:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:38:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg69> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%8C%BA%E5%B7%B4%E5%B1%B1%E8%B7%AF38%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:38:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.008675496084074,
 'lng': 118.73063170639526,
 'location': '南京项目地址：建邺区巴山路38号',
 'name': '华新城璟园',
 'price': 0,
 'when': '2016-05-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg42> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacely/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E6%96%B0%E8%B7%AF%E8%93%9D%E5%85%89%E5%85%AC%E5%9B%AD1%E5%8F%B7 HTTP/1.1" 200 146
2018-04-12 12:38:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.92591631683342,
 'lng': 118.67321099728457,
 'location': '南京项目地址：华新路蓝光公园1号',
 'name': '蓝光公园1号',
 'price': 0,
 'when': '2017-06-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg64> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:38:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hhqhwaayej/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:38:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacely/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:26 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:38:26 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacele/>: HTTP status code is not handled or not allowed
2018-04-12 12:38:27 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:38:27 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:38:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceni/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacekv/>: HTTP status code is not handled or not allowed
2018-04-12 12:38:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_njjazxabhgr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_slzxcaawcm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg41)
2018-04-12 12:38:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jsfaawlc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceni/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceli/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:38:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceli/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:38:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceou/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:38:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:38:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceou/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:28 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%A1%94%E8%B7%AF98%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:28 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.328638162523443,
 'lng': 118.88087325668766,
 'location': '南京项目地址：宝塔路98号',
 'name': '华辉秦淮湾',
 'price': 0,
 'when': '2017-06-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_cpsjgcabbis/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:38:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:38:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:38:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg65> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:38:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E4%B8%9C%E4%B8%AD%E8%B7%AF333%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.00432202883629,
 'lng': 118.73176864542782,
 'location': '南京项目地址：江东中路333号',
 'name': '南京金奥中心',
 'price': 0,
 'when': '2013-12-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djyfaaynn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_shxgabgvr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jrgjgcabeuu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcthyabgvb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyozcabgyt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%AD%E5%90%88%E5%8C%BA%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E7%8E%8B%E6%A1%A5%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 134
2018-04-12 12:38:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.33244867233251,
 'lng': 118.84063470707173,
 'location': '南京项目地址：六合区雄州街道王桥路99号',
 'name': '石林中心城',
 'price': 0,
 'when': '2017-10-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:38:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E8%8E%89%E6%B9%96%E8%A5%BF%E8%B7%AF31%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:38:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.33177772895079,
 'lng': 118.81890481887899,
 'location': '南京项目地址：龙池街道莉湖西路31号',
 'name': '东骏悦府',
 'price': ' 11000',
 'when': '2016-11-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dhjxhcyabmqu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzjjyaayda/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:38:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E5%B1%B1%E8%B7%AF95%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:38:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.94158984043159,
 'lng': 118.84824359301572,
 'location': '南京项目地址：金山路95号',
 'name': '金山府',
 'price': 0,
 'when': '2015-05-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wyqcwjblzxabgnj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ydhczxabgkt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:38:32 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.123523391191696,
 'lng': 118.72947850536069,
 'location': '南京项目地址：浦口区浦珠北路59号',
 'name': '大华锦绣华城商业',
 'price': ' 45000',
 'when': '2017-07-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:38:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:38:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%82%85%E5%AE%B6%E8%BE%B9%E7%8E%B0%E4%BB%A3%E5%86%9C%E4%B8%9A%E5%9B%AD%E5%8C%BA%E5%86%85 HTTP/1.1" 200 133
2018-04-12 12:38:34 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.577965439645308,
 'lng': 119.01108803019201,
 'location': '南京项目地址：傅家边现代农业园区内',
 'name': '森湖溪谷',
 'price': 0,
 'when': '2009-07-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:38:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A5%A0%E6%BA%AA%E6%B1%9F%E4%B8%9C%E8%A1%97%E4%B8%8E%E6%81%92%E5%B1%B1%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 136
2018-04-12 12:38:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.996202612883714,
 'lng': 118.74177240914636,
 'location': '南京项目地址：楠溪江东街与恒山路交汇处',
 'name': '金润国际广场',
 'price': ' 31000',
 'when': '2012-11-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BE%90%E5%BA%84%E8%BD%AF%E4%BB%B6%E5%9B%AD HTTP/1.1" 200 143
2018-04-12 12:38:37 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.097126504668104,
 'lng': 118.89223524935424,
 'location': '南京项目地址：徐庄软件园',
 'name': '苏宁紫金嘉悦',
 'price': ' 20000',
 'when': '2016-09-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sclfablcb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:38:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:38 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%A4%E5%B1%B1%E8%A1%97%E9%81%93%E9%BA%92%E9%BA%9F%E9%97%A8%E5%A4%A7%E9%81%936699%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:38:38 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04571553461317,
 'lng': 119.02176299880456,
 'location': '南京项目地址：汤山街道麒麟门大道6699号',
 'name': '绿城桃花源',
 'price': 0,
 'when': '2018-03-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:38 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%9C%B0%E9%93%81%E4%BA%8C%E5%8F%B7%E7%BA%BF%E5%A4%A9%E8%BF%88%E5%B9%BF%E5%9C%BA%E6%B2%B9%E5%9D%8A%E6%A1%A5%E7%AB%99 HTTP/1.1" 200 139
2018-04-12 12:38:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.971841104007034,
 'lng': 118.72764980327469,
 'location': '南京项目地址：建邺地铁二号线天迈广场油坊桥站',
 'name': '首创立方',
 'price': ' 30000',
 'when': '2017-10-13'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdmygcabmqh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:38:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hlgjablxd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:38:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdmygcabmqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:38:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ljlaaynh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:38:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rssfablye/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:38:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dyqsablea/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:38:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%81%E5%AE%81%E5%A4%A7%E9%81%931998%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:38:40 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：滁宁大道1998号',
 'name': '碧桂园欧洲城',
 'price': 0,
 'when': '2017-07-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E9%97%A8%E5%A4%A7%E8%A1%97297%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.043648320833704,
 'lng': 118.86848048488551,
 'location': '南京项目地址：中山门大街297号',
 'name': '钟鼎名悦广场',
 'price': 0,
 'when': '2017-09-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%A7%E8%A1%9781%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:38:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0574390450143,
 'lng': 118.78971204573793,
 'location': '南京项目地址：中大街81号',
 'name': '海伦国际',
 'price': 0,
 'when': '2017-10-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:41 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E9%97%A8%E5%A4%A7%E8%A1%97297%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:41 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.043648320833704,
 'lng': 118.86848048488551,
 'location': '南京项目地址：中山门大街297号',
 'name': '钟鼎名悦广场',
 'price': ' 50000',
 'when': '2018-03-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E9%BE%99%E5%87%A4%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:38:42 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.943934853497655,
 'lng': 118.94156811107989,
 'location': '南京项目地址：淳化街道龙凤路2号',
 'name': '万宇汽车五金博览中心',
 'price': 0,
 'when': '2016-05-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E4%B8%9C%E5%8C%97%E8%B7%AF%E9%BE%99%E6%B1%9F%E9%87%8C HTTP/1.1" 200 137
2018-04-12 12:38:43 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05770706730537,
 'lng': 118.74598750383659,
 'location': '南京项目地址：江东北路龙江里',
 'name': '龙江里',
 'price': ' 34000',
 'when': '2016-12-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%80%BB%E9%83%A8%E5%A4%A7%E9%81%93%E6%AF%85%E8%BE%BE%E6%B1%87%E5%88%9B%E4%B8%AD%E5%BF%83 HTTP/1.1" 200 136
2018-04-12 12:38:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：总部大道毅达汇创中心',
 'name': '毅达汇创中心',
 'price': ' 24500',
 'when': '2017-06-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_heshyhggabgfc/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:38:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg43> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_heshyhggabgfc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:38:47 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.393150940897428,
 'lng': 118.97196008794114,
 'location': '南京项目地址：双湖路1号',
 'name': '海尔双湖壹号公馆',
 'price': 0,
 'when': '2017-06-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wnsscdsjjqabelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg42)
2018-04-12 12:38:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jngcabbex/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znjyabaye/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg70> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:38:49 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E6%B4%B2%E8%B7%AF66%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:38:49 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.16240412601025,
 'lng': 118.75041249708227,
 'location': '南京项目地址：浦洲路66号',
 'name': '威尼斯水城第十九街区',
 'price': ' 20600',
 'when': '2017-11-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%85%AD%E5%90%88%E9%95%BF%E6%B1%9F%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:50 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.347517586163555,
 'lng': 118.84876979582978,
 'location': '南京项目地址：六合长江路1号',
 'name': '金宁广场',
 'price': ' 13000',
 'when': '2010-11-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%BD%AF%E4%BB%B6%E5%A4%A7%E9%81%93%E4%B8%AD%E5%8D%97%E9%94%A6%E8%8B%91 HTTP/1.1" 200 144
2018-04-12 12:38:50 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.984256699458975,
 'lng': 118.75651496529456,
 'location': '南京项目地址：软件大道中南锦苑',
 'name': '中南锦苑',
 'price': ' 150',
 'when': '2017-03-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg44> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htssyjabatw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcslabfij/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hlgjabatq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhcjzcabbrp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_undefinedaatan/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BA%91%E9%94%A6%E8%B7%AF%E5%AE%8F%E5%9B%BE%E4%B8%8A%E6%B0%B4%E4%BA%91%E9%94%A6 HTTP/1.1" 200 144
2018-04-12 12:38:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.021247988570856,
 'lng': 118.74727426898808,
 'location': '南京项目地址：云锦路宏图上水云锦',
 'name': '宏图上水云锦一期',
 'price': ' 55000',
 'when': '2017-01-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dcjmyaatpv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_znsjyyaaynl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E5%B1%B1%E8%A1%97%E9%81%93%E5%AF%8C%E5%A1%98%E8%A1%978%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97168171605523,
 'lng': 118.86003408519586,
 'location': '南京项目地址：东山街道富塘街8号',
 'name': '绿城深蓝',
 'price': 0,
 'when': '2018-02-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%A7%E8%A1%9781%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:38:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0574390450143,
 'lng': 118.78971204573793,
 'location': '南京项目地址：中大街81号',
 'name': '海伦国际',
 'price': ' 12730',
 'when': '2017-10-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E8%BE%B9%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:38:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.095733750047245,
 'lng': 118.74065486319363,
 'location': '南京项目地址：江边路1号',
 'name': '龙湖春江紫宸',
 'price': 0,
 'when': '2017-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E9%AB%98%E5%BA%99%E8%B7%AF%E6%9C%97%E8%AF%97%E7%86%99%E5%8D%8E%E5%BA%9C HTTP/1.1" 200 141
2018-04-12 12:38:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.9752553808195,
 'lng': 118.69895635055644,
 'location': '南京项目地址：南高庙路朗诗熙华府',
 'name': '朗诗熙华府',
 'price': 0,
 'when': '2017-11-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flshabfza/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:38:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%91%9B%E5%A1%98%E8%A1%97%E9%81%93%E5%92%8C%E6%97%AD%E8%B7%AF500%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:38:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.249438029473545,
 'lng': 118.74243099284794,
 'location': '南京项目地址：葛塘街道和旭路500号',
 'name': '荣盛首府',
 'price': 0,
 'when': '2017-11-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%B1%B1%E5%9B%BD%E5%AE%B6%E6%A3%AE%E6%9E%97%E5%85%AC%E5%9B%AD%E5%8D%97%E9%97%A8 HTTP/1.1" 200 136
2018-04-12 12:38:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华山国家森林公园南门',
 'name': '东原亲山',
 'price': ' 20000',
 'when': '2017-12-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ldhqchpbjabmmc/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:38:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ltxghyabnqx/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:38:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_cpsjgcabbis/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:38:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg66> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:38:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ldlxcabjex/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:38:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hyylqjabjif/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:38:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_lhxycabktp/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2018-04-12 12:38:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%87%E9%9D%96%E4%B8%9C%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:38:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.96985873235598,
 'lng': 118.87182639943344,
 'location': '南京项目地址：文靖东路88号',
 'name': '东城金茂悦',
 'price': 0,
 'when': '2017-07-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wjjyabgxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:55 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E4%B8%AD%E5%8D%97%E4%B8%96%E7%BA%AA%E9%9B%85%E8%8B%91 HTTP/1.1" 200 143
2018-04-12 12:38:55 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04313070524712,
 'lng': 118.91670898739703,
 'location': '南京项目地址：马群街道中南世纪雅苑',
 'name': '中南世纪雅苑',
 'price': 0,
 'when': '2017-05-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhtylabxle/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:38:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xlqpcsqabirr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%85%89%E8%B7%AF19%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:38:56 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.688295449939762,
 'lng': 119.03969542075559,
 'location': '南京项目地址：红光路19号',
 'name': '万景佳苑',
 'price': 0,
 'when': '2016-10-10'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hnldxsyjabiji/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yyssabjdy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%9C%E9%BA%92%E8%B7%AF277%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:38:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.01565712729463,
 'lng': 118.88669095266192,
 'location': '南京项目地址：东麒路277号',
 'name': '富力十号',
 'price': ' 900',
 'when': '2015-06-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:38:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:38:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:38:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:38:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%83%AD%E6%B2%B3%E5%8D%97%E8%B7%AF%E6%9E%9C%E5%93%81%E5%B8%82%E5%9C%BA%E5%9C%B0%E5%9D%97%E4%B8%AD%E6%B5%B7%E6%A1%83%E5%9B%AD%E9%87%8C HTTP/1.1" 200 136
2018-04-12 12:38:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.083859111765705,
 'lng': 118.7477835049071,
 'location': '南京项目地址：热河南路果品市场地块中海桃园里',
 'name': '中海桃源里',
 'price': 0,
 'when': '2018-03-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%8B%E5%AD%90%E6%A5%BC%E8%A5%BF108%E5%8F%B7 HTTP/1.1" 200 133
2018-04-12 12:38:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12560776782336,
 'lng': 118.90211449894603,
 'location': '南京项目地址：王子楼西108号',
 'name': '仙林汽配城',
 'price': ' 32000',
 'when': '2017-08-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:38:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hysdzxeqabgxt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhmsabhag/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:38:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:38:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg45> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:38:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyshsjabryn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:38:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wkdhnyaayrt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg43)
2018-04-12 12:38:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E5%8D%97%E8%B7%AF%E5%9C%B0%E4%B8%8B%E5%95%86%E4%B8%9A%E8%A1%97 HTTP/1.1" 200 137
2018-04-12 12:39:00 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.074991410650846,
 'lng': 118.78115603429792,
 'location': '南京项目地址：湖南路地下商业街',
 'name': '湖南路地下商业街',
 'price': ' 300',
 'when': '2017-06-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:00 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A8%AA%E5%B1%B1%E8%A5%BF%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%ADS1%E7%A7%A6%E6%B7%AE%E4%B8%96%E5%AE%B6 HTTP/1.1" 200 137
2018-04-12 12:39:00 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.648311742573938,
 'lng': 118.91514343402882,
 'location': '南京项目地址：横山西路碧桂园S1秦淮世家',
 'name': '碧桂园S1秦淮世家',
 'price': ' 60000',
 'when': '2018-03-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:39:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacela/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
2018-04-12 12:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%98%8E%E5%9F%8E%E5%A4%A7%E9%81%93%E4%B8%87%E7%A7%91%E9%83%BD%E8%8D%9F%E5%8D%97%E8%8B%91 HTTP/1.1" 200 136
2018-04-12 12:39:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.97475979445248,
 'lng': 118.81085768852734,
 'location': '南京项目地址：明城大道万科都荟南苑',
 'name': '万科星荟',
 'price': 0,
 'when': '2017-10-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceky/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacela/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg44)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:01 [scrapy.extensions.logstats] INFO: Crawled 421 pages (at 46 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:39:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg46> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacell/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:02 [scrapy.extensions.logstats] INFO: Crawled 636 pages (at 50 pages/min), scraped 310 items (at 7 items/min)
2018-04-12 12:39:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacell/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:02 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E5%91%A8%E8%A5%BF%E8%B7%AF33%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:39:02 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：秣周西路33号',
 'name': '远洋山水',
 'price': ' 18000',
 'when': '2018-04-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg47> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:39:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceks/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceks/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:39:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:39:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:39:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:39:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacems/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:39:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacems/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:39:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:39:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:39:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg48> (referer: https://nj.fang.lianjia.com/loupan/pg/pg47)
2018-04-12 12:39:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E6%A1%A5%E5%8C%97%E8%B7%AF%E5%BC%98%E9%98%B3%E6%97%B6%E4%BB%A3%E4%B8%AD%E5%BF%83 HTTP/1.1" 200 135
2018-04-12 12:39:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.145114679194116,
 'lng': 118.72727783203082,
 'location': '南京项目地址：大桥北路弘阳时代中心',
 'name': '弘阳时代中心二期',
 'price': ' 15000',
 'when': '2017-10-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
2018-04-12 12:39:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg46)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
2018-04-12 12:39:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg45)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacels/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacema/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacels/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacema/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceng/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg49> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E9%9E%8D%E8%A1%97%E9%81%93%E5%BC%98%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:39:06 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.5387256198191,
 'lng': 118.81897438994582,
 'location': '南京项目地址：马鞍街道弘湖路1号',
 'name': '郦湖美墅',
 'price': ' 18500',
 'when': '2017-07-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hyylqjabjif/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:39:06 [scrapy.extensions.logstats] INFO: Crawled 570 pages (at 34 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:39:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_ldlxcabjex/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:39:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg66> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:39:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg50> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:07 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B2%BF%E6%B1%9F%E8%A1%97%E9%81%93%E9%AB%98%E6%96%B0%E6%8A%80%E6%9C%AF%E4%BA%A7%E4%B8%9A%E5%BC%80%E5%8F%91%E5%8C%BA HTTP/1.1" 200 137
2018-04-12 12:39:07 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.16709029296466,
 'lng': 118.74179198502003,
 'location': '南京项目地址：沿江街道高新技术产业开发区',
 'name': '弘阳燕澜七缙',
 'price': ' 42000',
 'when': '2017-08-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg66> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhxycabktp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldhqchpbjabmmc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltxghyabnqx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cpsjgcabbis/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:39:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgywtyxabilr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:39:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceok/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:39:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceow/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
2018-04-12 12:39:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceow/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg48)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/pg/pg70> (failed 2 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%9C%A0%E5%A4%A7%E9%81%93660%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:39:09 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.915202403612295,
 'lng': 118.90964727896606,
 'location': '南京项目地址：龙眠大道660号',
 'name': '龙湖新壹城',
 'price': 0,
 'when': '2017-10-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldlxcabjex/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:39:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceov/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceot/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceot/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceql/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
2018-04-12 12:39:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceql/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg49)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg51> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%8E%8B%E5%A4%A7%E8%A1%97%E7%BB%BF%E5%9C%B0%E5%8D%8E%E4%BE%A8%E5%9F%8E%E6%B5%B7%E7%8F%80%E6%BB%A8%E6%B1%9F HTTP/1.1" 200 137
2018-04-12 12:39:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.981396621207637,
 'lng': 118.69564997992349,
 'location': '南京项目地址：龙王大街绿地华侨城海珀滨江',
 'name': '绿地华侨城海珀滨江',
 'price': 0,
 'when': '2017-11-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:12 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%A5%E5%87%A4%E8%B7%AF5%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:39:12 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.78563307820375,
 'lng': 118.86158025941931,
 'location': '南京项目地址：来凤路5号',
 'name': '蓝天星港花园',
 'price': ' 17000',
 'when': '2017-12-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg52> (referer: https://nj.fang.lianjia.com/loupan/pg/pg51)
2018-04-12 12:39:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg70> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg53> (referer: https://nj.fang.lianjia.com/loupan/pg/pg52)
2018-04-12 12:39:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceom/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg54> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceom/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacept/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacept/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:14 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B8%AF%E5%A4%A7%E9%81%9388%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:39:14 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.169791062821595,
 'lng': 118.87681335325735,
 'location': '南京项目地址：新港大道88号',
 'name': '翠屏水晶广场',
 'price': ' 45',
 'when': '2016-01-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceur/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceon/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceon/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BB%81%E9%98%B3%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%AD%E6%99%9A%E4%BA%AD%E5%8D%B0%E8%B1%A1 HTTP/1.1" 200 134
2018-04-12 12:39:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.346944453868932,
 'lng': 118.89424983420618,
 'location': '南京项目地址：滁阳路碧桂园晚亭印象',
 'name': '碧桂园晚亭印象',
 'price': ' 6900',
 'when': '2017-11-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:16 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%AB%98%E5%A1%98%E8%B7%AF99%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:39:16 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：高塘路99号',
 'name': '绿地理想城',
 'price': ' 35',
 'when': '2018-01-06'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:39:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg67> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceua/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:39:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgyslcfabkak/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceug/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceug/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacett/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacett/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceum/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceum/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg71> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E7%90%8A%E5%B1%B1%E8%B7%AF%E7%A2%A7%E6%A1%82%E5%9B%AD%E5%8D%81%E9%87%8C%E6%98%A5%E9%A3%8E HTTP/1.1" 200 134
2018-04-12 12:39:22 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.346944453868932,
 'lng': 118.89424983420618,
 'location': '南京项目地址：红琊山路碧桂园十里春风',
 'name': '碧桂园十里春风',
 'price': ' 7500',
 'when': '2018-03-07'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceol/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:39:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceol/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg72> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceli/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceli/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceps/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceln/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceve/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceps/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceln/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacest/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacess/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceve/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacest/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacess/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg68> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacern/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:39:25 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:39:25 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacern/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacekv/>: HTTP status code is not handled or not allowed
2018-04-12 12:39:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg73> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg69> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceju/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceju/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceni/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceni/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg55> (referer: https://nj.fang.lianjia.com/loupan/pg/pg54)
2018-04-12 12:39:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacery/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacery/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacely/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacely/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekw/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:39:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:39:28 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacele/>: HTTP status code is not handled or not allowed
2018-04-12 12:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceui/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceui/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg70> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacero/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:39:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacero/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceqf/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:39:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:39:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg56> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg57> (referer: https://nj.fang.lianjia.com/loupan/pg/pg56)
2018-04-12 12:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceqf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
2018-04-12 12:39:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceqf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg50)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qhyzabnwc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg74> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg75> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceol/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceol/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceou/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceou/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:39:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacept/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacept/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceti/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceti/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceps/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceps/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceon/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewa/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceon/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:36 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%8C%E5%A1%98%E5%8D%97%E8%B7%AF68%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:39:36 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.676904082947466,
 'lng': 119.03333730597843,
 'location': '南京项目地址：双塘南路68号',
 'name': '秦淮源筑',
 'price': ' 12000',
 'when': '2017-11-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdfchtabilb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xlqpcsqabirq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:36 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/> (failed 3 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcaceuy/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg76> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:39:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceom/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceom/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekz/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:39:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:39:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E9%A3%9E%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:39:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.104949086157944,
 'lng': 118.82824103380696,
 'location': '南京项目地址：华飞路1号',
 'name': '恒大翡翠华庭',
 'price': ' 380',
 'when': '2017-07-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcysabltv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://nj.fang.lianjia.com/loupan/p_bcacelq/>: Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%8B%E5%AD%90%E6%A5%BC%E8%A5%BF108%E5%8F%B7 HTTP/1.1" 200 133
2018-04-12 12:39:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.12560776782336,
 'lng': 118.90211449894603,
 'location': '南京项目地址：王子楼西108号',
 'name': '仙林汽配城',
 'price': 0,
 'when': '2017-08-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%B1%B1%E5%9B%BD%E5%AE%B6%E6%A3%AE%E6%9E%97%E5%85%AC%E5%9B%AD HTTP/1.1" 200 136
2018-04-12 12:39:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华山国家森林公园',
 'name': '新城源山',
 'price': ' 16000',
 'when': '2017-11-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qxyyaakrh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhfcxcaaksy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%84%E5%B7%9E%E8%A1%97%E9%81%93%E5%9B%AD%E6%9E%97%E8%A5%BF%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:39:40 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.360387136248946,
 'lng': 118.84133678305696,
 'location': '南京项目地址：雄州街道园林西路188号',
 'name': '清香雅苑',
 'price': 0,
 'when': '2016-12-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zjjlhaaksm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dphaakno/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg71> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:39:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E6%BA%AA%E9%95%87%E5%AE%9D%E5%A1%94%E8%B7%AF350%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:39:42 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.335414317323576,
 'lng': 118.90942190794753,
 'location': '南京项目地址：淳溪镇宝塔路350号',
 'name': '隆豪翡翠星城',
 'price': 0,
 'when': '2017-07-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:39:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:39:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wymsyaakoe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:39:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:39:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%93%E6%BA%AA%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:39:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：卓溪路10号',
 'name': '中交锦兰荟',
 'price': 0,
 'when': '2016-07-07'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E6%BA%A7%E6%B0%B4%E5%8E%BF%E4%B8%9C%E5%B1%8F%E9%95%87 HTTP/1.1" 200 138
2018-04-12 12:39:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.722363055816007,
 'lng': 119.03588719018546,
 'location': '南京项目地址：南京溧水县东屏镇',
 'name': '东屏湖9号',
 'price': 0,
 'when': '2013-01-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg58> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E5%B9%B3%E5%92%8C%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:39:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.943934853497655,
 'lng': 118.94156811107989,
 'location': '南京项目地址：淳化街道平和路8号',
 'name': '武夷名仕园',
 'price': 0,
 'when': '2015-10-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bgysjcbabisk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg57)
2018-04-12 12:39:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yclxjaarwg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:39:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceto/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:39:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceto/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceun/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceun/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%83%AD%E5%BA%84%E9%95%87%E6%9C%BA%E5%9C%BA%E5%A4%A7%E9%81%93%E5%8D%97%E7%A2%A7%E6%A1%82%E5%9B%AD%E4%B8%96%E7%BA%AA%E5%9F%8E%E9%82%A6 HTTP/1.1" 200 134
2018-04-12 12:39:48 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.346944453868932,
 'lng': 118.89424983420618,
 'location': '南京项目地址：郭庄镇机场大道南碧桂园世纪城邦',
 'name': '碧桂园世纪城邦',
 'price': ' 12000',
 'when': '2017-08-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhyggaamil/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:39:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
2018-04-12 12:39:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceui/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceui/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetj/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E5%88%9B%E6%96%B0%E4%B8%9C%E8%B7%AF2%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:39:50 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.8838176413981,
 'lng': 118.88290815941363,
 'location': '南京项目地址：秣陵街道创新东路2号',
 'name': '银城蓝溪郡',
 'price': 0,
 'when': '2015-10-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacewv/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacewp/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg72> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceti/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:39:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceti/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg73> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacevg/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacero/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacero/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacern/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:52 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B7%B3%E5%8C%96%E8%A1%97%E9%81%93%E6%B3%89%E4%B8%9C%E8%B7%AF58%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:39:52 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.9539171307712,
 'lng': 118.88896630931528,
 'location': '南京项目地址：淳化街道泉东路58号',
 'name': '中航樾公馆',
 'price': 0,
 'when': '2017-07-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg53)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacern/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg59> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:39:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gkrjaamhi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:39:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hysglaapty/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:39:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dflyaapvh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:39:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rjyblsaamir/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:39:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xchyzjaakrz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:39:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacery/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacery/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacepw/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg74> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacexb/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacevi/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:39:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacewz/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:39:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:56 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%88%E6%95%AC%E8%B7%AF313%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:39:56 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1266799019819,
 'lng': 118.98830874517166,
 'location': '南京项目地址：守敬路313号',
 'name': '高科荣境',
 'price': 0,
 'when': '2012-10-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:39:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zyzjgdaaqce/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:39:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_qdfzaagpr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:39:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:39:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg75> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:39:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:58 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%93%9D%E6%B5%B7%E8%B7%AF%E5%BC%98%E9%98%B3%E6%97%B6%E5%85%89%E9%87%8C HTTP/1.1" 200 144
2018-04-12 12:39:58 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.18039301137142,
 'lng': 118.7172462747398,
 'location': '南京项目地址：蓝海路弘阳时光里',
 'name': '弘阳时光里',
 'price': 0,
 'when': '2017-06-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:39:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:39:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacets/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:39:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacets/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:39:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg76> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:40:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:40:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:40:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:40:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-04-12 12:40:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 60,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 22,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 38,
 'downloader/request_bytes': 565012,
 'downloader/request_count': 767,
 'downloader/request_method_count/GET': 767,
 'downloader/response_bytes': 15745545,
 'downloader/response_count': 707,
 'downloader/response_status_count/200': 690,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/500': 16,
 'dupefilter/filtered': 900,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 4, 12, 4, 40, 0, 509090),
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/500': 6,
 'item_scraped_count': 310,
 'log_count/DEBUG': 1705,
 'log_count/ERROR': 304,
 'log_count/INFO': 23,
 'memusage/max': 153923584,
 'memusage/startup': 59555840,
 'request_depth_max': 76,
 'response_received_count': 697,
 'retry/count': 70,
 'retry/max_reached': 6,
 'retry/reason_count/500 Internal Server Error': 10,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 22,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 38,
 'scheduler/dequeued': 766,
 'scheduler/dequeued/memory': 766,
 'scheduler/enqueued': 766,
 'scheduler/enqueued/memory': 766,
 'spider_exceptions/IndexError': 304,
 'start_time': datetime.datetime(2018, 4, 12, 4, 29, 2, 263363)}
2018-04-12 12:40:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-04-12 12:40:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:40:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:40:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%A0%96%E9%9C%9E%E7%BB%8F%E4%BA%94%E8%B7%AF%E4%B8%8E%E8%BF%88%E5%8C%96%E8%B7%AF%E4%BA%A4%E6%B1%87%E5%A4%84 HTTP/1.1" 200 134
2018-04-12 12:40:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1312287642796,
 'lng': 118.84117460118358,
 'location': '南京项目地址：栖霞经五路与迈化路交汇处',
 'name': '东方兰园',
 'price': 0,
 'when': '2016-07-28'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E5%AE%81%E4%B8%B9%E9%98%B3%E5%A4%A7%E9%81%93110%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.849796224068285,
 'lng': 118.77857718961954,
 'location': '南京项目地址：江宁丹阳大道110号',
 'name': '瑞景叶泊蓝山',
 'price': 0,
 'when': '2012-10-02'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:01 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%B9%E9%9C%9E%E8%B7%AF%E6%96%B0%E5%9F%8E%E8%8A%B1%E6%BC%BE%E7%B4%AB%E9%83%A1 HTTP/1.1" 200 143
2018-04-12 12:40:01 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.18964133869749,
 'lng': 118.72037139247337,
 'location': '南京项目地址：丹霞路新城花漾紫郡',
 'name': '新城花漾紫郡',
 'price': 0,
 'when': '2016-10-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:40:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceya/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:40:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:40:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceya/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:40:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:02 [scrapy.extensions.logstats] INFO: Crawled 668 pages (at 98 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:40:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacety/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:40:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:40:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:40:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E7%BE%A4%E8%A1%97%E9%81%93%E4%B8%AD%E5%9E%A0%E7%B4%AB%E9%87%91%E8%A7%82%E9%82%B8 HTTP/1.1" 200 144
2018-04-12 12:40:03 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05232823923972,
 'lng': 118.90154611589733,
 'location': '南京项目地址：马群街道中垠紫金观邸',
 'name': '中垠紫金观邸',
 'price': 0,
 'when': '2017-12-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:40:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BA%92%E9%BA%9F%E8%A1%97%E9%81%93%E6%99%BA%E9%80%9A%E8%B7%AF189%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:03 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.03160625464619,
 'lng': 118.9119191637564,
 'location': '南京项目地址：麒麟街道智通路189号',
 'name': '启迪方洲博园',
 'price': 0,
 'when': '2016-07-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ydtcyjaadpy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:03 [scrapy.extensions.logstats] INFO: Crawled 521 pages (at 100 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:40:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:03 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A6%E6%B7%AE%E5%A4%A7%E9%81%93168%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:40:03 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.660021743699502,
 'lng': 119.05091071375787,
 'location': '南京项目地址：秦淮大道168号',
 'name': '亚东同城逸境',
 'price': 0,
 'when': '2016-03-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg60> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhjc1haalmu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
2018-04-12 12:40:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_zhjc1haalmu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg58)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 45, in parse_html
    item["name"] = response.xpath('//h1/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ygjbszzykpaadii/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldgyaadmw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsyyjaaaxe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:40:04 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%9388%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:04 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.09998525321101,
 'lng': 118.87119915132855,
 'location': '南京项目地址：玄武大道88号',
 'name': '阳光聚宝山庄臻园',
 'price': 0,
 'when': '2016-09-13'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:40:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:40:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:40:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%BA%A7%E6%B0%B4%E9%87%91%E7%89%9B%E5%8C%97%E8%B7%AF666%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:06 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.625957518863856,
 'lng': 119.00961238373077,
 'location': '南京项目地址：溧水金牛北路666号',
 'name': '溧都桂苑',
 'price': 0,
 'when': '2011-11-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A6%84%E5%8F%A3%E8%A1%97%E9%81%93%E4%BF%A1%E8%AF%9A%E5%A4%A7%E9%81%9333%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:40:06 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.7850970443259,
 'lng': 118.83236228130838,
 'location': '南京项目地址：禄口街道信诚大道33号',
 'name': '招商依云郡',
 'price': 0,
 'when': '2016-07-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jstjsaadxq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:40:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
2018-04-12 12:40:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_flsyjaaayv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_htssyjaaavr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xcjlhaaeaz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:06 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E9%94%A6%E4%B8%8A%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:06 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.046492104483946,
 'lng': 118.62730495548617,
 'location': '南京项目地址：江浦街道锦上路1号',
 'name': '金盛田锦上',
 'price': 0,
 'when': '2014-08-14'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacety/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:40:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg55)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacety/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:40:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:07 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:40:07 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:40:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacetv/>: HTTP status code is not handled or not allowed
2018-04-12 12:40:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:40:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%9B%A8%E8%8A%B1%E6%9D%BF%E6%A1%A5%E6%96%B0%E5%9F%8E%E6%96%B0%E6%B9%96%E5%A4%A7%E9%81%93%EF%BC%88%E8%BF%91%E8%8E%B2%E8%8A%B1%E6%B9%96%E5%85%AC%E5%9B%AD%EF%BC%89 HTTP/1.1" 200 143
2018-04-12 12:40:09 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.91023898425397,
 'lng': 118.66805461945387,
 'location': '南京项目地址：雨花板桥新城新湖大道（近莲花湖公园）',
 'name': '富力尚悦居一期',
 'price': 0,
 'when': '2015-10-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:09 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BA%91%E9%94%A6%E8%B7%AF%E5%AE%8F%E5%9B%BE%E4%B8%8A%E6%B0%B4%E4%BA%91%E9%94%A6 HTTP/1.1" 200 144
2018-04-12 12:40:09 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.021247988570856,
 'lng': 118.74727426898808,
 'location': '南京项目地址：云锦路宏图上水云锦',
 'name': '宏图上水云锦一期',
 'price': 0,
 'when': '2016-06-04'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:40:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:40:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:11 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%A7%A3%E9%99%B5%E8%A1%97%E9%81%93%E9%95%BF%E4%BA%AD%E8%A1%9755%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:11 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.914770739009395,
 'lng': 118.83304208150336,
 'location': '南京项目地址：秣陵街道长亭街55号',
 'name': '新城玖珑湖二期',
 'price': 0,
 'when': '2015-10-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_clgszaadsb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:40:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:13 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B9%8C%E5%A4%8F%E8%B7%AF88%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:13 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.74074774208822,
 'lng': 119.01363948733201,
 'location': '南京项目地址：乌夏路88号',
 'name': '藏珑谷山庄',
 'price': ' 12800',
 'when': '2016-06-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg61> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jnhdjzxabgvh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jmfaabfl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_aaayu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg59)
2018-04-12 12:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zrraaeor/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzscyfaacfh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:40:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhxycabgop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:40:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:15 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E7%89%9B%E6%B9%96%E8%A1%97%E9%81%93%E9%87%91%E7%89%9B%E6%B9%96%E7%A4%BE%E5%8C%BA88%E5%8F%B7 HTTP/1.1" 200 142
2018-04-12 12:40:15 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.47562584733648,
 'lng': 118.97543132009281,
 'location': '南京项目地址：金牛湖街道金牛湖社区88号',
 'name': '金牛湖度假中心',
 'price': 0,
 'when': '2013-12-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:17 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%80%9A%E6%B5%8E%E9%97%A8%E5%A4%96%E5%A4%A7%E8%A1%977%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:18 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.03040026511993,
 'lng': 118.80856022996521,
 'location': '南京项目地址：通济门外大街7号',
 'name': '京门府',
 'price': 0,
 'when': '2013-11-11'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:19 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacewl/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:40:20 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%A4%A7%E5%8E%82%E6%B5%A6%E5%85%AD%E5%8D%97%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:20 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.251425749873995,
 'lng': 118.75004994857319,
 'location': '南京项目地址：大厂浦六南路8号',
 'name': '君悦花园',
 'price': 0,
 'when': '2014-08-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:40:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-04-12 12:40:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 59,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 23,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 36,
 'downloader/request_bytes': 555314,
 'downloader/request_count': 754,
 'downloader/request_method_count/GET': 754,
 'downloader/response_bytes': 15531976,
 'downloader/response_count': 695,
 'downloader/response_status_count/200': 676,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/500': 18,
 'dupefilter/filtered': 912,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 4, 12, 4, 40, 20, 926139),
 'httperror/response_ignored_count': 6,
 'httperror/response_ignored_status_count/500': 6,
 'log_count/DEBUG': 1370,
 'log_count/ERROR': 602,
 'log_count/INFO': 23,
 'memusage/max': 154619904,
 'memusage/startup': 59535360,
 'request_depth_max': 76,
 'response_received_count': 683,
 'retry/count': 69,
 'retry/max_reached': 8,
 'retry/reason_count/500 Internal Server Error': 12,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 21,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 36,
 'scheduler/dequeued': 753,
 'scheduler/dequeued/memory': 753,
 'scheduler/enqueued': 753,
 'scheduler/enqueued/memory': 753,
 'spider_exceptions/IndexError': 296,
 'start_time': datetime.datetime(2018, 4, 12, 4, 30, 2, 933251)}
2018-04-12 12:40:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-04-12 12:40:22 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B2%B3%E8%A5%BF%E5%8D%97%E9%83%A8%E5%AD%A6%E5%AD%90%E8%B7%AF HTTP/1.1" 200 136
2018-04-12 12:40:22 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.087391829280385,
 'lng': 118.82174943981876,
 'location': '南京项目地址：河西南部学子路',
 'name': '正荣润峯',
 'price': 0,
 'when': '2017-04-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%8E%84%E6%AD%A6%E5%A4%A7%E9%81%93%E8%8B%8F%E5%AE%81%E9%92%9F%E5%B1%B1%E6%9C%9D%E9%98%B3%E5%BA%9C HTTP/1.1" 200 137
2018-04-12 12:40:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0913139891331,
 'lng': 118.89802397497581,
 'location': '南京项目地址：玄武大道苏宁钟山朝阳府',
 'name': '苏宁钟山朝阳府',
 'price': 0,
 'when': '2014-03-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%9C%A0%E5%A4%A7%E9%81%93660%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.915202403612295,
 'lng': 118.90964727896606,
 'location': '南京项目地址：龙眠大道660号',
 'name': '龙湖新壹城',
 'price': 0,
 'when': '2017-06-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_yjycydaabsv/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:40:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lcmgyaafsc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:40:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_xscaabhf/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2018-04-12 12:40:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:24 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%BD%8D%E5%A4%84%E5%8D%97%E4%BA%AC%E5%94%AF%E4%B8%80%E7%9C%81%E7%BA%A7%E6%97%85%E6%B8%B8%E5%BA%A6%E5%81%87%E5%8C%BA%E2%80%94%E2%80%94%E7%8F%8D%E7%8F%A0%E6%B3%89%E6%97%85%E6%B8%B8%E5%BA%A6%E5%81%87%E5%8C%BA%E5%AF%86%E6%9E%97%E6%B7%B1%E5%A4%84 HTTP/1.1" 200 142
2018-04-12 12:40:24 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1311378986881,
 'lng': 118.66847660834854,
 'location': '南京项目地址：位处南京唯一省级旅游度假区——珍珠泉旅游度假区密林深处',
 'name': '绿城玫瑰园',
 'price': ' 12800',
 'when': '2014-09-27'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tchabdhu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:25 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E5%B8%82%E6%B1%9F%E5%AE%81%E5%8C%BA%E6%B1%A4%E5%B1%B1%E5%9B%BD%E9%99%85%E6%B8%A9%E6%B3%89%E5%9F%8E%E5%9C%A3%E6%B1%A4%E5%A4%A7%E9%81%939%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:25 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04829213296588,
 'lng': 119.06564056974446,
 'location': '南京项目地址：南京市江宁区汤山国际温泉城圣汤大道9号',
 'name': '汤城汇',
 'price': 0,
 'when': '2015-02-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lggyaawox/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_cpsjgcabbis/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_mfcfzxabdwh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yckqabgrk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:40:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%8E%E6%96%B0%E8%B7%AF%E8%93%9D%E5%85%89%E5%85%AC%E5%9B%AD1%E5%8F%B7 HTTP/1.1" 200 146
2018-04-12 12:40:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.92591631683342,
 'lng': 118.67321099728457,
 'location': '南京项目地址：华新路蓝光公园1号',
 'name': '蓝光公园1号',
 'price': 0,
 'when': '2017-06-17'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg62> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:27 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%96%B0%E6%B8%AF%E5%A4%A7%E9%81%9388%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:27 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.169791062821595,
 'lng': 118.87681335325735,
 'location': '南京项目地址：新港大道88号',
 'name': '翠屏水晶广场',
 'price': ' 45',
 'when': '2016-01-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:29 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%A4%A7%E9%81%936%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:40:29 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.063466256710505,
 'lng': 118.67466304975159,
 'location': '南京项目地址：浦口大道6号',
 'name': '明发财富中心',
 'price': ' 17000',
 'when': '2017-10-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:30 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%87%91%E9%A9%AC%E8%B7%AF%E9%93%B6%E5%9F%8EKinmaQ+%E7%A4%BE%E5%8C%BA HTTP/1.1" 200 136
2018-04-12 12:40:30 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.07294880801665,
 'lng': 118.9122779050283,
 'location': '南京项目地址：金马路银城KinmaQ+社区',
 'name': '银城KinmaQ+社区',
 'price': ' 29000',
 'when': '2017-10-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_tyljxssyabfqd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E6%B5%A6%E8%A1%97%E9%81%93%E7%99%BD%E9%A9%AC%E8%B7%AF89%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:40:32 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08732150414787,
 'lng': 118.63490312801513,
 'location': '南京项目地址：江浦街道白马路89号',
 'name': '通宇林景象山墅院',
 'price': ' 38000',
 'when': '2016-03-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxjshyabdzu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_gjoydsygcabcyp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_yjycydaabsv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:40:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jagwlsabebt/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zsyfaawlq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_xscaabhf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg60)
2018-04-12 12:40:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%A1%94%E6%A1%A5%E8%A5%BF%E8%A1%97155%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:32 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.111578944142316,
 'lng': 118.75557194483122,
 'location': '南京项目地址：宝塔桥西街155号',
 'name': '锦绣江山花园',
 'price': 0,
 'when': '2016-11-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8D%97%E4%BA%AC%E5%B8%82%E6%BA%A7%E6%B0%B4%E5%8C%BA%E7%A7%A6%E6%B7%AE%E8%B7%AF159-21%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:32 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.657385165530922,
 'lng': 119.05231070860395,
 'location': '南京项目地址：南京市溧水区秦淮路159-21号',
 'name': '顾家欧亚达商业广场',
 'price': 0,
 'when': '2015-11-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:32 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%89%AA%E5%AD%90%E5%B7%B735%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:32 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.019721200388425,
 'lng': 118.79260288216061,
 'location': '南京项目地址：剪子巷35号',
 'name': '雅居乐长乐渡',
 'price': ' 2500',
 'when': '2017-12-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:34 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%99%BA%E6%B1%87%E8%B7%AF92%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:34 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.033566135579086,
 'lng': 118.91402647916111,
 'location': '南京项目地址：智汇路92号',
 'name': '京奥港未来墅',
 'price': ' 26000',
 'when': '2017-09-15'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E4%B8%9C%E8%B7%AF301%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:37 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04676420264064,
 'lng': 118.81321034167492,
 'location': '南京项目地址：中山东路301号',
 'name': '钟山颐府',
 'price': 0,
 'when': '2016-06-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%85%89%E4%B8%9C%E8%B7%AF8%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.686029241429527,
 'lng': 119.0426089417233,
 'location': '南京项目地址：红光东路8号',
 'name': '橡树城',
 'price': 0,
 'when': '2018-01-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_hdjbtxaawxd/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:40:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg63> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:40:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hblabcnq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:40:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_wjjyabgxy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:40:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_smjwsabcny/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:40:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%89%E4%B8%AD%E9%97%A8%E5%A4%A7%E8%A1%97%E6%B6%B5%E7%A2%A7%E6%A5%BC HTTP/1.1" 200 137
2018-04-12 12:40:40 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.04442588871159,
 'lng': 118.75600338659478,
 'location': '南京项目地址：汉中门大街涵碧楼',
 'name': '涵碧楼',
 'price': ' 25000',
 'when': '2015-08-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bjhbshyabctn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:40:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:40 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%BA%A2%E5%85%89%E8%B7%AF19%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:40 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.688295449939762,
 'lng': 119.03969542075559,
 'location': '南京项目地址：红光路19号',
 'name': '万景佳苑',
 'price': 0,
 'when': '2016-10-10'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%9F%B3%E6%9D%A8%E8%B7%AF107%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:42 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.01039784610178,
 'lng': 118.87256973377394,
 'location': '南京项目地址：石杨路107号',
 'name': '世茂君望墅',
 'price': 0,
 'when': '2015-09-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hhqhwaayej/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:40:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldbfgcaavjz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:40:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hdjbtxaawxd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg61)
2018-04-12 12:40:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhmsabhag/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:40:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_snzjjyaayda/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:40:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E6%BB%A8%E8%B7%AF58%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:42 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.9483738255737,
 'lng': 118.82015885337091,
 'location': '南京项目地址：湖滨路58号',
 'name': '百家湖别墅花园',
 'price': ' 43000',
 'when': '2017-04-12'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%A1%94%E8%B7%AF98%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:42 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.328638162523443,
 'lng': 118.88087325668766,
 'location': '南京项目地址：宝塔路98号',
 'name': '华辉秦淮湾',
 'price': 0,
 'when': '2017-06-05'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%B9%95%E5%BA%9C%E4%B8%9C%E8%B7%AF%E7%BB%BF%E5%9C%B0%E7%BC%A4%E7%BA%B7%E5%B9%BF%E5%9C%BA HTTP/1.1" 200 134
2018-04-12 12:40:42 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.1181890588941,
 'lng': 118.78596874649138,
 'location': '南京项目地址：幕府东路绿地缤纷广场',
 'name': '绿地缤纷广场',
 'price': ' 158',
 'when': '2017-09-16'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B0%B8%E6%B9%96%E8%B7%AF188%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:43 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.700575027936633,
 'lng': 119.07375409205974,
 'location': '南京项目地址：永湖路188号',
 'name': '恒大金碧天下',
 'price': 0,
 'when': '2018-03-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:43 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%A9%AC%E9%9E%8D%E8%A1%97%E9%81%93%E5%BC%98%E6%B9%96%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:40:43 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.5387256198191,
 'lng': 118.81897438994582,
 'location': '南京项目地址：马鞍街道弘湖路1号',
 'name': '郦湖美墅',
 'price': ' 18500',
 'when': '2017-07-09'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:45 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BE%90%E5%BA%84%E8%BD%AF%E4%BB%B6%E5%9B%AD HTTP/1.1" 200 143
2018-04-12 12:40:45 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.097126504668104,
 'lng': 118.89223524935424,
 'location': '南京项目地址：徐庄软件园',
 'name': '苏宁紫金嘉悦',
 'price': ' 20000',
 'when': '2016-09-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg64> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:40:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:40:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_djyfaaynn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:40:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lbzcaavye/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg62)
2018-04-12 12:40:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg65> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E6%B1%A0%E8%A1%97%E9%81%93%E8%8E%89%E6%B9%96%E8%A5%BF%E8%B7%AF31%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:40:48 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.33177772895079,
 'lng': 118.81890481887899,
 'location': '南京项目地址：龙池街道莉湖西路31号',
 'name': '东骏悦府',
 'price': ' 11000',
 'when': '2016-11-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ljlaaynh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg63)
2018-04-12 12:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:48 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%8F%B0%E5%8D%97%E8%B7%AF10%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:40:48 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：台南路10号',
 'name': '力标赞城',
 'price': 0,
 'when': '2018-01-01'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:50 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B1%9F%E4%B8%9C%E5%8C%97%E8%B7%AF%E9%BE%99%E6%B1%9F%E9%87%8C HTTP/1.1" 200 137
2018-04-12 12:40:50 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05770706730537,
 'lng': 118.74598750383659,
 'location': '南京项目地址：江东北路龙江里',
 'name': '龙江里',
 'price': ' 34000',
 'when': '2016-12-30'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:40:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhzdcabwtn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:51 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%AE%E9%97%A8%E8%A1%97%E9%81%93%E9%BE%99%E6%B9%96%E7%B4%AB%E9%83%BD%E5%9F%8E HTTP/1.1" 200 136
2018-04-12 12:40:51 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.08605878044825,
 'lng': 118.7778016186931,
 'location': '南京项目地址：中央门街道龙湖紫都城',
 'name': '龙湖紫都城',
 'price': ' 20000',
 'when': '2018-03-21'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jxmtdabfxn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zhtylabxle/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacejr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zzgjgcabgdh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AD%A6%E8%A1%A1%E8%B7%AF1%E5%8F%B7 HTTP/1.1" 200 137
2018-04-12 12:40:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.099652629076,
 'lng': 118.92292195845673,
 'location': '南京项目地址：学衡路1号',
 'name': '九霄梦天地',
 'price': ' 26000',
 'when': '2016-02-26'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E7%83%AD%E6%B2%B3%E5%8D%97%E8%B7%AF%E6%9E%9C%E5%93%81%E5%B8%82%E5%9C%BA%E5%9C%B0%E5%9D%97%E4%B8%AD%E6%B5%B7%E6%A1%83%E5%9B%AD%E9%87%8C HTTP/1.1" 200 136
2018-04-12 12:40:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.083859111765705,
 'lng': 118.7477835049071,
 'location': '南京项目地址：热河南路果品市场地块中海桃园里',
 'name': '中海桃源里',
 'price': 0,
 'when': '2018-03-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:40:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacejr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:40:53 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%8A%E6%B5%B7%E5%8C%97%E8%B7%AF699%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:40:53 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：上海北路699号',
 'name': '中州国际广场',
 'price': ' 14000',
 'when': '2017-05-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:40:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:40:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg66> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:40:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:40:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:40:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:40:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:40:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:55 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:40:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:40:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:40:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceln/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:40:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg67> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:40:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceln/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:40:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceka/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:40:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:40:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:40:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceml/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:58 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:40:58 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacele/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg64)
2018-04-12 12:40:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacele/>: HTTP status code is not handled or not allowed
2018-04-12 12:40:58 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:40:58 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacekv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:40:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacekv/>: HTTP status code is not handled or not allowed
2018-04-12 12:40:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacekc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:40:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacekc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg68> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:40:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceni/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:40:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceni/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:40:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:40:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:40:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:41:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenr/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:41:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacemh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:41:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacemh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:01 [scrapy.extensions.logstats] INFO: Crawled 602 pages (at 81 pages/min), scraped 0 items (at 0 items/min)
2018-04-12 12:41:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacend/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:41:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacend/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:41:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceju/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
2018-04-12 12:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepe/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceju/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg65)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg69> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacelu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:41:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacelu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:41:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacept/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacept/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceps/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceps/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceon/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceop/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceom/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceon/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceom/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceol/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceol/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:41:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg70> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:41:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenn/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacenv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
2018-04-12 12:41:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacenv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg69)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:41:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:41:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:41:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepw/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg71> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:41:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacepg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
2018-04-12 12:41:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacepg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg67)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg72> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
2018-04-12 12:41:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg70)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceou/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceoy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
2018-04-12 12:41:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceto/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceou/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceoy/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg68)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceto/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (failed 1 times): 500 Internal Server Error
2018-04-12 12:41:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetk/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacety/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacety/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceun/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceun/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceui/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:41:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceui/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacesd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:41:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesf/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacesd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg73> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:41:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:41:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacero/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:41:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacero/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (failed 2 times): 500 Internal Server Error
2018-04-12 12:41:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacern/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:41:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:41:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacern/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceti/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceti/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg74> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacerx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:41:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacerx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacetj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacetj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuq/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceuu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceuu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevg/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacely/> (failed 1 times): Connection was refused by other side: 111: Connection refused.
2018-04-12 12:41:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacets/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:41:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacets/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacery/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
2018-04-12 12:41:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacery/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg72)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacevx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
2018-04-12 12:41:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacevx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg73)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:24 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (failed 3 times): 500 Internal Server Error
2018-04-12 12:41:24 [scrapy.core.engine] DEBUG: Crawled (500) <GET https://nj.fang.lianjia.com/loupan/p_bcacetv/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg71)
2018-04-12 12:41:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <500 https://nj.fang.lianjia.com/loupan/p_bcacetv/>: HTTP status code is not handled or not allowed
2018-04-12 12:41:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg75> (referer: https://nj.fang.lianjia.com/loupan/pg/pg74)
2018-04-12 12:41:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ldhqchpbjabmmc/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:26 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%8E%8B%E5%A4%A7%E8%A1%97%E7%BB%BF%E5%9C%B0%E5%8D%8E%E4%BE%A8%E5%9F%8E%E6%B5%B7%E7%8F%80%E6%BB%A8%E6%B1%9F HTTP/1.1" 200 137
2018-04-12 12:41:26 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.981396621207637,
 'lng': 118.69564997992349,
 'location': '南京项目地址：龙王大街绿地华侨城海珀滨江',
 'name': '绿地华侨城海珀滨江',
 'price': 0,
 'when': '2017-11-20'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcaceya/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacely/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
2018-04-12 12:41:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcaceya/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexm/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacely/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg66)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexs/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexo/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacewl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacewl/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexh/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/pg/pg76> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_bcacexj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
2018-04-12 12:41:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://nj.fang.lianjia.com/loupan/p_bcacexj/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg75)
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/offsite.py", line 30, in process_spider_output
    for x in result:
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/spiders/Lianjia_spider.py", line 53, in parse_html
    '/html/body/div[2]/div[2]/div[4]/div[2]/div[2]/div/p[3]/span/text()').extract()[0]
IndexError: list index out of range
2018-04-12 12:41:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hlgjablxd/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:41:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:31 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%A4%A7%E8%A1%9781%E5%8F%B7 HTTP/1.1" 200 135
2018-04-12 12:41:31 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.0574390450143,
 'lng': 118.78971204573793,
 'location': '南京项目地址：中大街81号',
 'name': '海伦国际',
 'price': 0,
 'when': '2017-10-31'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_zdmygcabmqi/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:41:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_rssfablye/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:41:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:33 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E4%B8%AD%E5%B1%B1%E9%97%A8%E5%A4%A7%E8%A1%97297%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:41:33 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.043648320833704,
 'lng': 118.86848048488551,
 'location': '南京项目地址：中山门大街297号',
 'name': '钟鼎名悦广场',
 'price': ' 50000',
 'when': '2018-03-19'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_ltxghyabnqx/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:41:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_jshysfabnqz/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:41:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:35 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E8%91%9B%E5%A1%98%E8%A1%97%E9%81%93%E5%92%8C%E6%97%AD%E8%B7%AF500%E5%8F%B7 HTTP/1.1" 200 136
2018-04-12 12:41:35 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.249438029473545,
 'lng': 118.74243099284794,
 'location': '南京项目地址：葛塘街道和旭路500号',
 'name': '荣盛首府',
 'price': 0,
 'when': '2017-11-29'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dhjxhcyabmqu/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:41:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%9D%A5%E5%87%A4%E8%B7%AF5%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:41:37 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.78563307820375,
 'lng': 118.86158025941931,
 'location': '南京项目地址：来凤路5号',
 'name': '蓝天星港花园',
 'price': ' 17000',
 'when': '2017-12-23'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:37 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%A1%94%E6%A1%A5%E6%B1%9F%E5%B1%B1%E6%B1%87%E6%82%A6%E5%B1%B1%E5%BA%9C HTTP/1.1" 200 136
2018-04-12 12:41:37 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.11252831954423,
 'lng': 118.75754400569694,
 'location': '南京项目地址：宝塔桥江山汇悦山府',
 'name': '江山汇悦山府',
 'price': ' 33500',
 'when': '2017-12-24'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:39 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B5%A6%E5%8F%A3%E5%8C%BA%E6%B5%A6%E7%8F%A0%E5%8C%97%E8%B7%AF59%E5%8F%B7 HTTP/1.1" 200 139
2018-04-12 12:41:39 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.123523391191696,
 'lng': 118.72947850536069,
 'location': '南京项目地址：浦口区浦珠北路59号',
 'name': '大华锦绣华城商业',
 'price': ' 45000',
 'when': '2017-07-18'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_lhxycabktp/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:41:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_hnldxsyjabiji/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:41:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:42 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E9%BE%99%E7%9C%A0%E5%A4%A7%E9%81%93660%E5%8F%B7 HTTP/1.1" 200 138
2018-04-12 12:41:42 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.915202403612295,
 'lng': 118.90964727896606,
 'location': '南京项目地址：龙眠大道660号',
 'name': '龙湖新壹城',
 'price': 0,
 'when': '2017-10-25'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_sclfablcb/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:41:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://nj.fang.lianjia.com/loupan/p_dyqsablea/> (referer: https://nj.fang.lianjia.com/loupan/pg/pg76)
2018-04-12 12:41:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:44 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E6%B9%96%E5%8D%97%E8%B7%AF%E5%9C%B0%E4%B8%8B%E5%95%86%E4%B8%9A%E8%A1%97 HTTP/1.1" 200 137
2018-04-12 12:41:44 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.074991410650846,
 'lng': 118.78115603429792,
 'location': '南京项目地址：湖南路地下商业街',
 'name': '湖南路地下商业街',
 'price': ' 300',
 'when': '2017-06-03'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%BB%BA%E9%82%BA%E5%9C%B0%E9%93%81%E4%BA%8C%E5%8F%B7%E7%BA%BF%E5%A4%A9%E8%BF%88%E5%B9%BF%E5%9C%BA%E6%B2%B9%E5%9D%8A%E6%A1%A5%E7%AB%99 HTTP/1.1" 200 139
2018-04-12 12:41:47 [scrapy.core.scraper] ERROR: Error processing {'lat': 31.971841104007034,
 'lng': 118.72764980327469,
 'location': '南京项目地址：建邺地铁二号线天迈广场油坊桥站',
 'name': '首创立方',
 'price': ' 30000',
 'when': '2017-10-13'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.map.baidu.com
2018-04-12 12:41:47 [urllib3.connectionpool] DEBUG: http://api.map.baidu.com:80 "GET /geocoder/v2/?output=json&ak=1wgyLlU4Rpb21GtLBj7cXl6rd55scdzQ&address=%E5%8D%97%E4%BA%AC%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9A%E5%AE%9D%E5%8D%8E%E5%B1%B1%E5%9B%BD%E5%AE%B6%E6%A3%AE%E6%9E%97%E5%85%AC%E5%9B%AD%E5%8D%97%E9%97%A8 HTTP/1.1" 200 136
2018-04-12 12:41:47 [scrapy.core.scraper] ERROR: Error processing {'lat': 32.05723550180587,
 'lng': 118.77807440802562,
 'location': '南京项目地址：宝华山国家森林公园南门',
 'name': '东原亲山',
 'price': ' 20000',
 'when': '2017-12-22'}
Traceback (most recent call last):
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/twisted/internet/defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/HousePriceNJ/pipelines.py", line 26, in process_item
    self.collection.insert(dict(item))
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 2935, in insert
    check_keys, manipulate, write_concern)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 598, in _insert
    bypass_doc_val, session)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/collection.py", line 579, in _insert_one
    _check_write_command_response(result)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 208, in _check_write_command_response
    _raise_last_write_error(write_errors)
  File "/home/yue/Desktop/NJ_HousePriceCrawler/venv/lib/python3.5/site-packages/pymongo/helpers.py", line 190, in _raise_last_write_error
    raise WriteError(error.get("errmsg"), error.get("code"), error)
pymongo.errors.WriteError: db already exists with different case already have: [test] trying to create [Test]
2018-04-12 12:41:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-04-12 12:41:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 57,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 22,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 35,
 'downloader/request_bytes': 554098,
 'downloader/request_count': 752,
 'downloader/request_method_count/GET': 752,
 'downloader/response_bytes': 15483020,
 'downloader/response_count': 695,
 'downloader/response_status_count/200': 678,
 'downloader/response_status_count/404': 1,
 'downloader/response_status_count/500': 16,
 'dupefilter/filtered': 912,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 4, 12, 4, 41, 47, 238746),
 'httperror/response_ignored_count': 4,
 'httperror/response_ignored_status_count/500': 4,
 'log_count/DEBUG': 1382,
 'log_count/ERROR': 604,
 'log_count/INFO': 21,
 'memusage/max': 147521536,
 'memusage/startup': 59322368,
 'request_depth_max': 76,
 'response_received_count': 683,
 'retry/count': 67,
 'retry/max_reached': 6,
 'retry/reason_count/500 Internal Server Error': 12,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 20,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 35,
 'scheduler/dequeued': 751,
 'scheduler/dequeued/memory': 751,
 'scheduler/enqueued': 751,
 'scheduler/enqueued/memory': 751,
 'spider_exceptions/IndexError': 290,
 'start_time': datetime.datetime(2018, 4, 12, 4, 31, 1, 961806)}
2018-04-12 12:41:47 [scrapy.core.engine] INFO: Spider closed (finished)
